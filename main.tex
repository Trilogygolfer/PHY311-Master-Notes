\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{calc}
\usepackage{xcolor}
\usepackage{mathrsfs}
\usepackage{pxfonts}
\usepackage{titlesec}
\usepackage[margin=01.in]{geometry}

\title{Classical Particles, Fields and Matter II}
\author{Nathan Reynolds}
\date{January 2023}

\begin{document}

\maketitle

\tableofcontents
\pagebreak
\chapter{\Huge{Electrostatics}}
\section{The Electric Field $\boldsymbol{E}$ and The Electric Potential $V$}
\subsection{Relation to the fundamental goal of mechanics}
\subsubsection{The fundamental goal of classical mechanics is:}
\paragraph{\indent "Given the total force $\boldsymbol{F}(t)$ acting on a particle during some time interval, what is the position of the particle $\boldsymbol{r}(t)$ for all times within that time interval?"}
\subsubsection{To reach this goal, we must know all the forces acting on the body:}
\begin{equation*}
    \textcolor{red}{\sum_{i}\boldsymbol{F}_i=m\frac{d^2\boldsymbol{r}}{dt^2}}
\end{equation*}
\subsubsection{You have learned that the force on a charge $q$ is given by the \textcolor{blue}{Lorentz Force Law}: $\boldsymbol{F}=q\boldsymbol{E}+q\boldsymbol{v\times B}$}
\subsubsection{So we must know the electric and magnetic fields $\boldsymbol{E}$ and $\boldsymbol{B}$ is we are to find the forces on charged objects- \textcolor{blue}{this represents a key motivation to study electricity and magnetism}}
\subsubsection{To make things simple to start with, we will begin by looking at non-moving charges: "electrostatics"}
\subsubsection{Electric and magnetic fields $\boldsymbol{E}$ and $\boldsymbol{B}$ are \textcolor{blue}{vector fields}, so we will need all the tools of vector calculus that we have learned so far.}
\subsection{Definition of the electric field E}
\subsubsection{The electrostatic force on a \textcolor{blue}{small test charge} is given by the product of the magnitude $Q$ of the electric charge on the small test charge and the magnitude and direction of the electric field $\boldsymbol{E}$ at the location $\boldsymbol{r}$ of the small test charge:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{F}=Q\boldsymbol{E(r)}}
\end{equation*}
\paragraph{A. The word "small" means that the test charge $Q$ itself does not distort the electric field at its location. (In principle, we would have to take the limit $Q\rightarrow 0$ for this to be strictly true.)}
\paragraph{B. Since initially we are studying \textcolor{blue}{electrostatics}, the small test charge $Q$ is not moving, nor will any other charge we are talking about be allowed to move. (Until later in the course)}
\paragraph{C. We will also restrict ourselves for now to consider only situations \textcolor{blue}{in vacuum}. (Until later in the course.)}
\subsubsection{Experimentally, the force between our small test charge $Q$ located at $\boldsymbol{r}$ and another electric charge $q$ located at $\boldsymbol{r'}$ is given by Coulomb's Law:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{F}=\frac{1}{4\pi \epsilon_0}\frac{qQ}{\mathfrak{r^2}}\hat{\mathfrak{r}}: \mathfrak{r}=\boldsymbol{r-r'}}
\end{equation*}
\paragraph{A. In numbers, $\frac{1}{4\pi \epsilon_0}=8.99\times10^9$ newton $\cdot$ meters $^2$/ coulomb$^2$. Compare this with the constant of proportionality for gravitation: $G=6.67\times 10^{-11}$ newton $\cdot$ meters $^2$ / kilogram $^2$}
\paragraph{B. Since our small test charge does not distort the electric field $\boldsymbol{E}$, and since $\boldsymbol{F}=Q\boldsymbol{E}$, then the elecrtic field $\boldsymbol{E}$ produced by the charge $q$ must be:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E}=\frac{1}{4\pi \epsilon_0}\frac{q}{\mathfrak{r^2}}\hat{\boldsymbol{\mathfrak{r}}}: \mathfrak{r}=\boldsymbol{r-r'}}
\end{equation*}
\paragraph{We use $\boldsymbol{r}$ to indicate the location (relative to the origin of our coordinate system) for a particular point where we want to know the value of the field under discussion. That point is called a "\textcolor{blue}{field point}", and is given in "field coordinates".}
\paragraph{We use $\boldsymbol{r'}$ to indicate the location of a source for the field under discussion: the "\textcolor{blue}{source point}",which is given in "source coordinates".}
\subsection{The electric field E from discrete and continuous charge distributions}
\subsubsection{Experimentally, the strength of the electric field $\boldsymbol{E}$ depends \textcolor{blue}{linearly} on the magnitude of the charge $q$:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E(r)}=\frac{1}{4\pi \epsilon_0}\frac{q}{\mathfrak{r^2}}\hat{\boldsymbol{\mathfrak{r}}}}
\end{equation*}
\subsubsection{The electric field due to \textit{N} multiple charges of $q_i$ will be given by the vector sum of the individual electric fields ("\textcolor{blue}{Principle of Superposition}":}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E(r)}=\sum_{n=1}^N\boldsymbol{E}(q_i)=\frac{1}{4\pi\epsilon_0}\sum_{n=1}^N\frac{q_i}{\mathfrak{r}_i^2}\hat{\mathfrak{r}_i}:\mathfrak{r}_i=\boldsymbol{r-r_i'}}
\end{equation*}
\paragraph{A. Again: This is an experimental observation}
\paragraph{B. Note: This different $\hat{\mathfrak{r}_i}$ all point in different directions.}
\subsubsection{For a continuous charge distribution, the sum becomes an integral:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E(r)}=\frac{1}{4\pi\epsilon_0}\sum_{i=1}\frac{q_i}{\boldsymbol{\mathfrak{r}_i^2}}\hat{\boldsymbol{\mathfrak{r}_i}}\longrightarrow\boldsymbol{E(r)}=\frac{1}{4\pi\epsilon_0}\int\frac{dq}{\boldsymbol{\mathfrak{r}^2}}\hat{\boldsymbol{\mathfrak{r}}}}
\end{equation*}
\paragraph{A. From previous courses, you know that, depending on the situation, you can have $dq=\lambda dl'$, $dq=\sigma da'$, or $dq=\rho d\tau'$.}
\paragraph{B. Though the variable $\mathfrak{r}$ contains both $\boldsymbol{r}$ and $\boldsymbol{r'}$, the integration is \textcolor{blue}{solely with respect to source (primed) coordinates}.}
\subsection{$\boldsymbol{E}$ and the vector integral theorems}
\subsubsection{\textcolor{blue}{The Divergence Theorem of Gauss} and $\boldsymbol{E}$}
\paragraph{A. The divergence of a vector field $\boldsymbol{G}$ gives the \textcolor{blue}{net source density} of the field at the point in space where the divergence is evaluated.}
\begin{equation*}
    \nabla\cdot\boldsymbol{G}=\frac{\text{(number of sources}-\text{number of sinks)}}{\text{as the volume}\longrightarrow0}\cdot \text{(proportionality constant)}
\end{equation*}
\paragraph{B. We expect $\nabla\cdot \boldsymbol{E}=\text{[(net electric charge)/(volume}\longrightarrow0)]\cdot \text{constant}$}
\paragraph{C. We know that the electric field is given by:}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E(r)}=\frac{1}{4\pi\epsilon_0}\int \frac{\rho(\boldsymbol{r'})d\tau'}{\boldsymbol{\mathfrak{r}^2}}\hat{\boldsymbol{\mathfrak{r}}}:\boldsymbol{\mathfrak{r}}=\boldsymbol{r-r'}}
\end{equation*}
\paragraph{D. Let's explicitly calculate $\nabla \cdot\boldsymbol{E(r)}$:}
\begin{align*}
    \nabla\cdot\boldsymbol{E}&=\nabla \cdot \bigg( \frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r'})d\tau'}{\boldsymbol{\mathfrak{r}^2}}\hat{\boldsymbol{\mathfrak{r}}}\bigg):\boldsymbol{\mathfrak{r}}=\boldsymbol{r-r'}\\
    \nabla\cdot\boldsymbol{E}&=\frac{1}{4\pi\epsilon_0}\int\rho(\boldsymbol{r'})d\tau' \nabla \cdot \bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\boldsymbol{\mathfrak{r}^2}}\bigg)\\
    \nabla\cdot\boldsymbol{E}&=\frac{1}{4\pi\epsilon_0}\int\rho(\boldsymbol{r'})d\tau' \cdot 4\pi\delta^3(\boldsymbol{\mathfrak{r}})\\
    \nabla\cdot\boldsymbol{E}&=\frac{1}{4\pi\epsilon_0}\int\rho(\boldsymbol{r'})d\tau' \cdot 4\pi\delta^3(\boldsymbol{r-r'})\\
    \nabla \cdot\boldsymbol{E}&= \frac{\rho(\boldsymbol{r})}{\epsilon_0}\\
\end{align*}
\paragraph{This is exactly what we expected:
\\$\nabla\cdot \boldsymbol{E}=\text{[(net electric charge)/(volume}\longrightarrow0)]\cdot \text{constant}$}
\paragraph{E. The \textcolor{blue}{Divergence Theorem of Gauss} states:}
\begin{equation*}
    \textcolor{red}{\oiiint_V \nabla \cdot \boldsymbol{E}d\tau=\oiint_S \boldsymbol{E\cdot da}}
\end{equation*}
\paragraph{We just learned that: $\nabla \cdot \boldsymbol{E}=\frac{\rho(\boldsymbol{r})}{\epsilon_0}$ .}
\paragraph{So the left hand side can be evaluated as:}
\begin{align*}
    \oiiint_V \nabla \cdot \boldsymbol{E}d\tau&=\oiint_S \boldsymbol{E\cdot da}\\
\oiiint_V \frac{\rho(\boldsymbol{r})}{\epsilon_0}d\tau&=\oiint_S \boldsymbol{E\cdot da}\\
    \frac{1}{\epsilon_0}\oiiint_V \rho(\boldsymbol{r})d\tau&=\oiint_S \boldsymbol{E\cdot da}\\
    \frac{Q_{enc}}{\epsilon_0}&=\oiint_S \boldsymbol{E\cdot da}\\
\end{align*}
\paragraph{This means that:}
\begin{equation*}
    \oiint_S\boldsymbol{E\cdot da}=\frac{Q_{enc}}{\epsilon_0}
\end{equation*}
\paragraph{F. These two equations are both called Gauss's Law}
\begin{equation*}
    \oiint_S \boldsymbol{E\cdot da}=\frac{Q_{enc}}{\epsilon_0}\quad :\textbf{\textcolor{red}{Integral Form}}
\end{equation*}
\begin{equation*}
    \nabla \cdot \boldsymbol{E}=\frac{\rho(\boldsymbol{r})}{\epsilon_0}\quad : \textbf{\textcolor{red}{Differential Form}}
\end{equation*}
\paragraph{i. The integral form is "Always true. Sometimes useful."}
\paragraph{Only useful if you can define a \textcolor{blue}{"Gaussian Surface"} $S$ based on symmetries of the problem:}
\paragraph{$\cdot$ The Electric Field $\boldsymbol{E}$ is everywhere perpendicular to the surface (i.e., parallel to the surface element $\boldsymbol{da}$).}
\paragraph{$\cdot$ The Electric Field $\boldsymbol{E}$ is constant over the entire surface $S$.}
\paragraph{$\cdot$ The charge density enclosed in the surface $S$ is finite.} 
\paragraph{If these circumstances arise, then the left-hand side of the equation is just $|\boldsymbol{E}|A=EA$, the right-hand side is $\frac{Q_{enc}}{\epsilon_0}$, and the magnitude of $\boldsymbol{E}$ is just} 
\begin{equation*}
    E=\frac{Q_{enc}}{\epsilon_0A}
\end{equation*}
\subsubsection{\textcolor{blue}{The Curl Theorem of Stokes} and $\boldsymbol{E}$}
\paragraph{A. Suppose we have a charge $Q$ at the origin: $\boldsymbol{r'}=0$ then }
\begin{equation*}
    \hat{\boldsymbol{\mathfrak{r}}}=\hat{\boldsymbol{r}}
\end{equation*}
\paragraph{B. Let's look at the quantity $\boldsymbol{E\cdot dl}$ in spherical coordinates:}
\begin{equation*}
    \boldsymbol{E\cdot dl}=\bigg(\frac{Q}{4\pi\epsilon_0}\frac{\hat{\boldsymbol{\mathfrak{r}}}}{r^2}\bigg)\cdot(dr\hat{\boldsymbol{r}}+rd\theta\hat{\boldsymbol{\theta}}+r\sin{\phi}d\phi\hat{\boldsymbol{\phi}})=\frac{Q}{4\pi \epsilon_0}\frac{dr}{r^2}
\end{equation*}
\paragraph{C. Thus, the integral of this quantity along some path $C$ would be}
\begin{equation*}
    \textcolor{red}{\int_C \boldsymbol{E\cdot dl}=\int_C \frac{Q}{4\pi \epsilon_0}\frac{dr}{r^2}=-\frac{Q}{4\pi \epsilon_0}\bigg\{ \frac{1}{r_2}-\frac{1}{r_1}\bigg\}}
\end{equation*}
\paragraph{D. Obviously, around a closed path (i.e., $r_2=r_1$), we would find}
\begin{equation*}
    \oint\boldsymbol{E\cdot dl}=0
\end{equation*}
\paragraph{E. We could generalize this for \textcolor{blue}{any number of point charges} each, located at different places using the \textcolor{blue}{principle of super position}...  and we'd get exactly the same thing. So, apparently, for any \textcolor{blue}{static} charge distribution}
\begin{equation*}
    \oint\boldsymbol{E\cdot dl}=0
\end{equation*}
\paragraph{F. The Curl Theorem of Stokes says}
\begin{equation*}
    \oint_c\boldsymbol{E\cdot dl}=\iint_S (\nabla \times \boldsymbol{E})\cdot \boldsymbol{da}
\end{equation*}
\paragraph{G. Since the left-hand side is zero for any closed path $C$, the integrand on the right-hand side must also be equal to zero, which means that, for electrostatics}
\begin{equation*}
    \nabla \times \boldsymbol{E}=0
\end{equation*}
\paragraph{H. Since we know that the electrostatic force is $\boldsymbol{F}=Q\boldsymbol{E}$, then for an electrostatic force we have}
\begin{equation*}
    W=\oint \boldsymbol{F\cdot dl}=Q\int\boldsymbol{E\cdot dl}
\end{equation*}
\paragraph{As seen in previous classes, since the work around a closed path is zero, this result means the electrostatic force is conservative (i.e., the total mechanical energy is conserved). We thus also know (1) work is path independent and (2) we can write $\boldsymbol{F}=-\nabla U$, where $U$ is the \textcolor{blue}{potential energy} function.}
\subsubsection{\textcolor{blue}{The Helmholtz Theorem} and $\boldsymbol{E}$}
\paragraph{A. What does it take to uniquely define $\boldsymbol{E}$?}
\paragraph{B. The Helmholtz Theorem spells out the requirements by which a vector field can be specified uniquely.}
\paragraph{For a vector field $\boldsymbol{G(r)}$, if...}
\quad\\
$\cdot$ The divergence $D(\boldsymbol{r})$ and the curl $\boldsymbol{C(r)}$ for $\boldsymbol{G(r)}$ are specified, AND\\
$\cdot$ both $D(\boldsymbol{r})$ and $\boldsymbol{C(r)}$ got to zero faster than $r^{-2}$ as $r\rightarrow \infty$, AND\\
$\cdot$ the vector field $\boldsymbol{G(r)}$ goes to zero as $r\rightarrow \infty$,\\
\textcolor{blue}{then} the vector field $\boldsymbol{G(r)}$ is given by the expression
\begin{equation*}
    \textcolor{red}{\boldsymbol{G(r)}=-\nabla V(\boldsymbol{r}) +\nabla \times \boldsymbol{W(r)}}
\end{equation*}
\indent where,
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi}\int\frac{D(\boldsymbol{r'})}{\mathfrak(r)}d\tau' \quad \text{and} \quad \boldsymbol{W(r)}\equiv \frac{1}{4\pi}\int\frac{\boldsymbol{C(r')}}{\mathfrak{r}}d\tau'
\end{equation*}
\paragraph{C. So: how do you uniquely specify the electrostatic field $\boldsymbol{E(r)}$?}
For an electrostatic electric field $\boldsymbol{E(r)}$, if...\\
$\cdot$ The divergence $D(\boldsymbol{r})$ and the curl $\boldsymbol{C(r)}$ for $\boldsymbol{E(r)}$ are specified, AND\\
$\cdot$ both $D(\boldsymbol{r})$ and $\boldsymbol{C(r)}$ got to zero faster than $r^{-2}$ as $r\rightarrow \infty$, AND\\
$\cdot$ the vector field $\boldsymbol{E(r)}$ goes to zero as $r\rightarrow \infty$,\\
\textcolor{blue}{then} the vector field $\boldsymbol{E(r)}$ is given by the expression
\begin{equation*}
    \textcolor{red}{\boldsymbol{E(r)}=-\nabla V(\boldsymbol{r}) +\nabla \times \boldsymbol{W(r)}=-\nabla V(\boldsymbol{r})}
\end{equation*}
\indent where, 
\begin{equation*}
    V(\boldsymbol{r)}\equiv \frac{1}{4\pi}\int\frac{D(\boldsymbol{r'})}{\mathfrak{r}}d\tau'=\frac{1}{4\pi\epsilon_0}\int\frac{\rho (\boldsymbol{r'})}{\mathfrak{r}}d\tau'\quad\text{and} \quad\boldsymbol{W(r)}\equiv \frac{1}{4\pi}\int\frac{\boldsymbol{C(r')}}{\mathfrak{r}}d\tau'=0
\end{equation*}
\paragraph{D. What do the Helmholtz conditions imply?}
\paragraph{E. Provided we meet the Helmholtz conditions, then $\boldsymbol{E(r)}$ is uniquely defined.}
\paragraph{F. The function $V(\boldsymbol{r})$ is very important. It's called the \textcolor{blue}{electric potential}.}
\subsection{The Definition of the Electric Potential $V$}
\subsubsection{In the previous section, we learned that, provided we satisfy all the Helmholtz conditions, the \textbf{electrostatic} field $\boldsymbol{E(r)}$ is uniquely specified with the relationship $\boldsymbol{E(r)}=-\nabla V(\boldsymbol{r})$, where the \textcolor{blue}{electric potential} $V(\boldsymbol{r})$ is given by}
\begin{equation*}
    V(\boldsymbol{r})\equiv \frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r'})}{\mathfrak{r}}d\tau'
\end{equation*}
\subsubsection{Given the relationship $\boldsymbol{E(r)}=-\nabla V(\boldsymbol{r})$, let us further define}
\begin{equation*}
    V(\boldsymbol{r})\equiv  -\int_{r_{ref}}^{r}\boldsymbol{E\cdot dl}
\end{equation*}
\paragraph{as the "electric potential at the point $\boldsymbol{r}''$}
\paragraph{a. Typically we will pick the \textcolor{blue}{reference point} $\boldsymbol{r}_{ref}$ to be at $\infty$, which will work well for all \textcolor{blue}{finite} charge distributions.}
\paragraph{b. N.B.: Be careful not to confuse the \textcolor{blue}{electrostatic potential energy} $U(\boldsymbol{r})$ (which is an energy), with the \textcolor{blue}{electric potential} $V(\boldsymbol{r})$ (which has units of energy/charge).}
\paragraph{c. The \textcolor{blue}{potential difference} between points $\boldsymbol{r}_a$ and $\boldsymbol{r}_b$ is}
\begin{equation*}
    V(\boldsymbol{r}_b)-V(\boldsymbol{r}_a)=-\int_{r_{ref}}^{r_{b}}\boldsymbol{E\cdot dl}-\bigg(-\int_{r_{ref}}^{r_{a}}\boldsymbol{E\cdot dl}\bigg)
\end{equation*}
\begin{equation*}
    V(\boldsymbol{r}_b)-V(\boldsymbol{r}_a)=-\int_{r_{a}}^{r_{b}}\boldsymbol{E\cdot dl}
\end{equation*}
\paragraph{\indent 1. Thus, the actual value of $V(\boldsymbol{r_{ref}})$ is irrelevant for potential differences.}
\paragraph{\indent 2. This defining relationship gives us a tool for finding the electric potential $V$ if we know the electrostatic field $E$.}
\paragraph{\indent 3. \textcolor{blue}{If you have a finite charge distribution}, setting the reference point $\boldsymbol{r}_{ref}$ to be at $\boldsymbol{r}=\infty$ is reasonable, since the electric field $\boldsymbol{E}$ (and thus the electric potential $V(\boldsymbol{r}_{ref})$) for a finite charge distribution is zero at $\boldsymbol{r}=\infty$}
\paragraph{d. A few more observations about the electric potential $V$}
\paragraph{\indent i. Lousy name: multiple uses of the word "potential" causes confusion}
\paragraph{\indent ii. The electric potential $V(\boldsymbol{r})$ is a scalar, not a vector like $\boldsymbol{E(r)}$.}
\paragraph{\indent iii. The Definition of $V(\boldsymbol{r})$ says $V=V(\rho)$, too.}
\paragraph{\indent iv. Since $V(\boldsymbol{r})$ depends linearly on $\rho(\boldsymbol{r'})$, the principle of superposition applies to $V(\boldsymbol{r})$:}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int\frac{\rho_1(\boldsymbol{r'})}{\mathfrak{r}}d\tau'+\frac{1}{4\pi\epsilon_0}\int\frac{\rho_2(\boldsymbol{r'})}{\mathfrak{r}}d\tau'+\dots
\end{equation*}
\begin{equation*}
    V(\boldsymbol{r})=V_1+V_2+\dots=\sum_iV_i
\end{equation*}
\subsection{The Electric Potential $V$ and the equations of Poisson and Laplace}
\subsubsection{Earlier, we derived Maxwell's Equations for electrostatics:}
\begin{equation*}
    \nabla \cdot \boldsymbol{E}=\frac{\rho}{\epsilon_0} \quad \text{and}\quad \nabla \times\boldsymbol{E}=0
\end{equation*}
\subsubsection{From Helmholtz's Theorem, we also learned that $\boldsymbol{E(r)}$ is uniquely defined (*if we meet the Helmholtz conditions) when we use the definition}
\begin{equation*}
    \boldsymbol{E(r)}=-\nabla V(\boldsymbol{r})\quad \text{:}\quad V(\boldsymbol{r})\equiv \frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r'})}{\mathfrak{r}}d\tau'
\end{equation*}
\subsubsection{Since the gradient, $-\nabla V$, is itself a vector, we can operate on $-\nabla V$ with the $\nabla $ operator in any way we normally would with a vector. In particular, we can take the curl and divergence of $-\nabla V$.}
\indent \paragraph{A. If we take the curl of $-\nabla V$, we recall that the curl of any gradient is identically zero}
\begin{equation*}
    \nabla \times (-\nabla V)=0=\nabla \times \boldsymbol{E}
\end{equation*}
\indent \paragraph{No surprise there. We already knew $\nabla \times \boldsymbol{E}=0$}
\paragraph{B. More interesting is the divergence of $-\nabla V$}
\begin{equation*}
    \nabla \cdot (-\nabla V)=-\nabla^2V=-\bigg\{ \frac{\partial^2V}{\partial x^2}+\frac{\partial^2 V}{\partial y^2}+\frac{\partial^2V}{\partial z^2}\bigg\}
\end{equation*}
\paragraph{Note: You should know that the operator $\nabla^2$ is called the \textcolor{blue}{Laplacian}}
\indent \paragraph{i. But we also know that Maxwell's Equations for Electrostatics gives us the result that}
\begin{equation*}
    \nabla \cdot \boldsymbol{E}=\frac{\rho}{\epsilon_0}
\end{equation*}
\indent \paragraph{ii. Putting these last two results together, we see that}
\begin{equation*}
    \nabla \cdot (-\nabla V)=-\nabla^2V=\nabla \cdot \boldsymbol{E}=\frac{\rho}{\epsilon_0}
\end{equation*}
\begin{equation*}
    \nabla^2 V=-\frac{\rho}{\epsilon_0}
\end{equation*}
\paragraph{\indent $\cdot$ A second-order partial differential equation of a scalar function V.}
\paragraph{\indent $\cdot$ If $\rho \neq 0$, then we have \textcolor{blue}{Poisson's Equation}.}
\paragraph{\indent $\cdot$ If $\rho = 0$, then we have \textcolor{blue}{Laplace's Equation}.}
\paragraph{\indent $\cdot$ These are two extremely important equations in mathematical physics, engineering, quantum mechanics, thermodynamics, etc.}
\paragraph{\indent $\cdot$ We will spend most of our time in later parts finding solutions of Poisson's and Laplace's equations. (Note: This means that we will have to make sure we can prove that we can find \textcolor{blue}{unique} solutions to these equations.)}
\pagebreak
\paragraph{C. The electrostatic triangle: the relationship between $\rho, V,$ and $\boldsymbol{E}$}
\begin{figure}[h]
    \centering
    \includegraphics[scale=.75]{The electrostatic triangle.png}
    \caption{The Electrostatic Triangle}
    \label{fig:my_label}
\end{figure}
\paragraph{\indent 1. We now have the whole set of equations that relate $\rho, V,$ and $\boldsymbol{E}$.}
\paragraph{\indent 2. Note that with one exception, each of these relationships is either an integral or a partial derivative equation.}
\paragraph{\indent 3. That one exception is Poisson's equation, which we will look at closely in the next chapter.}
\paragraph{\indent 4. You should memorize the various relationships of this figure.}
\section{Work and Energy in Electrostatics}
\subsection{Relationship between Work and V}
\subsubsection{The increment of work that \textcolor{blue}{we} do moving \textcolor{blue}{against} the electrostatic force $\boldsymbol{F}$ over a small displacement $\boldsymbol{dl}$ is given by $dW=-\boldsymbol{F\cdot dl}=-(Q\boldsymbol{E})\cdot \boldsymbol{dl}$}
\subsubsection{For electrostatics, the work needed to move a charge $Q$ from $\boldsymbol{r}_a$ to $\boldsymbol{r}_b$ is}
\begin{equation*}
    W=-\int_{r_a}^{r_b}\boldsymbol{F\cdot dl}=-Q\int_{r_a}^{r_b}\boldsymbol{E\cdot dl}=Q(V(\boldsymbol{r}_b)-V(\boldsymbol{r}_a))
\end{equation*}
\paragraph{\indent a. Since the electrostatic force is conservative, $W$ is path independent.}
\paragraph{\indent b. The work per unit of charge needed to move the charge $Q$ from $\boldsymbol{r}_a$ to $\boldsymbol{r}_b$ is }
\begin{equation*}
    \frac{W}{Q}=V(\boldsymbol{r}_b)-V(\boldsymbol{r}_a)
\end{equation*}
\paragraph{\indent c. If we have a finite charge distribution and have chosen $\boldsymbol{r}_{ref}=\infty$, then the work needed to bring the charge from infinity to $\boldsymbol{r}_a$ is }
\begin{equation*}
     W=-\int_{\infty}^{r}\boldsymbol{F\cdot dl}=-Q\int_{\infty}^{r}\boldsymbol{E\cdot dl}=Q(V(\boldsymbol{r})-V(\infty))=QV(\boldsymbol{r})
\end{equation*}
\subsection{Energies associated with assemblies of electric charge}
\subsubsection{How much work does it take to assemble a distribution of three point charges $q_1,q_2, q_3$, in that order, with no other charges around?}
\paragraph{\indent a. It takes \textcolor{blue}{no work} to bring $q_1$ from infinity to is final location. $W_1=0$}
\paragraph{\indent b. The work $W_2$ needed to bring $q_2$ from infinity to its final location is solely due to the work done against the electrostatic field produced by $q_1$:}
\begin{equation*}
    W_2=q_2\cdot V_1(q_1)=q_2\cdot\frac{1}{4\pi \epsilon_0}\frac{q_1}{\mathfrak{r}_{12}}=\frac{1}{4\pi\epsilon_0}\frac{q_1q_2}{\mathfrak{r}_{12}}
\end{equation*}
\paragraph{\indent c. The work $W_3$ needed to bring $q_3$ from infinity to its final location will be due to the work done against the electrostatic field produced by $q_1$ and the work done against the electrostatic field produced by $q_2$:}
\begin{equation*}
    W_3=q_3\cdot V_1(q_1)+q_3\cdot V_2(q_2)=q_3\cdot \bigg\{ \frac{1}{4\pi\epsilon_0}\frac{q_1}{\mathfrak{r}_{13}} +\frac{1}{4\pi\epsilon_0}\frac{q_2}{\mathfrak{r}_{23}}\bigg\}
\end{equation*}
\begin{equation*}
    W_3=\frac{1}{4\pi\epsilon_0}\frac{q_1q_3}{\mathfrak{r}_{13}}+\frac{1}{4\pi\epsilon_0}\frac{q_2q_3}{\mathfrak{r}_{23}}
\end{equation*}
\paragraph{\indent d. Putting all these together, the total work needed to put this charge assembly together would be}
\begin{align*}
    W=W_1+W_2+W_3&=0+\bigg(\frac{1}{4\pi\epsilon_0}\frac{q_1q_2}{\mathfrak{r}_{12}}\bigg)+\bigg(\frac{1}{4\pi\epsilon_0}\frac{q_1q_3}{\mathfrak{r}_{13}}+\frac{1}{4\pi\epsilon_0}\frac{q_2q_3}{\mathfrak{r}_{23}}\bigg)\\
    W&=\frac{1}{4\pi\epsilon_0}\sum_{i=1}^3\sum_{j>i}^3\frac{q_iq_j}{\mathfrak{r}_{ij}}\\
    W&=\frac{1}{2}\frac{1}{4\pi\epsilon_0}\sum_{i=1}^3\sum_{j>i}^3\frac{q_iq_j}{\mathfrak{r}_{ij}}\\
    W&=\frac{1}{2}\sum_{i=1}^3q_i\bigg( \sum_{j\neq i}^3\frac{1}{4\pi \epsilon_0}\frac{q_j}{\mathfrak{r}_{ij}}\bigg)\\
     W&=\frac{1}{2}\sum_{i=1}^3q_iV(\boldsymbol{r}_i) \quad : \quad V\equiv \sum_{j\neq i}^{3}\frac{1}{4\pi\epsilon_0}\frac{q_j}{\mathfrak{r}_{ij}}
\end{align*}
\paragraph{\indent e. More generally, we could do the same thing for $n$ charges and we would get}
\begin{equation*}
    W=\frac{1}{2}\sum_{i=1}^n q_i V(\boldsymbol{r}_i) \quad :\quad V\equiv\sum_{j\neq i}^n \frac{1}{4\pi\epsilon_0}\frac{q_j}{\mathfrak{r}_{ij}}
\end{equation*}
\paragraph{\indent f. For a \textcolor{blue}{continuous charge distribution}, we modify this formula by taking the limit as $q_i=dg\rightarrow 0$, and our summation over $q_i$ would become an integral over $dq$:}
\begin{equation*}
    W=\frac{1}{2}\sum_{i=1}^n q_i V(\boldsymbol{r}_i) \longrightarrow W=\frac{1}{2}\int dq\cdot V
\end{equation*}
\paragraph{\indent where V is now the potential produced by the \textcolor{blue}{entire} charge distribution (since $dq\rightarrow0$)}
\paragraph{\indent i. If we are dealing with volume, surface, or linear charge distributions, then we'd write $dq=\rho d\tau, \sigma da,$ or $\lambda dl$, respectively.}
\paragraph{\indent ii. This $W$ is the total work needed to assemble this particular charge distribution. Alternately, we could say that this is the energy "stored" in this assembly of charge (the assembly's "potential energy").}
\subsubsection{Suppose we have a continuous distribution of charge. We just now saw that}
\begin{equation*}
    W=\frac{1}{2}\int dq\cdot V=\frac{1}{2}\int \rho d\tau V
\end{equation*}
\paragraph{\indent a. We can use the divergence equation from Maxwell's equations for electrostatics to eliminate $\rho=\epsilon_0(\nabla \cdot \boldsymbol{E})$:}
\begin{equation*}
    W=\frac{1}{2}\int \rho d\tau V = \frac{1}{2}\int \epsilon_0 (\nabla\cdot \boldsymbol{E}) V d\tau
\end{equation*}
\paragraph{\indent b. Let's make use of the product rule identity}
\begin{equation*}
    \nabla\cdot (V\boldsymbol{E})=(\nabla\cdot \boldsymbol{E})V+\boldsymbol{E}\cdot (\nabla V)
\end{equation*}
\paragraph{\indent In particular, let's move things around to get}
\begin{equation*}
    (\nabla\cdot \boldsymbol{E})V=-\boldsymbol{E}\cdot(\nabla V)+\nabla\cdot(V\boldsymbol{E}
\end{equation*}
\paragraph{\indent then we get}
\begin{equation*}
    W=\frac{1}{2}\int \epsilon_0(\nabla\cdot\boldsymbol{E})Vd\tau=\frac{1}{2}\int d\tau \epsilon_0\boldsymbol{E}\cdot(-\nabla V)+\frac{1}{2}d\tau \epsilon_0\nabla\cdot(V\boldsymbol{E})
\end{equation*}
\paragraph{\indent d. So now we have}
\begin{equation*}
    W=\frac{1}{2}\int \epsilon_0(\nabla\cdot\boldsymbol{E})Vd\tau=\frac{1}{2}\int d\tau \epsilon_0\boldsymbol{E}\cdot(-\nabla V)+\frac{1}{2}d\tau \epsilon_0\nabla\cdot(V\boldsymbol{E})
\end{equation*}
\paragraph{\indent i. We immediately recognize $\boldsymbol{E}=\nabla V$ in the first term.}
\paragraph{\indent ii. Let's use the divergence theorem of Gauss to clean up that last term and explicitly indicate that we are integrating over a particular volume $V$:}
\begin{equation*}
    W=\frac{\epsilon_0}{2}\oiiint_V d\tau \boldsymbol{E\cdot E}+\frac{\epsilon_0}{2}\oiint_S (V\boldsymbol{E})\cdot \boldsymbol{da}
\end{equation*}
\paragraph{\indent iii.What volume $V$ do we use for this integration? The \textcolor{blue}{most general volume} would be \textcolor{blue}{all space}, so let's try that. That puts the boundary of $S$ at $\boldsymbol{r}=\infty$}
\paragraph{\indent iv. If our electric field $\boldsymbol{E}$ satisfies the Helmholtz conditions, then we know that $\boldsymbol{E}(\boldsymbol{r})=0$. Hence, the last term vanishes and all we're left with is}
\begin{equation*}
    W=\frac{\epsilon_0}{2}\oiiint_V d\tau \boldsymbol{E\cdot E} \longrightarrow W=\frac{\epsilon_0}{2}\int d\tau E^2 \quad \text{(all space)}
\end{equation*}
\paragraph{\indent e. A few more observations about the work/energy $W$}
\paragraph{\indent i. At this point, we cannot say definitively where $W$ is "stored". Is the energy stored in the charges, in the fields, or both? The "final" answer will have to come later on.}
\paragraph{\indent ii. The quantity $\textcolor{blue}{\frac{\epsilon_0 E^2}{2}}$ is sometimes referred to as the "\textcolor{blue}{energy density of the electric field}".}
\paragraph{\indent iii. Note: Neither expression for $W$ involves the charge \textcolor{blue}{linearly}, so the principle of superposition does \textcolor{blue}{not} apply to $W$. For example, if we have two electric fields $\boldsymbol{E}_1$ and $\boldsymbol{E}_2$, then the combination of those two $\boldsymbol{E}=\boldsymbol{E}_1+\boldsymbol{E}_2$ would give}
\begin{equation*}
    W=\frac{\epsilon_0}{2}\int d\tau E^2=\frac{\epsilon_0}{2}\int d\tau \boldsymbol{E\cdot E}=\frac{\epsilon_0}{2}\int d\tau(\boldsymbol{E_1+E_2})\cdot(\boldsymbol{E_1+E_2})
\end{equation*}
\begin{equation*}
    W=\frac{\epsilon_0}{2}\int d\tau E_1^2+\frac{\epsilon_0}{2}\int d\tau E_2^2+\frac{\epsilon_0}{2}\int d\tau (2\boldsymbol{E_1\cdot E_2})
\end{equation*}
\begin{equation*}
    W=W_1+W_2+\epsilon_0 \int d\tau (\boldsymbol{E_1\cdot E_2})\textcolor{red}{\neq W_1+W_2}
\end{equation*}
\subsection{\textcolor{blue}{ Conductors}}
\subsubsection{Basic concepts and results}
\paragraph{1. Definitions- we split the materials of the world into two classes}
\paragraph{\indent a. Conductors}
\paragraph{\indent\indent i. Materials (e.g., aluminum, copper, most metals) where charged particles are essentially free to move within the material.}
\paragraph{\indent\indent ii. Electrical current flows ("conducts") easily in a conductor. }
\paragraph{\indent\indent iii. We say the material has \textcolor{blue}{low electrical resistance} (ideally zero).}
\paragraph{\indent b. \textcolor{blue}{Insulators} or \textcolor{blue}{dielectrics}}
\paragraph{\indent\indent i. Materials (e.g., rubber, glass) where all electric charges are tightly bound to an atom. Thus, all the charged particles of the material are essentially immobile.}
\paragraph{\indent\indent ii. Electric current flows negligibly in an insulator or dielectric.}
\paragraph{\indent\indent iii. We say the material has \textcolor{blue}{high electric resistance} (ideally infinite).}
\paragraph{2. Basic observations and implications for net charge on conducting bodies}
\paragraph{\indent a. All free charge in a conductor resides on the surface of the conductor. Thus, the charge density $\rho$ is, \textcolor{blue}{$\rho = 0$ within a conductor.}}
\paragraph{\indent b. Since $\rho=0$ inside a conductor, a Gaussian surface of any shape inside the conductor will contain zero net charge. Hence, the electric field \textcolor{blue}{$E(r)=0$ inside any conductor}.}
\paragraph{\indent c. If an external electric field is applied, charges rearrange to cancel the applied field within the conductor. Thus, inside the conductor, even if there is an external electric field, $\boldsymbol{E(r)}=0$.}
\paragraph{\indent d. Since everywhere inside a conductor $\boldsymbol{E(r)}=0$, and $\boldsymbol{E(r)}=-\nabla V(\boldsymbol{r})$, then the electric potential \textcolor{blue}{$V(\boldsymbol{r})$ inside a conductor is constant}.}
\paragraph{\indent e. Since, mathematically, the electric potential $V(\boldsymbol{r})$ must be continuous, \textcolor{blue}{the surface of a conductor is an equipotential surface}.}
\paragraph{\indent f. Since the surface is an equipotential, any electric field outside the surface must be perpendicular at the surface: \textcolor{blue}{$\boldsymbol{E}=-\frac{\partial V}{\partial n}$}.}
\paragraph{3. Boundary conditions - The divergence theorem of Gauss and the curl theorem of Stokes lead to results that give us conditions on how the perpendicular and parallel components of $\boldsymbol{E}$ behave at boundaries. (e.g., surfaces of conductors)}
\paragraph{\indent a. The integral form of Gauss' law (which came from the divergence theorem of Gauss) tells us that}
\begin{equation*}
    \oiint_S \boldsymbol{E\cdot da}=\frac{Q_{enc}}{\epsilon_0}
\end{equation*}
\paragraph{\indent\indent i. If we imagine an infinitesimally thin pillbox on the surface of a conductor, we know that the total charge enclosed is $\sigma A$, while the left-hand side of the equation is simply $EA$}
\paragraph{\indent\indent ii. So $E=\frac{\sigma}{\epsilon_0}=-\frac{\partial V}{\partial n}$ just outside the boundary.}
\paragraph{\indent\indent iii. Since $\boldsymbol{E}$ is zero inside the conductor and is perpendicular to the surface just outside, the perpendicular component of $\boldsymbol{E}$ is discontinuous by an amount $\frac{\sigma}{\epsilon_0}$ at the boundary}
\begin{equation*}
    E_{above}^{\perp}-E_{below}^{\perp} =\frac{\sigma}{\epsilon_0}
\end{equation*}
\begin{equation*}
     E_{above}^{\perp}-E_{below}^{\perp}=-\frac{\partial V}{\partial n}=\frac{\sigma}{\epsilon_0}
\end{equation*}
\paragraph{\indent b. The curl theorem of Stokes told us that, for electrostatics, }
\begin{equation*}
    \oint\boldsymbol{E\cdot dl}=0
\end{equation*}
\paragraph{\indent\indent i. Imagine an infinitesimally rectangular loop( $l$ long, $\epsilon$ high) going above and below a charged surface.}
\paragraph{\indent\indent ii. Shrink the sides of the loop that pierce the surface to nothing ($\epsilon=0$).}
\paragraph{\indent\indent iii. This means, then, that $E_{above}^{\parallel}\cdot l-E_{below}^{\parallel}\cdot l=0$}
\paragraph{\indent\indent iv. Thus, the parallel component of $\boldsymbol{E}$ is the same above and below the boundary:}
\begin{equation*}
    E_{above}^{\parallel}=E_{below}^{\parallel}
\end{equation*}
\paragraph{\indent c. With a similar analysis, you can show that both these analyses apply to \textcolor{blue}{any boundary carrying a surface charge density}, whether the boundary is at the surface of a conducting material or not}
\begin{equation*}
    \textcolor{red}{ E_{above}^{\perp}-E_{below}^{\perp} =\frac{\sigma}{\epsilon_0}\quad \text{and}\quad E_{above}^{\parallel}=E_{below}^{\parallel}}
\end{equation*}
\paragraph{4. Forces on Conductors}
\paragraph{\indent 1. A patch of charge on the surface of a conductor experiences an average force $F_{avg}$ perpendicular to the surface given by}
\begin{equation*}
    F_{avg}+QE_{avg}=\sigma A\cdot E_{avg}
\end{equation*}
\begin{equation*}
    F_{avg}=\sigma A\cdot\bigg(\frac{E_{above}-E_{below}}{2}\bigg)=\sigma A\cdot\bigg(\frac{\sigma/\epsilon_0-0}{2}\bigg)=\frac{\sigma^2 A}{2\epsilon_0}
\end{equation*}
\paragraph{\indent 2. This force results in an \textcolor{blue}{electrostatic pressure} given by}
\begin{equation*}
    P=\frac{F}{A}=\frac{\sigma^2}{2\epsilon_0}
\end{equation*}
\paragraph{\indent\indent This pressure tries to pull the conductor into the field.}
\paragraph{\indent 3. If the field is great enough, the pressure can pull atoms from the surface (capacitor failure, neurotransmitter flow at synapses, metal balloons, etc.)}
\paragraph{\indent 4. The energy density of the electric field just outside the conductor is}
\begin{equation*}
    \frac{\epsilon_0 E^2}{2}=\frac{\epsilon_0}{2}(\sigma/\epsilon_0)^2=\frac{\sigma^2}{2\epsilon_0}
\end{equation*}
\paragraph{\indent\indent This energy density is precisely the same as the electrostatic pressure.}
\subsection{Capacitors}
\paragraph{1. Suppose we have two isolated conductors, one with a charge $+Q$ and the other with a charge $-Q$. What is the electric potential $V$ between the two conductors?}
\paragraph{\indent a. There's an ambiguity at this point: Which way do we intend to take this difference? We \textcolor{blue}{choose} to take the potential difference between the electric potential on the positive conductor $V_+$ and the electric potential on the negative conductor $V_-$: \textcolor{blue}{$V=V_+-V_-$}.}
\paragraph{\indent b. Then, using the definition of the electric potential, we would say the potential difference $V$ is}
\begin{equation*}
    V=V_+-V_-=-\int_{r(V_-)}^{r(V_+)}\boldsymbol{E}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent where the electric field $\boldsymbol{E}$ arises from the charge on the conductor as}
\begin{equation*}
    \boldsymbol{E}=\frac{1}{4\pi\epsilon_0}\int_{all charge}\frac{\rho(\boldsymbol{r}')d\tau'}{\mathfrak{r}}\hat{\boldsymbol{\mathfrak{r}}}
\end{equation*}
\paragraph{\indent c. This potential difference $V=V_+-V_-$ has a total of three pieces}
\paragraph{\indent\indent i. As we've noted before, the electric field $\boldsymbol{E}$ depends \textcolor{blue}{linearly} on the \textcolor{blue}{total charge $Q$}, whatever its magnitude. Thus, the total charge $Q$ is simply a number that comes out of the integral for $\boldsymbol{E}$ once we've integrated over the charge.}
\paragraph{\indent\indent ii. The integral for $\boldsymbol{E}$ depends on the details of \textcolor{blue}{the geometry of how charge is arranged on a conductor}. The factor $Q$ will multiply this geometry integral.}
\paragraph{\indent\indent iii. The final path integral for the electric potential $V=V_+-V_-$ depends on \textcolor{blue}{the geometry of how the conductors are oriented with respect to each other}.}
\paragraph{\indent d. So the potential difference $V=V_+-V_-$ could be written as a product of two things: the total charge $Q$, and an overall geometric factor from the two geometry integrals:}
\begin{equation*}
    V=V_+-V_-=Q\times\text{(geometric factor)}
\end{equation*}
\paragraph{\indent\indent i. In words: The potential difference $V$ is proportional to the total charge $Q$  times an overall geometric factor that depends on the particular geometry.}
\paragraph{\indent\indent ii. Or: For a given geometric arrangement of conductors, the potential difference depends linearly on the total charge $Q$. If you double $Q$, you double the potential difference between two conductors.}
\paragraph{2. If that's the case, then, for a particular geometric arrangement of conductors, we could define a number that pills out this overall geometric factor:}
\begin{equation*}
    V=V_+-V_-=Q\times \text{(geometric factor)}\rightarrow V=\frac{Q}{C}
\end{equation*}
\begin{equation*}
    C=\frac{Q}{V}:\quad C=\frac{1}{\text{(geometric factor)}}
\end{equation*}
\paragraph{\indent a. The quantity $C$ is called the \textcolor{blue}{capacitance} for that particular geometric arrangement of conductors.}
\paragraph{\indent b. An assembly of conductors that separates electric charges is called a \textcolor{blue}{capacitor}.}
\paragraph{\indent c. The capacitance $C$ depends \textcolor{blue}{solely} on the particular geometric arrangement of the conductors.}
\paragraph{\indent d. The charge $Q$ is always the charge on the positive conductor, and the electric potential difference is the difference $V=V_+-V_-$. \textcolor{blue}{Anytime you calculate $C$, the result always must be positive}.}
\paragraph{\indent e. The units for capacitance}
\paragraph{\indent\indent i. Based on the definition of the capacitance, the units for $C$ would be coulombs per volt.}
\paragraph{\indent\indent $\cdot$ One coulomb per volt is called a farad, after Michael Faraday.}
\paragraph{\indent\indent $\cdot$ This is a truly huge unit because a coulomb is a huge charge. More often than not, we see micro-farad or pico-farad ($\mu F$ or $pF$).}
\paragraph{\indent\indent ii. Symbolically, the units for capacitance could be found this way:}
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r}')d\tau'}{\mathfrak{r}}\approx\frac{\text{coulombs}}{\epsilon_0\times \text{length}}
\end{equation*}
\begin{equation*}
    C=\frac{Q}{V}\approx\frac{\text{coulombs}}{\text{coulombs/}\epsilon_0\times \text{length}}=\epsilon_0\times \text{length}
\end{equation*}
\paragraph{3. The element of work needed to add charge $dq$ to a capacitor would be}
\begin{equation*}
    dW=dqV
\end{equation*}
\paragraph{\indent i. So the total work needed to charge the capacitor must be}
\begin{equation*}
    W=\int_{0}^{Q} dq\cdot V
\end{equation*}
\paragraph{\indent ii. But we know that $V=Q/C$, so this integral becomes}
\begin{equation*}
    W=\int_0^Q dq\cdot\frac{Q}{C}=\frac{1}{2C}Q^2
\end{equation*}
\paragraph{\indent iii. Using the same definition $V=Q/C$ again on this result, we could also write this as $W=\frac{1}{2}QV$ or $W=\frac{1}{2}CV^2$}
\paragraph{\indent iv. So capacitors are useful for storing energy in electrical systems.}
\paragraph{\indent v. Is this result sensible? For the parallel plate capacitor, we would have}
\begin{equation*}
    W=\frac{Q^2}{2C}=\frac{1}{2}\frac{\sigma^2A^2}{\frac{\epsilon_0A}{d}}=\bigg(\frac{\sigma^2}{2\epsilon_0}\bigg)\cdot Ad=\frac{\epsilon_0}{2}E^2\cdot Ad\quad: \textcolor{blue}{\frac{\epsilon_0}{2}E^2}\quad\textcolor{blue}{\text{electric density in the electric field}}
\end{equation*}
\paragraph{So, yes, this makes sense. The work needed is equal to the energy density of the electrostatic field times the volume between plates.}
\section{Potentials}
\subsection{Laplaces' Equations}
\subsubsection{General Observations}
\paragraph{1. We have seen that, if we have an electric field $\boldsymbol{E}$ and a charge density $\rho$,}
\begin{equation*}
    \nabla \cdot \boldsymbol{E}=\frac{\rho}{\epsilon_0}\quad,\quad \nabla \times \boldsymbol{E}=0 \longrightarrow \boldsymbol{E}=-\nabla V
\end{equation*}
\begin{equation*}
    \longrightarrow \nabla\cdot (-\nabla V)=-\nabla^2V=\frac{\rho}{\epsilon_0}
\end{equation*}
\begin{equation*}
    \nabla^2V=\frac{\rho}{\epsilon_0}
\end{equation*}
\paragraph{\indent a. A second-order partial differential equation for a scalar function V}
\paragraph{\indent b. We can use this equation to describe the behavior of V in a particular region of space $R$ in which we are interested}
\paragraph{\indent c. There are, in fact, only two possibilities within this region $R$:}
\paragraph{\indent\indent 1. The charge density $\rho\neq 0$ in the region of interest $R$ \textcolor{blue}{(Poisson's Equation)}}
\paragraph{\indent\indent $\cdot$ A formidable problem you'll encounter in a partial differential equations course, graduate level, E and M, etc.}
\paragraph{\indent\indent $\cdot$ We will use the uniqueness theorems and  some cleverness to handle a few examples of this equation \textcolor{blue}{(Mirror of Images)}.}
\paragraph{\indent\indent 2. The charge density $\rho=0$ in the region of interest $R$ \textcolor{blue}{(Laplace's Equation)}}
\paragraph{2. Laplace's Equation $\nabla^2V=0$}
\paragraph{\indent \textcolor{blue}{Note:} Though the charge density $\rho$ is zero in the region of interest $R$, there must be charge \textcolor{blue}{somewhere} in the problems we work. (If not, we get $V=0$ everywhere.) But for Laplace's equation, $\rho=0$ in the region of interest $R$.}
\paragraph{\indent A. \textcolor{blue}{Laplace's Equation in one dimension} would be $\frac{d^2V}{dx^2}=0$.}
\paragraph{\indent\indent 1. This equation has the solution $V=mx+b$. We can make \textcolor{blue}{three observations} about $V$ from this solution, which will be true of solutions in any number of dimensions.}
\paragraph{\indent\indent $\cdot$ A set of boundary conditions can completely specify all undetermined constants. }
\paragraph{\indent\indent $\cdot$ $V(x)$ is the average of $V(x+a)$ and $V(x-a)$. In other words, the solution $V(x)$ in any sub-region of $R$ will yield the average of $V(x)$ in that sub-region of $R$ (This leads to the relaxation method).}
\paragraph{\indent\indent $\cdot$ There are no extrema for $V(x)$ in $R$ (for anywhere in $\nabla^2V=0$) nor in any sub-region of $R$.}
\paragraph{\indent\indent 2. These observations hold for 1-D solutions in other coordinate systems:}
\paragraph{\indent\indent $\cdot \quad V = -\frac{c}{r} +k$ }
\paragraph{\indent\indent $\cdot \quad V= c\ln r +k$ }
\paragraph{3. Laplace's Equation in three dimensions}
\begin{equation*}
    \frac{\partial^2 V(x,y,z)}{\partial x^2}+\frac{\partial^2 V(x,y,z)}{\partial y^2}+\frac{\partial^2 V(x,y,z)}{\partial z^2}=0
\end{equation*}
\paragraph{\indent A. The same three observations apply:}
\paragraph{\indent i. A set of boundary conditions can completely specify all undetermined constants.}
\paragraph{\indent ii. The solution $V(x,y,z)$ is the average value of $V$ for a sphere about the point $V(x,y,z)$.}
\paragraph{\indent iii. There are no extrema for $V(x,y,z)$ in $R$ (for anywhere that $\nabla^2V=0$) nor in any sub-region of $R$.}
\paragraph{\indent \textcolor{blue}{This last observation leads to Earnshaw's Theorem}.}
\paragraph{\indent \textcolor{purple}{Earnshaw's Theorem: A charged particle cannot be held in a stable equilibrium by electrostatic forces alone.}}
\paragraph{\indent B. For solving Laplace's equation, we will use the method of \textcolor{blue}{separation of variables} when we have 2-D or 3-D problems.}
\subsubsection{Uniqueness Theorems and Corollaries}
\paragraph{\textcolor{blue}{1. The Principle of Superposition}}
\paragraph{\indent If $\varphi_1,\varphi_2,\dots \varphi_n$ are solutions of Laplace's Equation, then the function $\varphi=c_1\varphi_1+c_2\varphi_2+\dots +c_n\varphi_n$ is also a solution.}
\paragraph{\indent a. \textcolor{purple}{PROOF:} We substitute the proposed solution into Laplace's Equation}
\begin{equation*}
    \nabla^2 \varphi=\nabla^2(c_1\varphi_1)+\nabla^2(c_2\varphi_2)+\dots=c_1\nabla^2\varphi_1+c_2\nabla^2\varphi_2+\dots
\end{equation*}
\paragraph{\indent but, if $\varphi_1,\varphi_2,\dots, \varphi_n$ are solutions of Laplace's equation, then we know that $\nabla^2\varphi_1=0,\nabla^2\varphi_2=0,$ etc.}
\paragraph{\indent thus, we have $\nabla^2\varphi=c_1\cdot0+c_2\cdot 0+\dots =0$. Q.E.D.}
\paragraph{\indent b. Why is this a big deal? The principle of superposition will be important for us in this whole chapter because this means we can produce an ansatz (i.e. an educated guess) that is a sum of possible solutions to Laplace's equations (e.g. say, orthogonal functions). We then match our boundary conditions on the surface $S$ that bounds the region of interest $R$ to obtain a fully-specified solution to Laplace's Equation.}
\paragraph{\textcolor{blue}{2. A Uniqueness theorem for $V$}}
\paragraph{Theorem: The solution to Laplace's Equation in a region of interest $R$ is uniquely determined if $V$ is specified on the surface $S$ bounding $R$.}
\paragraph{\indent \textcolor{purple}{"$V$ is specified on the surface $S$ bounding $R$" These are "Dirichlet-type boundary conditions", and a problem posed with these boundary conditions is called a "Dirichlet Problem".}}
\paragraph{\indent a. \textcolor{purple}{Proof:} Suppose we did find two different solutions $V_1$ and $V_2$ that satisfy the boundary condition at $S$.}
\paragraph{\indent\indent i. Define $V_3\equiv V_2-V_1$, at $S$, $V_3$ must be equal to zero because $V_1$ and $V_2$ satisfy the boundary conditions at $S$.}
\paragraph{\indent\indent ii. Using the Principle of Superposition, $\nabla^2 V_3=\nabla^2V_2-\nabla^2V_1=0$ everywhere in $R$.}
\paragraph{\indent\indent iii. Solutions of Laplace's equation cannot have extrema in $R$.}
\paragraph{\indent\indent iv. Therefore, $V_3$ must be equal to zero everywhere in $R$.}
\paragraph{\indent\indent v. Thus, $V_2$  must equal $V_1$ everywhere in $R$}
\paragraph{\indent\indent vi. Only one solution exists in $R$ meeting the boundary conditions a $S$. Q.E.D.}
\paragraph{\indent b. \textcolor{blue}{This is an extremely important result!} If we find a solution for $V$ that meets the boundary conditions at the boundary $S$, \textcolor{blue}{no matter how we do it}, we have found the \textcolor{blue}{only} solution for $V$ in the region $R$.}
\subsection{The Method of Images}
\subsubsection{\textcolor{purple}{Reprise: The Power of Uniqueness Theorems}}
\paragraph{1. For a particular region of interest $R$, our electric potential $V$ must satisfy \textcolor{blue}{Laplace's Equation} (in those cases where we have $\rho=0$ in $R$) or \textcolor{blue}{Poisson's Equation} (where $\rho\neq 0$ in $R$).}
\paragraph{2. We are interested in a \textcolor{blue}{unique solution} of Laplace's (or Poisson's) equation in $R$ that meets a particular set of boundary conditions for the surface $S$ which encloses $R$.}
\paragraph{\indent a. We may not know -and definitely do not care- what happens outside of $R$.}
\paragraph{\indent b. The uniqueness theorem(s) guarantee that if we find \textcolor{blue}{a} solution $V$ in $R$ that satisfies the boundary conditions in $S$ -regardless of how we do that- then we have the \textcolor{blue}{only} solution for $V$ for our problem.}
\subsubsection{The \textcolor{blue}{method of images} works this way:}
\paragraph{1. We have one or more charges in $R$ and we want to find $V$ in $R$.}
\paragraph{2. Suppose we have \textcolor{blue}{equipotential surfaces} as the boundaries of $R$.}
\paragraph{3. Suppose we can replace those equipotential surfaces by placing one or more imaginary charges \textcolor{blue}{outside} $R$, so that the total potential $V$ due to the imaginary charges outside $R$ \textcolor{blue}{plus} any charges inside $R$ generates all those equipotential surfaces.}
\paragraph{4. Then the potential $V$ from all those real and imaginary charges is the unique solution for the potential $V$ in $R$.}
\subsubsection{The classic example of \textcolor{blue}{the method of images}: a point charge near infinite grounded conducting plane}
\paragraph{1. \textcolor{blue}{A point charge $+q$ on the z-axis is a distance of $d$ away from an infinite grounded conducting plane. What is the electric potential $V(x,y,z$) in the semi-infinite region $R$ in which the charge is located?}}
\paragraph{2. Here is what we know immediately:}
\paragraph{\indent a. This is a Poisson's equation problem.}
\paragraph{\indent b. The problem is symmetric about the z-axis, so $V(x,y,z)$ must be, too.}
\paragraph{\indent c. Since the xy-plane is a conductor, the electric field in $R$ must be perpendicular to the plane at the plane.}
\paragraph{\indent \indent i. At $z=0, V(x,y,0)=0$.}
\paragraph{\indent \indent ii. At $z>>d, V(x,y,z>>d)=0$.}
\paragraph{3. Since this is a Poisson's equation problem, we're not surprised that we're not even sure how to begin finding the electric potential from $\nabla^2V$}
\paragraph{4. It's time to be clever.}
\paragraph{\indent a. Remember: We do not care what happens outside $R$.}
\paragraph{\indent b. The field $\boldsymbol{E}$ in $R$ looks like half of an electric dipole.}
\paragraph{\indent c. Suppose we put a \textcolor{blue}{mirror image} negative charge $-q$ at $z=(0,0,-d)$ below the xy-plane?}
\paragraph{\indent d. The electric potential $V(x,y,z)$ in $R$ for this charge assembly would be the sum from the two point charges:}
\begin{equation*}
    \textcolor{blue}{V=\frac{1}{4\pi\epsilon_0}\bigg\{ \frac{q}{\sqrt{x^2+y^2+(z-d)^2}}+\frac{-q}{\sqrt{x^2+y^2+(z+d)^2}}\bigg\} }
\end{equation*}
\paragraph{\indent e. Well, what about our boundary conditions? The boundary conditions for $S$ on $R$ are:}
\paragraph{\indent \indent i. At $z=0, V(x,y,0)=0$}
\paragraph{\indent \indent ii. At $z>>d, V(x,y,z>>d)=0$}
\paragraph{\indent f. But the Uniqueness Theorem says: If this $V(x,y,z)$ meets the boundary conditions for $S$ on $R$, this is the only solution!}
\paragraph{\textcolor{purple}{Since we now have the electric potential $V$ for the region $R$, we can calculate all the sorts of things we usually do with the electric potential \textbf{as long as we only calculate those things in $R$}. For example, we can calculate the charge distribution on the plane, the electric field in $R$, the force on the charge $+q$ the energy of the fields, etc. \textbf{but only in} $R$.}}
\paragraph{5. What surface charge distribution $\sigma(x,y,0)$ is induced on the plane?}
\begin{equation*}
    \sigma(x,y,0)=-\epsilon_0\frac{\partial V}{\partial n}\bigg]_{z=0}=-\epsilon_0\frac{\partial V}{\partial z}\bigg]_{z=0}=\frac{1}{2\pi}\bigg\{ \frac{-qd}{(x^2+y^2+d^2)^\frac{3}{2}}\bigg\}
\end{equation*}
\paragraph{\indent a. The surface charge density $\sigma$ is constant about the z-axis for rings on the xy-plane (i.e., where $s=\sqrt{x^2+y^2}$). This, of course, is due to the cylindrical symmetry of the problem. We can write}
\begin{equation*}
    \sigma(s,z=0)=\frac{1}{2\pi}\bigg\{ \frac{-qd}{(s^2+d^2)^{\frac{3}{2}}} \bigg\} \quad:\quad s=\sqrt{x^2+y^2}
\end{equation*}
\paragraph{\indent b. What is the total charge induced on the grounded conducting plane? Lets integrate all rings of charge from $s=0$ to $s=\infty$}
\begin{equation*}
    Q=\int_0^{\infty}\sigma\cdot 2\pi s\quad ds=2\pi\int_0^{\infty}s\quad ds\cdot \frac{1}{2\pi}\bigg\{ \frac{-qd}{(s^2+d^2)^{\frac{3}{2}}}\bigg\} =\frac{qd}{(s^2+d^2)^{\frac{1}{2}}}\bigg]_0^{\infty}=-q
\end{equation*}
\paragraph{\textcolor{purple}{This makes sense, too. Outside $R$, we expect no field because the grounded onductor should shield the region outside $R$ from $q$.}}
\paragraph{6. The electric field in $R$ will be $\boldsymbol{E}=-\nabla V$. At $(x,y,d)$ where the charge $q$ is, evidently the electric field will be equivalent to the electric field produced by the image charge $-q$:}
\begin{equation*}
    \boldsymbol{E}=-\frac{1}{4\pi \epsilon_0}\frac{1}{(2d)^2}\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{The force on the charge $q$ in $R$ thus will be}
\begin{equation*}
    \boldsymbol{F}=q\boldsymbol{E}=-\frac{1}{4\pi\epsilon_0}\frac{q^2}{4d^2}\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{7. What about the energy $W$ of this charge-plus-grounded-conducting-plane system?}
\paragraph{For a \textcolor{blue}{real} dipole assembly, we would have}
\begin{equation*}
    W=qV_{-q}=q\cdot\frac{1}{4\pi\epsilon_0}\frac{(-q)}{2d}=-\frac{q^2}{8\pi\epsilon_0d}
\end{equation*}
\paragraph{\textcolor{blue}{But this isn't our situation:} This $W$ includes the electric field outside $R$-the "bottom half" of the universe. We can really only talk about $R$, so the correct answer is half this.}
\begin{equation*}
    W=-\frac{q^2}{16\pi\epsilon_0d}
\end{equation*}
\paragraph{8. Let's reprise the recipe for the \textcolor{blue}{method of images}}
\paragraph{\indent \textcolor{red}{1. We had} one charge in $R$ and we wanted to find $V$.}
\paragraph{\indent \textcolor{red}{2. We had} \textcolor{blue}{equipotential surfaces} as the boundaries of $R$.}
\paragraph{\indent \textcolor{red}{3. We replaced} those equipotential surfaces by placing one charge \textcolor{blue}{outside} the region $R$, so that the total potential $V$ due to imaginary charges outside $R$ \textcolor{blue}{plus} any charges inside $R$ generates all those equipotential surfaces.}
\paragraph{\indent 4. Then the potential $V$ from all those real and imaginary charges is the only possible solution for the potential $V$ in $R$.}
\paragraph{\textcolor{red}{We did all this without having to solve Poisson's equation!}}
\paragraph{That's what I mean by clever.}
\paragraph{Notice that we were very careful to distinguish between the \textcolor{blue}{real charges} and \textcolor{blue}{imaginary charges}, and to \textcolor{blue}{only do calculations with} $V$ \textcolor{blue}{while in the region of interest} $R$.}
\subsection{Separation of Variables}
\paragraph{\textcolor{purple}{Prelude}}
\paragraph{We want to find a potential $V$ in a region where the charge density $\rho$ is zero. In such cases, we are solving \textcolor{blue}{Laplace's equation} in a particular coordinate system.}
\begin{equation*}
    \text{Cartesian Coordinates} \quad \nabla^2V=\frac{\partial^2 V}{\partial x^2}+\frac{\partial^2 V}{\partial y^2}+\frac{\partial^2 V}{\partial z^2}=0
\end{equation*}
\begin{equation*}
    \text{Cylindrical Coordinates}\quad \nabla^2V=\frac{1}{s}\frac{\partial}{\partial s}\bigg(s\frac{\partial V}{\partial s}\bigg)+\frac{1}{s^2}\frac{\partial^2 V}{\partial \phi^2}+\frac{\partial^2V}{\partial z^2}
\end{equation*}
\begin{equation*}
    \text{Spherical Coordinates}\quad \nabla^2V=\frac{1}{r^2}\frac{\partial}{\partial r}\bigg(r^2\frac{\partial V}{\partial r}\bigg) +\frac{1}{r^2\sin\theta}\frac{\partial}{\partial r}\bigg( \sin\theta\frac{\partial V}{\partial \theta}\bigg)+\frac{1}{r^2\sin^2\theta}\frac{\partial^2V}{\partial\phi^2}
\end{equation*}
\paragraph{In the \textcolor{blue}{method of separation of variables}, the ansatz (educated guess) for the potential is always a product of functions, each involving only one coordinate.}
\begin{align*}
    \text{Cartesian Coordinates}\quad V(x,y,z)&=X(x)Y(y)Z(z)\\
    \text{Cylindrical Coordinates}\quad V(s,\phi,z)&=S(s)\Phi(\phi)Z(z)\\
    \text{Spherical Coordinates}\quad V(r,\theta,\phi)&=R(r)\Theta(\theta)\Phi(\phi)
\end{align*}
\subsubsection{Cartesian Coordinates}
\paragraph{1. Laplace's equation for $V$ in Cartesian Coordinates is}
\begin{equation*}
\nabla^2V=\frac{\partial^2 V}{\partial x^2}+\frac{\partial^2 V}{\partial y^2}+\frac{\partial^2 V}{\partial z^2}=0
\end{equation*}
\paragraph{\indent a. The uniqueness theorems require that we provide boundary conditions for $S$ enclosing $R$. Most commonly, we have:}
\paragraph{\indent i. \textcolor{blue}{Dirichlet boundary conditions}: Provide $V$ everywhere on $S$.}
\paragraph{\indent ii. \textcolor{blue}{Neumann boundary conditions}: Provide the derivative of $V$ everywhere on $S$.}
\paragraph{\indent b. Remember: No charge density in the region of interest $R$.}
\paragraph{2. We assume a solution $V(x,y,z)=X(x)Y(y)Z(z)$}
\paragraph{\indent a. This ansatz separates the coordinate dependencies for $V$ into separate functions for each coordinate.}
\paragraph{\indent b. If the symmetries of the problem indicate no dependence for a particular coordinate, then the function for that coordinate is a constant - might as well call it 1.}
\paragraph{\indent c. The reason we try this ansatz is that if this works - great! We're done! If not, we'll have to try something else.}
\paragraph{3. If our problem appears to have symmetries such that we expect the potential is most efficiently expressed in the coordinates $x,y,z$, then we start with the Laplacian in Cartesian coordinates for $V(x,y,z)$:}
\begin{equation*}
    \nabla^2V=\frac{\partial^2 V}{\partial x^2}+\frac{\partial^2 V}{\partial y^2}+\frac{\partial^2 V}{\partial z^2}=0
\end{equation*}
\paragraph{We now assume the ansatz \textcolor{blue}{$V(x,y,z)=X(x)Y(y)Z(z)$.}}
\paragraph{Substitution of this ansatz in the Laplacian gives}
\begin{equation*}
    \nabla^2V=Y(y)Z(z)\frac{\partial^2X(x)}{\partial x^2}+X(x)Z(z)\frac{\partial^2Y(y)}{\partial y^2}+X(x)Y(y)\frac{\partial^2Z(z)}{\partial z^2}=0
\end{equation*}
\paragraph{Dividing by $V(x,y,z)=X(x)Y(y)Z(z)=XYZ$, we get}
\begin{equation*}
    \textcolor{red}{\frac{1}{X(x)}\frac{\partial^2X(x)}{\partial x^2}+\frac{1}{Y(y)}\frac{\partial^2Y(y)}{\partial y^2}+\frac{1}{Z(z)}\frac{\partial^2Z(z)}{\partial z^2}=0}
\end{equation*}
\paragraph{\indent a. Each term on the left-hand side depends on a single coordinate.}
\paragraph{\indent b. Thus, since the other two terms don't change when we vary a single coordinate, then \textcolor{blue}{each} of the terms on the left hand side must be equal to a constant, and the sum of those three constants is zero.} 
\paragraph{\indent c. Since each term depends on only a single variable and each of those terms is a constant, substituting this ansatz into our original \textcolor{blue}{single three-dimensional second-order} \textcolor{red}{partial} \textcolor{blue}{differential equation} has given us \textcolor{blue}{three separate (and separated) second-order} \textcolor{red}{ordinary} \textcolor{blue}{differential equations}}
\begin{equation*}
    \frac{1}{X(x)}\frac{\partial^2X(x)}{\partial x^2}=c_x^2 \quad:\quad \frac{1}{Y(y)}\frac{\partial^2Y(y)}{\partial y^2}=c_y^2\quad:\quad \frac{1}{Z(z)}\frac{\partial^2Z(z)}{\partial z^2}=c_z^2
\end{equation*}
\paragraph{\textcolor{purple}{The constants $c_x,c_y,c_z$ are called separation constants}}
\paragraph{\indent d. Since the sum of the constants equal zero, unless all three are zero, \textcolor{blue}{at least one must be positive} and \textcolor{blue}{at least one must be negative}. With the constraint that the sum must be zero, one of the constants is equal to the sum of the other two, so their are really \textcolor{blue}{only two constants} to deal with.}
\paragraph{\indent i. Each of these ODE's for a particular Cartesian Coordinate $w$ looks like}
\begin{equation*}
    \frac{1}{W(w)}\frac{d^2W(w)}{dw^2}=c_w^2\longrightarrow \frac{d^2W(w)}{dw^2}=c_w^2W(w)
\end{equation*}
\paragraph{\indent ii. If \textcolor{blue}{$c_w^2>0$} i.e., positive, we have \textcolor{blue}{hyperbolic trigonometric solutions}:}
\begin{equation*}
    W(w)=Ae^{c_ww}+Be^{-c_ww}=a\sinh c_w w+b\cosh c_w w
\end{equation*}
\paragraph{\indent iii. If \textcolor{blue}{$c_w^2<0$} i.e., negative, we have \textcolor{blue}{regular trigonometric solutions}}
\begin{equation*}
    W(w)=Ce^{ic_ww}+De^{-ic_ww}=c\sin c_ww+d\cos c_ww
\end{equation*}
\paragraph{These regular trigonometric solutions are called \textcolor{blue}{harmonic functions} because these solutions are periodic on $w$ with $c_ww=n\pi$}
\paragraph{\indent e. From earlier courses, you know the set of sine and cosine functions $\sin kw$ and $\cos kw$ (where k=1,2,3$\dots$) is a complete set of orthogonal functions:}
\paragraph{\indent i. By the term \textcolor{blue}{orthogonal}, we mean that these functions behave as}
\begin{equation*}
    \int_0^{\pi} \sin kw \sin lw \quad dw=\frac{\pi}{2}\delta_{kl}\quad:\quad k,l \quad \text{are integers}
\end{equation*}
\begin{equation*}
    \int_0^{\pi} \cos{kw}\cos{lw}\quad dw=\frac{\pi}{2}\delta_{mn}\quad:\quad k,l \quad \text{are integers}
\end{equation*}
\begin{equation*}
    \delta_{kl}=\begin{cases}
        0 &: k\neq l \\
        1 &: k=l\\
    \end{cases}
\end{equation*}
\paragraph{\indent ii. By \textcolor{blue}{complete}, we mean we can write any function on the interval $0\leq w\leq l$ as an infinite (Fourier) series}
\begin{equation*}
    f(w)=\sum_{j=1}^{\infty}\bigg\{ C_j\sin \frac{j\pi w}{L}+D_j\cos\frac{j\pi w}{L}\bigg\} \quad \text{where,}
\end{equation*}
\begin{equation*}
    C_j=\frac{2}{L}\int_0^L f(w)\sin\frac{j\pi w}{L}dw
\end{equation*}
\begin{equation*}
    D_j=\frac{2}{L}\int_0^L f(w)\cos\frac{j\pi w}{L}dw
\end{equation*} 
\paragraph{4. So our strategy will look like this:}
\paragraph{\indent STEP 1. Make sure there are \textcolor{blue}{no charges in the region} of interest $R$.}
\paragraph{\indent STEP 2. \textcolor{blue}{Determine the boundary conditions for $S$} enclosing $R$. (For example, Dirichlet boundary conditions require that we specify $V$ \textcolor{blue}{everywhere} on $S$.)}
\paragraph{\indent STEP 3. \textcolor{blue}{Determine what symmetries exist} in the problem and use the appropriate coordinate system: rectangular (Cartesian), cylindrical, or spherical symmetry. Note if any coordinate can be eliminated and how the remaining separation constants relate to each other.}
\paragraph{\indent STEP 4. \textcolor{blue}{Identify the coordinate(s) with periodic boundary conditions}, and plan to use trigonometric solutions as the functional dependence for that coordinate(s). (i.e., we will set $c_w^2<0$ for that coordinate.)}
\paragraph{\indent STEP 5. Applying the periodic boundary conditions, \textcolor{blue}{use the orthogonality of the harmonic functions to determine the coefficients} (and any even/odd restrictions for terms) in the Fourier expansion of the functional dependence for the periodic coordinate(s).}
\subsubsection{Spherical Coordinates}
\paragraph{1. For problems that have spherical symmetry, the Laplacian in spherical coordinates is}
\begin{equation*}
    \textcolor{red}{\nabla^2V=\frac{1}{r^2}\frac{\partial}{\partial r}\bigg(r^2\frac{\partial V}{\partial r}\bigg) + \frac{1}{r^2\sin\theta}\frac{\partial}{\partial \theta}\bigg(\sin\theta\frac{\partial V}{\partial\theta}\bigg)+\frac{1}{r^2\sin^2\theta}\frac{\partial^2V}{\partial \phi^2}=0}
\end{equation*}
\paragraph{2. Using separation of variables, we might assume a solution like}
\begin{equation*}
    V(r,\theta,\phi)=R(r)\Theta(\theta)\Phi(\phi)
\end{equation*}
\paragraph{3. Suppose the problem is symmetric in $\phi$ (i.e., azimuthal symmetry)}
\paragraph{\indent a. Then the $\Phi(\phi)$ solution is a constant. Let's pick $\Phi(\phi)=1$.}
\paragraph{\indent b. The $\phi$ term in the Laplacian is then just zero.}
\paragraph{\indent c. This means that the solution for the electric potential $V(r,\theta,\phi)$ will be $V(r,\theta)=R(r)\Theta(\theta)$.}
\paragraph{4. Using $V(r,\theta)=R(r)\Theta(\theta)$ in Laplace's equation (and dividing by $V$) leads to:}
\begin{equation*}
    \frac{1}{R(r)\Theta(\theta)}\cdot\nabla^2V=\frac{1}{R(r)}\frac{d}{dr}\bigg(r^2\frac{dR(r)}{dr}\bigg)+\frac{1}{\Theta(\theta)}\frac{1}{\sin\theta}\frac{d}{d\theta}\bigg(\sin \theta \frac{d\Theta(\theta)}{d\theta}\bigg)=0
\end{equation*}
\paragraph{\indent a. As in Cartesian Coordinates, our variables are now separated.}
\paragraph{\indent\indent i. Each term of the Laplacian must be equal to a constant.}
\paragraph{\indent\indent ii. The sum of these two constants is zero, so one term is the positive value of that constant and the other the negative of that constant.}
\paragraph{\indent\indent iii. We know that \textcolor{blue}{the $\Theta(\theta)$ solution must be periodic} because the angle $\theta$ can only go from 0 to $\pi$.}
\paragraph{\indent \indent $\cdot$ Our solution hunt is easier than in the case of Cartesian coordinates, where we had to figure out which coordinate was periodic.}
\paragraph{\indent \indent $\cdot$ Since the $\theta$ coordinate is periodic, then we expect that we can always use separation of variables in spherical coordinates. (It may not always be an efficient approach, and we still have to worry about uniqueness requirements.)}
\begin{equation*}
    \nabla^2V=\frac{1}{R(r)}\frac{d}{dr}\bigg(r^2\frac{dR(r)}{dr}\bigg)+ \frac{1}{\Theta(\theta)}\frac{1}{\sin\theta}\frac{d}{d\theta}\bigg(\sin\theta\frac{d\Theta(\theta)}{d\theta}\bigg)=0
\end{equation*}
\paragraph{\indent b. The Radial solution \textcolor{blue}{$R(r)$}}
\paragraph{\indent\indent i. Perhaps the simplest solution for the r dependence for \textcolor{blue}{$V(r,\theta)$} would be a power series for \textcolor{blue}{$R(r):R(r)\approx r^k$}}
\paragraph{\indent\indent ii. Substitution of this solution into the radial portion of the Laplacian, we would take two derivatives in $r$. So we would wind up with something like $\textcolor{blue}{k(k-1)R(r)}$.}
\paragraph{\indent\indent iii. In the end, it will be simpler to define a new index $\textcolor{blue}{l}$ for our power series \textcolor{blue}{$k=l+1$}. With that definition, we'd get \textcolor{blue}{$l(l+1)R(r)$}.}
\paragraph{\indent\indent iv. Substitution then gives}
\begin{equation*}
    \textcolor{blue}{\frac{d}{dr}\bigg(r^2\frac{dR(r)}{dr}\bigg)=l(l+1)R(r)}
\end{equation*}
\paragraph{\indent\indent v. With this identification, our power series $r$ solution would be}
\begin{equation*}
    R(r)=\sum_{l=0}^{\infty}\bigg(A_lr^l+\frac{B_l}{r^{l+1}}\bigg)
\end{equation*}
\paragraph{\indent c. The angular solution \textcolor{blue}{$\Theta(\theta)$}}
\paragraph{\indent\indent i. Using the previous power-series solution for \textcolor{blue}{$R(r)$}, Laplace's equation becomes}
\begin{equation*}
    \textcolor{blue}{\frac{d}{d\theta}\bigg(\sin\theta\frac{d\Theta(\theta)}{d\theta}\bigg)=-l(l+1)\sin\theta\cdot\Theta(\theta)}
\end{equation*}
\paragraph{\indent\indent ii. The solutions to the angular equation are \textcolor{blue}{the Legendre Polynomials}: \textcolor{blue}{$\Theta(\theta)=P_l(\cos\theta)$}.}
\paragraph{\indent\indent $\cdot$ The \textcolor{blue}{$P_l(\cos\theta)$} are a \textcolor{blue}{complete} set of \textcolor{blue}{orthogonal} harmonic functions}
\paragraph{\indent\indent $\cdot$ By "complete", we mean we can write for any function \textcolor{blue}{$\Theta(\theta)$}}
\begin{equation*}
    \textcolor{blue}{\Theta(\theta)=\sum_{l=0}^{\infty}C_lP_l(\cos\theta)}
\end{equation*}
\paragraph{\indent\indent $\cdot$ By orthogonal, we mean}
\begin{equation*}
    \textcolor{blue}{\int_0^{\pi}P_l(\cos\theta)P_m(\cos\theta)d(\cos\theta)=\begin{cases}
        0 &: \text{if}\quad l\neq m \\
        \frac{2}{2l+1} &:  \text{if}\quad l=m\\
    \end{cases}}
\end{equation*}
\paragraph{5. Putting all the pieces together and combining products of constants, when we have spherical and azimuthal symmetry, the general solution for the electric potential where Laplace's equation is valid will be}
\begin{equation*}
    \textcolor{blue}{V(r,\theta)=\sum_{l=0}^{\infty}\bigg(A_lr^l+\frac{B_l}{r^{l+1}}\bigg)P_l(\cos\theta)}
\end{equation*}
\paragraph{\indent This will \textcolor{blue}{always} be the solution for azimuthally-symmetric problems.}
\paragraph{6. For the record, what if we do \textcolor{blue}{not} have azimuthal symmetry?}
\paragraph{\indent a. Following the separation of variables approach, we isolate the azimuthal dependence in the Laplacian's azimuthal term as}
\begin{equation*}
    \frac{1}{\Phi(\varphi)}\frac{\partial^2\Phi(\varphi)}{\partial\varphi^2}=-m^2\rightarrow \Phi(\varphi)=e^{\pm im\varphi}
\end{equation*}
\paragraph{\indent b. The solutions to the full angular portion \textcolor{blue}{$\Theta(\theta)\Phi(\varphi)$} of the Laplacian are the spherical harmonics \textcolor{blue}{$Y_l^m=\Theta(\theta)\Phi(\varphi)$}:}
\begin{equation*}
    \textcolor{blue}{\Theta(\theta)\Phi(\varphi)=Y_l^m(\theta,\phi)=N_{lm}e^{im\varphi}P_l(\cos\theta)}
\end{equation*}
\paragraph{where $N_{lm}$ is a normalizing factor.}
\paragraph{7. In cases where we have spherical and azimuthal symmetry, we actually have much the same strategy as before for confronting and solving problems where we want to find the electric potential in a region using Laplace's equation:}
\paragraph{STEP 1. Make sure there are \textcolor{blue}{no charges in the region} of interest $R$.}
\paragraph{STEP 2. \textcolor{blue}{Determine the boundary conditions for $S$} enclosing $R$. (For example, Dirichlet boundary conditions require that we specify $V$ \textcolor{blue}{everywhere} on $S$.)}
\paragraph{STEP 3. \textcolor{blue}{Determine what symmetries exist} in the problem and use the appropriate coordinate system.}
\paragraph{STEP 4. \textcolor{blue}{Identify the coordinate(s) with periodic boundary conditions}. With spherical symmetry, that's already fixed for you: The angular dependence is periodic, so the potential will automatically be periodic in angle.}
\paragraph{STEP 5. Applying the boundary conditions, \textcolor{blue}{use the orthogonality of the harmonic functions to determine the coefficients} (and any even/odd restrictions for terms).}
\subsection{The multipole expansion of the electrostatic potential $V$}
\subsubsection{Azimuthally-symmetric distributions:$\rho=\rho(r',\theta')$}
\paragraph{1. As usual, we will be using primed coordinates to indicate source points, and unprimed coordinates to indicate field points.}
\paragraph{\indent a. The coordinates of a small infinitesimal element of our charge distribution $dQ'=\rho(r',\theta')d\tau'$ will be $(r',\theta', \phi')$.}
\paragraph{\indent b. The coordinates of any field point at which we want to know the potential will be $P=(r,\theta,\phi)$.}
\paragraph{\indent c. The magnitude of the separation between $dQ'$ and $P$ is $\mathfrak{r}=|\boldsymbol{r}-\boldsymbol{r'}|$}
\paragraph{2. Suppose we have a finite, azimuthally-symmetric charge distribution \textcolor{blue}{$\rho=\rho(r',\theta')$}.}
\paragraph{\indent a. Let the maximum value of $r'$ for any non-zero piece of \textcolor{blue}{$\rho(r',\theta')$} be $R_{max}$. For all $P$, we demand $r>R_{max}$; (i.e., we are always and absolutely outside the entire distribution).}
\paragraph{\indent b. The contribution $dV$ to the potential from an infinitesimal element \textcolor{blue}{$dQ'=\rho(r',\theta')d\tau'$} of the distribution is}
\begin{equation*}
    dV=\frac{1}{4\pi\epsilon_0}\frac{\textcolor{blue}{dQ'}}{\mathfrak{r}}\quad:\quad \mathfrak{r}=|\boldsymbol{r}-\boldsymbol{r'}|\quad \text{and}\quad k=\frac{1}{4\pi\epsilon_0}
\end{equation*}
\begin{equation*}
    dV=k\frac{\textcolor{blue}{\rho(r',\theta')d\tau'}}{\mathfrak{r}}
\end{equation*}
\begin{equation*}
    dV=k\frac{\textcolor{blue}{\rho(r',\theta')}}{\mathfrak{r}}\cdot\textcolor{blue}{r'^2\sin\theta'dr'd\theta'd\phi'}
\end{equation*}
\paragraph{3. The factor $\mathfrak{r}^{-1}$ can be written as a power series (the 1/r expansion):}
\begin{equation*}
    \frac{1}{\mathfrak{r}}=\frac{1}{r}\cdot\sum_{n=0}^{\infty}\bigg(\frac{\textcolor{blue}{r'}}{r}\bigg)^n\cdot \textcolor{blue}{P_n(\cos\theta')}\cdot P_n(\cos\theta) \quad:\quad r>R_{max}
\end{equation*}
\paragraph{\indent a. Thus, the infinitesimal contribution for each $dQ$ becomes (with $r>R_{max}$)}
\begin{equation*}
    dV=\frac{k}{r}\times\sum_{n=0}^{\infty}P_n(\cos\theta)\cdot\bigg(\frac{\textcolor{blue}{r'}}{r}\bigg)^n\textcolor{blue}{P_n(\cos\theta')\rho(r',\theta')\cdot r'^2\sin\theta'dr'd\theta'd\phi'}
\end{equation*}
\paragraph{\indent b. Let's separate source coordinate and field point pieces:}
\begin{equation*}
    dV=\frac{k}{r}\times\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot\textcolor{blue}{r'^nP_n(\cos\theta')\rho(r',\theta')\cdot r'^2\sin\theta'dr'd\theta'd\phi'}
\end{equation*}
\paragraph{4. The full potential $V(r,\theta,\phi)$ with $r>R_{max}$ is the integral over the entire charge distribution Q:}
\begin{equation*}
V=\int_QdV=\frac{k}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n} \textcolor{blue}{\Bigg\{ \int_Qr'^nP_n(\cos\theta')\rho(r',\theta')\cdot r'^2\sin\theta'dr'd\theta'd\phi'\bigg\}}
\end{equation*}
\paragraph{The \textcolor{blue}{quantity in braces} is \textcolor{blue}{$Q_n$}, the "$2^n$ multipole moment of the charge distribution":}
\begin{equation*}
    \textcolor{blue}{Q_n\equiv\int_Qr'^nP_n(\cos\theta')}\textcolor{red}{\rho(r',\theta')r'^2\sin\theta'dr'd\theta'd\phi'}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{Q_n\equiv\int_Qr'^nP_n(\cos\theta')}\cdot\textcolor{red}{dQ}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{Q_0=\int_Qr'^0P_0(\cos\theta')}\cdot\textcolor{red}{dQ}=\textcolor{blue}{\int_Q 1\cdot 1}\cdot\textcolor{red}{dQ}=\textcolor{blue}{Q} \quad:\quad \text{(Monopole moment, net charge)}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{Q_1=\int_Qr'^1P_1(\cos\theta')}\cdot\textcolor{red}{dQ}\quad :\quad \text{(dipole moment)}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{Q_2=\int_Qr'^2P_2(\cos\theta')}\cdot\textcolor{red}{dQ}\quad:\quad \text{(quadrupole moment)}
\end{equation*}
\paragraph{5. With that definition, the full potential $V(r\theta,\phi)$ is}
\begin{equation*}
    V(r,\theta,\phi)=\frac{k}{r}\sum_{n=0}^{\infty} \frac{P_n(\cos\theta)}{r^n}\textcolor{blue}{Q_n} \quad:\quad \textcolor{blue}{Q_n=\int_Qr'^nP_n(\cos\theta')\cdot dQ}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{k}{r}\bigg\{ \frac{\textcolor{blue}{Q_0}}{r^0}P_0(\cos\theta)+\frac{\textcolor{blue}{Q_1}}{r^1}P_1(\cos\theta)+\frac{\textcolor{blue}{Q_2}}{r^2}P_2(\cos\theta)+\dots\bigg\}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0 r}\bigg\{ \textcolor{blue}{Q}+\frac{\textcolor{blue}{Q_1}}{r}(\cos\theta)+\frac{\textcolor{blue}{Q_2}}{r^2}\bigg(\frac{3}{2}\cos^2\theta-\frac{1}{2}\bigg)+\dots\bigg\}
\end{equation*}
\paragraph{6. At very large distances (i.e., $r>>R_{max}$) from the distribution, this multipole expansion will be dominated by the leading term of the series}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0 r}\bigg\{ \frac{\textcolor{blue}{Q_0}}{r^0}P_0(\cos\theta)+\frac{\textcolor{blue}{Q_1}}{r^1}P_1(\cos\theta)+\frac{\textcolor{blue}{Q_2}}{r^2}P_2(\cos\theta)+\dots\bigg\}
\end{equation*}
\paragraph{\indent a. If the net total charge in the charge distribution \textcolor{blue}{$Q=Q_0$} is non-zero, the leading term of the multipole expansion of the potential for large distances (i.e., for $r>>R_{max}$ will be}
\begin{equation*}
    V(r,\theta,\phi)\equiv \frac{\textcolor{blue}{Q_0}}{4\pi\epsilon_0 r}=\frac{Q}{4\pi\epsilon_0 r}
\end{equation*}
\paragraph{\indent b. If \textcolor{blue}{$Q=Q_0=0$}, then the leading term of the multipole expansion of the potential for large distances (i.e., for $r>>R_{max}$) is the electric dipole term}
\begin{equation*}
    V(r,\theta,\phi)\equiv\frac{\textcolor{blue}{Q_1}}{4\pi\epsilon_0 r}(\cos\theta)
\end{equation*}
\paragraph{unless \textcolor{blue}{$Q_1$} vanishes.}
\paragraph{\indent c. If both \textcolor{blue}{$Q_0$} and \textcolor{blue}{$Q_1$} vanish, then the next non-vanishing term becomes the dominate term for $r>>R_{max}$.}
\subsubsection{Examples}
\paragraph{Our procedure for finding the multipole expansion for the electric potential for an azimuthally-symmetric charge distribution is}
\paragraph{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r'})$}
\paragraph{STEP 2. Determine the value of $R_{max}$}
\paragraph{STEP 3. Define an element of the charge distribution $dQ=\rho(\boldsymbol{r'})d\tau'$}
\paragraph{STEP 4. Using $dQ$ the expression for the electric multipole moments in $Q_n$}
\begin{equation*}
    Q_n=\int_Q r'^nP_n(\cos\theta')\cdot dQ
\end{equation*}
\paragraph{integrate over the entire charge distribution to find the multipole moments.}
\paragraph{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential}
\begin{equation*}
    V(r, \theta, \phi)=\frac{1}{4\pi \epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos \theta')}{r^n}\cdot Q_n \quad :\quad r>R_{max}
\end{equation*}
\paragraph{STEP 6. Write the first few non-vanishing terms.}
\paragraph{\textcolor{blue}{Example 1. - A charge distribution consists of a point charge $+q$ located at the origin. Find the multipole expansion of the potential and provide the first few non-zero terms.}}
\paragraph{\textcolor{red}{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r}')$.}}
\paragraph{\indent Our charge is located at $\boldsymbol{r}'=0$. Thus, the charge distribution is simply}
\begin{equation*}
    \rho(r',\theta')=+q\delta^3(\boldsymbol{r'-r})\cdot 1=q\delta^3(\boldsymbol{r}')P_0(\cos\theta')
\end{equation*}
\paragraph{\textcolor{red}{STEP 2. Determine $R_{max}$}}
\paragraph{\indent Since we have a point charge, then $R_{max}=0$.}
\paragraph{\textcolor{red}{STEP 3. Write the expression for an element of the charge distribution $dQ$}}
\paragraph{\indent The element of the charge distribution would be }
\begin{align*}
    dQ&=\rho(r',\theta')d\tau\\
    dQ&=\rho(r',\theta')r'^2\sin \theta'dr'd\theta'd\phi'\\
    dQ&=q\delta^3(\boldsymbol{r}')P_0(\cos\theta')r'^2\sin\theta' dr'd\theta'd\phi'
\end{align*}
\paragraph{\textcolor{red}{STEP 4. Using the expression for the electric multipole moments $Q_n$ integrate over the entire charge distribution to find the multipole moments.}}
\begin{equation*}
    Q_n=\int_Q r'^nP_n(cos\theta')\cdot dQ
\end{equation*}
\begin{equation*}
    Q_n=\int_Q r'^nP_n(\cos \theta')\cdot q\delta^3(\boldsymbol{r}')P_0(\cos\theta')r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\begin{equation*}
    Q_0=q\quad \text{and}\quad Q_{n>0}=0
\end{equation*}
\paragraph{\textcolor{red}{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential for $r>R_{max}$.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot Q_n\quad : \quad r>R_{max}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0r}\bigg\{ \frac{P_0(cos\theta)}{r^0}\cdot Q_0+\frac{P_1(\cos\theta)}{r^1}\cdot Q_1+\frac{P_2(\cos\theta)}{r^2}\cdot Q_2+\dots\bigg\}\quad : \quad r>0
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0r}\bigg\{ \frac{P_0(cos\theta)}{r^0}\cdot q+\frac{P_1(\cos\theta)}{r^1}\cdot \textcolor{red}{0}+\frac{P_2(\cos\theta)}{r^2}\cdot \textcolor{red}{0}+\dots\bigg\}\quad : \quad r>0
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0r}\frac{P_0(\cos\theta)}{r^0}\cdot q=\frac{1}{4\pi\epsilon_0}\cdot \frac{1}{1}\cdot q\quad :\quad r>0
\end{equation*}
\begin{equation*}
    V(r,\theta, \phi)=\frac{q}{4\pi\epsilon_0r}\quad:\quad r>0
\end{equation*}
\paragraph{\textcolor{red}{STEP 6. Write the first few non-vanishing terms.}}
\paragraph{\indent There is only one non-vanishing term:}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\quad:\quad r>0
\end{equation*}
\paragraph{\textcolor{blue}{Example 2. - A charge distribution consists of a charge $+q$ at $z=+\frac{d}{2}$ on the z-axis and another charge $-q$ located on the z-axis at $z=\frac{-d}{2}$. Find the multipole expansion of the potential, and provide the first few non-zero terms.}}
\paragraph{\textcolor{red}{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r})$.}}
\paragraph{\indent We have two pieces in our charge distribution:}
\begin{equation*}
    +q\quad\text{at}\quad \boldsymbol{r_1}'=(r'=\frac{d}{2},\theta'=0) \quad\text{and}\quad -q \quad\text{at}\quad \boldsymbol{r_2}'=(r'=\frac{-d}{2},\theta'=\pi)
\end{equation*}
\paragraph{\indent so we would write our charge distribution as}
\begin{equation*}
    \rho(r',\theta)=+q\delta^3(\boldsymbol{r_1}')+(-q)\delta^3(\boldsymbol{r_2}')=q(\delta^3(\boldsymbol{r_1}')-\delta^3(\boldsymbol{r_2}'))
\end{equation*}
\paragraph{\textcolor{red}{STEP 2. Determine $R_{max}$}}
\paragraph{\indent Based on the description given for our charge distribution, we must have $R_{max}=\frac{d}{2}$.}
\paragraph{\textcolor{red}{STEP 3. Write the expression for an element of the charge distribution $dQ$.}}
\paragraph{\indent The element of the charge distribution would be}
\begin{align*}
    dQ&=\rho(r',\theta')d\tau\\
    dQ&=\rho(r',\theta')r'^2\sin\theta'dr'd\theta'd\phi'\\
    dQ&=q(\delta^3(\boldsymbol{r_1}')-\delta^3(\boldsymbol{r_2}'))r'^2\sin\theta'dr'd\theta'd\phi'\\
\end{align*}
\paragraph{\textcolor{red}{STEP 4. Using the expression for the electric multipole moments $Q_n$ integrate over the entire charge distribution to find the multipole moments.}}
\begin{equation*}
    Q_n=\int_Q r'^n P_n (\cos\theta')\cdot dQ
\end{equation*}
\begin{equation*}
    Q_n=\int_Q r'^n P_n (\cos\theta')\cdot q(\delta^3(\boldsymbol{r_1}')-\delta^3(\boldsymbol{r_2}'))r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\begin{align*}
    Q_n=q\int_Qr'^n P_n (\cos\theta')\cdot (\delta^3(\boldsymbol{r_1}'))r'^2\sin\theta'dr'd\theta'd\phi'\\
    -q\int_Qr'^n P_n (\cos\theta')\cdot (\delta^3(\boldsymbol{r_2}'))r'^2\sin\theta'dr'd\theta'd\phi'
\end{align*}
\begin{equation*}
    Q_n=q\bigg(\frac{d}{2}\bigg)^n P_n(1)-q\bigg(\frac{d}{2}\bigg)^n P_n(-1)
\end{equation*}
\paragraph{\indent \textcolor{purple}{If $n$ is even: $P_n(\pm 1)=1$ and If $n$ is odd, $P_n(\pm 1)=\pm 1$}}
\begin{equation*}
    Q_n=\begin{cases}
    0\quad, & \text{:   n even}.\\
    \frac{qd^n}{2^{n-1}}\quad, & \text{:   n odd}.\\
    \end{cases}
\end{equation*}
\paragraph{\textcolor{red}{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential for $r>R_{max}$}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot Q_n\quad:\quad r>R_{max}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{q}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot\frac{d^n}{2^{n-1}}\quad:\quad r>\frac{d}{2}
\end{equation*}
\paragraph{\textcolor{red}{STEP 6. Write the first non-vanishing terms.}}
\begin{equation*}
    V(r,\theta, \phi)=\frac{q}{4\pi\epsilon_0r}\sum_{n=\text{odd}}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot\frac{d^n}{2^{n-1}}\quad:\quad r>\frac{d}{2}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\bigg\{ \frac{P_1(\cos\theta)}{r^1}\cdot d +\frac{P_3(\cos\theta)}{r^3}\cdot \frac{d^3}{4}+\frac{P_5(\cos\theta)}{r^5}\cdot \frac{d^5}{16}+\dots\bigg\}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\bigg\{ \frac{qd}{r^2}\cos\theta +\frac{qd^3}{4r^4}P_3(\cos\theta)+\frac{qd^5}{16r^6}P_5(\cos\theta)+\dots\bigg\}
\end{equation*}
\paragraph{\textcolor{blue}{Example 3. - A charge $+q$ is distributed as $\rho(r')=f(r')$ in a sphere of radius $a$. The sphere is centered on the origin. Find the multipole expansion of the potential, and provide the first few non-zero terms.}}
\paragraph{\textcolor{red}{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r}'$)}}
\paragraph{\indent This is a \underline{spherically symmetric} charge distribution. We will have to integrate the charge distribution $f(r')$ over the volume of the sphere. Anticipating that we will need some angular integration, we write the charge distribution as}
\begin{equation*}
    \rho(r',\theta)=f(r')\cdot 1=f(r')\textcolor{red}{P_0(\cos\theta')}
\end{equation*}
\paragraph{\textcolor{red}{STEP 2. Determine $R_{max}$}}
\paragraph{\indent Based on the description given for our charge distribution, we must have $R_{max}=a$.}
\paragraph{\textcolor{red}{STEP 3. Write the expression for an element of the charge distribution $dQ$.}}
\paragraph{\indent The element of the charge distribution would be}
\begin{equation*}
    dQ=\rho(r',\theta')d\tau'
\end{equation*}
\begin{equation*}
    dQ=f(r')\textcolor{red}{P_0(\cos\theta)}r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\paragraph{\textcolor{red}{STEP 4. Using the expression for the electric multipole moments $Q_n$ integrate over the entire charge distribution to find the multipole moments.}}
\begin{equation*}
    Q_n=\int_Q r'^n P_n (\cos\theta')\cdot dQ
\end{equation*}
\begin{equation*}
    Q_n=\int_Q r'^nP_n(\cos\theta')\cdot f(r')\textcolor{red}{P_0(\cos\theta')}r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\begin{equation*}
    Q_n=\int_0^a r'^2dr'\cdot r'^n f(r')\int_0^{2\pi}d\phi'\textcolor{red}{\int_0^{\pi} P_n(\cos\theta')\cdot P_0(\cos\theta')\sin\theta'd\theta'}
\end{equation*}
\paragraph{\indent Notice, the last integral can be written as a Kronecker Delta function by exploiting its orthogonality. It would reduce to}
\begin{equation*}
    \frac{2\delta_{n0}}{2n+1}
\end{equation*}
\paragraph{\indent Thus, leaving us the equation}
\begin{equation*}
    Q_{n=0}=\int_0^a 4\pi r'^2 r'^{n=0}f(r')=\int_0^a 4\pi r'^2dr'f(r')=q
\end{equation*}
\paragraph{\textcolor{red}{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential for $r>R_{max}$.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r} \quad:\quad r>a
\end{equation*}
\paragraph{\textcolor{red}{STEP 6. Write the first few non-vanishing terms.}}
\paragraph{\indent There is only one non-vanishing term:}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r} \quad:\quad r>a
\end{equation*}
\paragraph{\indent An important result: \textcolor{blue}{Once outside the entire charge distribution, the multipole moment expansion for any spherically symmetric charge distribution is}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}
\end{equation*}
\paragraph{\textcolor{blue}{Example 4. A charge $+q$ is uniformly distributed on an infinitesimally thin ring of radius $a$. The ring lies in the xy-plane centered on the origin. Find the multipole expansion of the potential, and provide the first few non-zero terms.}}
\paragraph{\textcolor{red}{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r}')$.}}
\paragraph{\indent Here the charge distribution has a single variable, since all the charge is at $r'=a$ and $\theta'=\frac{\pi}{2}$. We can write this simply as $\lambda\cdot a\cdot d\phi'$ where $\lambda=\frac{q}{2\pi a}$.}
\paragraph{\textcolor{red}{STEP 2. Determine $R_{max}$}}
\paragraph{\indent Based on the description given for our charge distribution, we must have $R_{max}=a$}
\paragraph{\textcolor{red}{STEP 3. Write the expression for an element of the charge distribution $dQ$.}}
\paragraph{\indent With $\theta'=\frac{\pi}{2}$, we have a single variable problem in $\phi'$:}
\begin{equation*}
    dQ=\lambda\cdot a \cdot d\phi' \quad:\quad \theta'=\frac{\pi}{2}
\end{equation*}
\paragraph{\textcolor{red}{STEP 4. Using the expression for the electric multipole moments $Q_n$ integrate over the entire charge distribution to find the multipole moments.}}
\begin{equation*}
    Q_n=\int_Q r'^n P_n(\cos\theta')\cdot dQ
\end{equation*}
\begin{equation*}
    Q_n=\int_Q a^nP_n(\cos\theta'=0)\cdot\lambda a d\phi'
\end{equation*}
\begin{equation*}
    Q_n=a^{n+1}P_n(0)\cdot2\pi\lambda
\end{equation*}
\begin{equation*}
    Q_n=qa^nP_n(0)
\end{equation*}
\paragraph{\textcolor{purple}{Note: If n is odd, $P_n(0)=0$}}
\begin{equation*}
    Q_n=\begin{cases}
        qa^nP_n(0), & \text{: n even}.\\
        \quad 0, & \text{: n odd}.\\
    \end{cases}
\end{equation*}
\paragraph{\textcolor{red}{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential for $r>R_{max}$.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\sum_{n=\text{even}}^{\infty} \frac{P_n(\cos\theta)}{r^n}\cdot a^nP_n(0)\quad:\quad r>a
\end{equation*}
\paragraph{\textcolor{red}{STEP 6. Write the first few non-vanishing terms.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\sum_{n=\text{even}}^{\infty} \frac{P_n(\cos\theta)}{r^n}\cdot a^nP_n(0)\quad:\quad r>a
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\cdot \bigg\{ \frac{P_0(\cos\theta)}{r^0}\cdot a^0P_0(0)+\frac{P_2(\cos\theta)}{r^2}\cdot a^2P_2(0)+\frac{P_4(\cos\theta)}{r^4}\cdot a^4P_4(0)+\dots\bigg\}
\end{equation*}
\begin{equation*}
     V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0r}\cdot \bigg\{ 1-\frac{1}{2}\bigg( \frac{a}{r}\bigg)^2P_2(\cos\theta)+\frac{3}{8}\bigg(\frac{a}{r}\bigg)^4P_4(\cos\theta)+\dots\bigg\}\quad:\quad r>a
\end{equation*}
\paragraph{\textcolor{blue}{Example 5. - A finite thin line of length 2a and charge $+q$ lies on the z-axis from $z=-a$ to $z=+a$. Find the multipole expansion of the potential, and provide the first few non-zero terms.}}
\paragraph{\textcolor{red}{STEP 1. Write an expression for the charge distribution $\rho(\boldsymbol{r}')$.}}
\paragraph{\indent We treat this as a two-piece charge distribution, one piece with $\theta'=0$ and the other with $\theta'=\pi$. But the charge distribution also is \textcolor{blue}{one-dimensional} along the z-axis, and for both pieces $\lambda=\frac{q}{2a}$.}
\paragraph{\textcolor{red}{STEP 2. Determine $R_{max}$.}}
\paragraph{\indent Based on the statement of the problem, $R_{max}=a$.}
\paragraph{\textcolor{red}{STEP 3. Write the expression for an element of the charge distribution $dQ$.}}
\begin{equation*}
    dQ_{upper}=\lambda dr'\quad :\quad 0\leq r'\leq a \quad, \quad \theta'=0
\end{equation*}
\begin{equation*}
    dQ_{lower}=\lambda dr'\quad :\quad 0\leq r' \leq a \quad, \quad \theta'=\pi
\end{equation*}
\paragraph{\textcolor{red}{STEP 4. Using the expression for the electric multipole moments $Q_n$, integrate over the entire charge distribution to find the multipole moments.}}
\begin{align*}
    Q_n&=\int_Q r'^nP_n(\cos\theta')\cdot dQ\\
    Q_n&=\int_{up}r'^n P_n(\cos\theta'=1)\cdot dQ_{upper} +\int_{low}r'^nP_n(\cos\theta'=-1)\cdot dQ_{lower}\\
    Q_n&=\int_0^a r'^nP_n(1)\cdot \lambda dr'+\int_0^a r'^nP_n(-1)\cdot \lambda dr'\\
    Q_n&=\frac{\lambda a^{n+1}}{n+1}\{P_n(1)+P_n(-1)\}
\end{align*}
\paragraph{\textcolor{purple}{Note: If n is even: $P_n(\pm 1)=1$ and If n is odd: $P_n(\pm 1)=\pm 1$}}
\begin{equation*}
    Q_n=\frac{2\lambda a^{n+1}}{n+1}\quad:\quad \text{n even}
\end{equation*}
\begin{equation*}
    Q_n=q\frac{a^n}{n+1}\quad:\quad \text{n even}
\end{equation*}
\paragraph{\textcolor{red}{STEP 5. Plug the expression(s) for the electric multipole moments into the multipole expansion series for the electric potential.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty} \frac{P_n(\cos\theta)}{r^n}\cdot Q_n \quad :\quad r>R_{max}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty} \frac{P_n(\cos\theta)}{r^n}\cdot q\frac{a^n}{n+1} \quad :\quad r>a \quad\text{and n even}
\end{equation*}
\paragraph{\textcolor{red}{STEP 6. Write the first few non-vanishing terms.}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty} \frac{P_n(\cos\theta)}{r^n}\cdot q\frac{a^n}{n+1} \quad :\quad r>a \quad\text{and n even}
\end{equation*}
\begin{equation*}
    V(r,\theta,\phi)=\frac{q}{4\pi\epsilon_0 r}\bigg\{ 1+\frac{1}{3}\bigg(\frac{a}{r}\bigg)^2P_2(\cos\theta)+\frac{1}{5}\bigg(\frac{a}{r}\bigg)^4P_4(\cos\theta)+\dots\bigg\} \quad:\quad r>a
\end{equation*}
\paragraph{\textcolor{purple}{Note: For more complex composite objects, we can always use the principle of superposition! This will allow us to tackle more difficult problems. }}
\subsubsection{The monopole and dipole moments of $V(r,\theta$)}
\paragraph{\textcolor{purple}{Reprise: We have developed a formalism for the multipole expansion of the electric potential $V(r,\theta$) for an azimuthally-symmetric charge distribution:}}
\begin{equation*}
    V(r,\theta)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot Q_n
\end{equation*}
\paragraph{where,}
\begin{equation*}
    Q_n\equiv\int_Q r'^nP_n(\cos\theta')\rho(r',\theta')r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\begin{equation*}
    V(r,\theta)=\frac{1}{4\pi\epsilon_0r}\bigg\{ \frac{Q_0}{r^0}P_0(\cos\theta)+\frac{Q_1}{r^1}P_1(\cos\theta)+\frac{Q_2}{r^2}P_2(\cos\theta)+\dots\bigg\}
\end{equation*}
\paragraph{\textcolor{purple}{For future reference, if there are no symmetries present in the charge distribution $\rho(r',\theta',\phi')$, the multipole expansion of $V(r,\theta,\phi)$ can be performed with the spherical harmonics $Y_{lm}(\theta,\phi)$:}}
\begin{equation*}
    V(r,\theta,\phi)=\frac{1}{4\pi\epsilon_0r}\sum_{l=0}^{\infty}\sum_{m=-l}^{l}\sqrt{\frac{4\pi}{2l+1}}\frac{Y_{lm}(\theta,\phi)}{r^l}\cdot Q_{lm}
\end{equation*}
\paragraph{where,}
\begin{equation*}
    Q_{lm}\equiv\int_Q r'^l\sqrt{\frac{4\pi}{2l+1}}Y_{lm}(\theta',\phi')\rho(r',\theta',\phi')r'^2\sin\theta'dr'd\theta'd\phi'
\end{equation*}
\subsubsection{The monopole and dipole moments of $V(r,\theta)$}
\begin{equation*}
    V(r,\theta)=\frac{1}{4\pi\epsilon_0}\frac{1}{r}\sum_{n=0}^{\infty}\frac{P_n(\cos\theta)}{r^n}\cdot Q_n
\end{equation*}
\begin{equation*}
     V(r,\theta)=\frac{1}{4\pi\epsilon_0r}\bigg\{ \frac{Q_0}{r^0}P_0(\cos\theta)+\frac{Q_1}{r^1}P_1(\cos\theta)+\frac{Q_2}{r^2}P_2(\cos\theta)+\dots\bigg\}
\end{equation*}
\paragraph{1. The various \textcolor{blue}{multipole moments of the \underline{electric potential}} $Q_n$ are called the \textcolor{red}{electric $2^n$-pole moments of the \underline{electric potential} } $V(r,\theta)$.}
\paragraph{\indent a. The $n=0$ moment $Q_0$ is the \textcolor{red}{electric monopole moment of the electric potential}. $Q_0$ is equal to the net charge $Q$ on the object. If $Q_0\neq0$, then at large distances the electric potential$V(r,\theta)$ is dominated by the $Q_0$ term, which decreases as $r^{-1}$.}
\paragraph{\indent b. The $n=1$ moment $Q_1$ is the \textcolor{red}{electric dipole moment of the electric potential}. If $Q_0=0$, then at large distances $V(r,\theta)$ is dominated by the $Q_1$ term, which decreases as $r^-2$ unless $Q_1=0$.}
\paragraph{\indent c. The $n=2$ term is the \textcolor{red}{electric quadrupole moment of the electric potential}. If $Q_0=Q_1=0$, then at large distances $V(r,\theta)$ is dominated by the $Q_2$ term, which decreases as $r^{-3}$ unless $Q_2=0$.}
\paragraph{\indent d. The $n=3$ term is the \textcolor{red}{electric octupole moment of the electric potential}...}
\paragraph{\indent e. The $n=4$ term is the \textcolor{red}{electric hexadecapole moment of the electric potential}...}
\paragraph{\indent f. The $n=5$ term is the \textcolor{red}{electric 32-pole moment of the electric potential}...}
\paragraph{\indent g. The $n=6$ term is the \textcolor{red}{electric 64-pole moment of the electric potential}...}
\paragraph{2. Now lets look more closely at \underline{just} the \textcolor{blue}{electric dipole term of the potential}:}
\begin{equation*}
    V_{dipole}=\frac{1}{4\pi\epsilon_0}\frac{Q_1}{r^2}P_1(\cos\theta)=\frac{1}{4\pi\epsilon_0r^2}\int_Q \rho(r',\theta')d\tau'r'\textcolor{blue}{P_1(\cos\theta')P_1(\cos\theta)}
\end{equation*}
\paragraph{\indent a. The product \textcolor{blue}{$P_1(\cos\theta')P_1(\cos\theta)$} is equal to \textcolor{blue}{$\hat{\boldsymbol{r'}}\cdot\hat{\boldsymbol{r}}$}.}
\paragraph{\indent b. Thus, we could just as well write $V_{dipole}$ as}
\begin{equation*}
    V_{dipole} =\frac{1}{4\pi\epsilon_0r^2}\cdot\int_Q \rho(r',\theta') d\tau' r'\hat{\boldsymbol{r'}}\cdot\hat{\boldsymbol{r}}
\end{equation*}
\begin{equation*}
    V_{dipole}=\frac{1}{4\pi\epsilon_0r^2}\cdot \textcolor{red}{\bigg\{ \int_Q \rho(r',\theta')d\tau'}\textcolor{blue}{\boldsymbol{r'}}\textcolor{red}{\bigg\}}\cdot \hat{\boldsymbol{r}}
\end{equation*}
\begin{equation*}
    V_{dipole}=\frac{\textcolor{red}{\boldsymbol{p}}\cdot \hat{\boldsymbol{r}}}{4\pi\epsilon_0r^2}\quad:\quad \textcolor{red}{\boldsymbol{p}\equiv\int_Q \rho(r',\theta')d\tau'}\textcolor{blue}{\boldsymbol{r'}}=\textcolor{red}{\int_Q dQ} \boldsymbol{r'}
\end{equation*} 
\paragraph{\indent c. The \underline{vector} \textcolor{red}{$\boldsymbol{p}$} is the \textcolor{red}{electric dipole moment of the \underline{charge distribution}}.}
\paragraph{\indent d. For point charges, the expression for $\boldsymbol{p}$ becomes}
\begin{equation*}
    \boldsymbol{p}=\int_Q \rho(r',\theta') d\tau' \cdot \boldsymbol{r'} \longrightarrow \boldsymbol{p}=\sum_{i}q_i\boldsymbol{r'}
\end{equation*}
\paragraph{\indent Suppose we define a new coordinate system, with its origin a distance $\boldsymbol{d}$ from the original coordinate system: $\boldsymbol{r''=r'+d}$.}
\paragraph{\indent In the new coordinate system, }
\begin{equation*}
    \boldsymbol{p''}=\sum_{i}q_i\boldsymbol{r''_i}=\sum_{i}q_i(\boldsymbol{r'+d})_i
\end{equation*}
\begin{equation*}
    \boldsymbol{p''}=\sum_{i}q_i\boldsymbol{r'}_i+\sum_{i}q_i\boldsymbol{d}
\end{equation*}
\begin{equation*}
    \boldsymbol{p''}=\boldsymbol{p}+Q\boldsymbol{d}
\end{equation*}
\paragraph{If $Q=0$, the electric dipole moment vector $\boldsymbol{p}$ will be \underline{independent of the}\\ 
\underline{origin of the coordinate system}.}
\paragraph{In chapter 4, the molecules of the materials we discuss will have $Q=0$.}
\paragraph{3. The electric dipole term of the potential written with $\boldsymbol{p}$ is}
\begin{equation*}
    \text{\textcolor{blue}{Coordinate free form}} \quad V_{dipole}(r,\theta)= \frac{\boldsymbol{p\cdot \hat{r}}}{4\pi\epsilon_0 r^2}
\end{equation*}
\paragraph{\indent Suppose we take $\boldsymbol{p} \parallel \hat{\boldsymbol{z}}$. Then this $V_{dipole}(r,\theta)$ would be written}
\begin{equation*}
    V_{dipole}(r,\theta)=\frac{\boldsymbol{p}\cdot\hat{\boldsymbol{r}}}{4\pi\epsilon_0r^2}=\frac{p\cos\theta}{4\pi\epsilon_0r^2}
\end{equation*}
\paragraph{\indent The electric field $\boldsymbol{E}_{dipole}$ that comes from \underline{only} this dipole term is}
\begin{align*}
    \boldsymbol{E}_{dipole}&=-\nabla V_{dipole}(r,\theta)=-\nabla \Bigg[\frac{p\cos\theta}{4\pi\epsilon_0r^2}\Bigg]\\
    \boldsymbol{E}_{dipole}&=-\bigg\{ \bigg( \frac{\partial}{\partial r}\bigg) \hat{\boldsymbol{r}}+\frac{1}{r}\bigg(\frac{\partial}{\partial \theta}\bigg)\hat{\boldsymbol{\theta}}+\frac{1}{r\sin\theta}\bigg(\frac{\partial}{\partial \phi}\bigg)\hat{\boldsymbol{\phi}}\bigg\}V_{dipole}(r,\theta)    \\
    \boldsymbol{E}_{dipole}&=-\bigg\{\bigg(\frac{\partial}{\partial r}\frac{p\cos\theta}{4\pi\epsilon_0r^2}\bigg)\hat{\boldsymbol{r}} +\frac{1}{r}\bigg(\frac{\partial}{\partial \theta}\frac{p\cos\theta}{4\pi\epsilon_0r^2}\bigg)\hat{\boldsymbol{\theta}}\bigg\}   \\
    \boldsymbol{E}_{dipole}&=\frac{p}{4\pi\epsilon_0}\bigg\{ \bigg(\frac{2\cos\theta}{r^3}\bigg)\hat{\boldsymbol{r}}+\frac{1}{r}\bigg( \frac{\sin\theta}{r^2}\bigg)\hat{\boldsymbol{\theta}}\bigg\}  \\
    \boldsymbol{E}_{dipole}&=\frac{p}{4\pi\epsilon_0r^3}\{ 2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\} \\
\end{align*}
\paragraph{4. This electric field, derived from \underline{only the electric dipole term} $V_{dipole}$, is called the electric field for a \textcolor{blue}{pure dipole}.}
\begin{equation*}
    \boldsymbol{E}_{dipole}=\frac{p}{4\pi\epsilon_0r^3}\{ 2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}
\end{equation*}
\paragraph{\indent a. The full multipole expansion of the potential for a dipole charge distribution, what we could call a \textcolor{blue}{physical dipole}, is }
\begin{equation*}
    V(r,\theta)=\frac{1}{4\pi\epsilon_0r}\bigg\{ \frac{Q_1}{r^1}P_1(\cos\theta)+\frac{Q_2}{r^2}P_2(\cos\theta)+\frac{Q_3}{r^3}P_3(\cos\theta)+\dots\bigg\}
\end{equation*}
\paragraph{The \textcolor{blue}{pure dipole} potential $V_{dipole}$ omits the $n>1$ terms that a \textcolor{blue}{physical dipole} potential has (quadrupole, octopole, etc.).}
\paragraph{\indent b. But a \textcolor{blue}{physical dipole} \underline{will} look like a \textcolor{blue}{pure dipole} when we are far enough away from the source so that the $n>1$ terms of the expansion are unimportant. At large distances (i.e. when $r$ is much greater than the dimensions of the charge distribution), the $n>1$ terms are negligible and the \textcolor{blue}{physical dipole} behaves exactly like a \textcolor{blue}{pure dipole}.}
\paragraph{\indent c. In chapter 4, we will only be considering situations where $r$ is much, much greater than the atomic dimensions of the charge distributions for the atoms and molecules that comprise dielectric materials. So the "pure dipole" field will be sufficient for our understanding.}
\paragraph{5. The expression for the electric field of a \textcolor{blue}{pure dipole}}
\begin{equation*}
    \boldsymbol{E}_{dipole}=\frac{p}{4\pi\epsilon_0r^3}\{ 2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}
\end{equation*}
\paragraph{is often written in a "coordinate-free" form, too}
\paragraph{\indent a. If $\boldsymbol{p}\parallel\hat{\boldsymbol{z}}$, then the radial and angular components of $\boldsymbol{p}$ are given by}
\begin{equation*}
    \boldsymbol{p}=(\boldsymbol{p\cdot \hat{r}})\hat{\boldsymbol{r}}+(\boldsymbol{p\cdot \hat{\theta}})\hat{\boldsymbol{\theta}}=p\cos\theta\hat{\boldsymbol{r}}+p\cos(\theta+\frac{\pi}{2})\hat{\boldsymbol{\theta}}=p\cos\theta\hat{\boldsymbol{r}}-p\sin\theta\hat{\boldsymbol{\theta}}
\end{equation*}
\paragraph{\indent So if we form the combination $3(\boldsymbol{p\cdot\hat{r}})\hat{\boldsymbol{r}}$, we get}
\begin{align*}
    3(\boldsymbol{p\cdot\hat{r}})\hat{\boldsymbol{r}}&=3p\cos\theta \hat{\boldsymbol{r}}\\
    3(\boldsymbol{p\cdot\hat{r}})\hat{\boldsymbol{r}}-\boldsymbol{p}&=3p\cos\theta\hat{\boldsymbol{r}}-(p\cos\theta\hat{\boldsymbol{r}}-p\sin\theta\hat{\boldsymbol{\theta}})\\
    3(\boldsymbol{p\cdot\hat{r}})\hat{\boldsymbol{r}}-\boldsymbol{p}&=p\{ 2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}\\
\end{align*}
\paragraph{\indent b. So we can write $\boldsymbol{E}_{dipole}$ in a "coordinate free" form as }
\begin{equation*}
    \boldsymbol{E}_{dipole}=\frac{p}{4\pi\epsilon_0r^3}\{3(\boldsymbol{p\cdot\hat{r}})\hat{\boldsymbol{r}}-\boldsymbol{p}\}
\end{equation*}
\section{Polarization Phenomena in Materials}
\subsection{Dielectric materials and polarization}
\paragraph{\indent In contrast to conductors where charges are (relatively) free to move, in \textcolor{blue}{dielectric materials}, charges are (comparatively) \textcolor{blue}{not} free to move between atoms/molecules.}
\paragraph{\indent Negative charges move opposite to the direction of the applied electric field, while positive charges move in the direction of the applied electric field. These movements of charge create \textcolor{blue}{a distribution of electric dipole moments} in the material.}
\paragraph{\indent The electric field produced by these displacements of charge will counter the applied electric field, resulting in \textcolor{blue}{a net reduction} of the \textcolor{blue}{total} electric field in the region where this charge displacement occurs.}
\paragraph{\indent There are three types of polarization phenomena in materials, which we will call: \textcolor{blue}{electronic polarization, orientational polarization, and molecular polarization.}}
\paragraph{A. \textcolor{blue}{Electronic Polarization} - In electronic polarization, the orbital motions of the atomic electrons shift slightly in a direction \textcolor{blue}{opposite} to the direction of the local electric field.}
\paragraph{\indent i. Remember: The direction of the electric field is the direction a \textcolor{blue}{positive} charge will move.}
\paragraph{\indent ii. When an external electric field is applied, the electron charge density shifts opposite to the direction of the applied electric field. The positively charged nucleus moves in the direction of the applied field.}
\paragraph{\indent iii. Thus, the induced electric dipole moment of the charge distribution will point in the direction of the applied field. The local electric field is \textcolor{blue}{reduced.}}
\paragraph{\indent iv. In \textcolor{blue}{electronic polarization}, the electric dipole moment $\boldsymbol{p}$ is proportional to the applied electric field $\boldsymbol{E}$.}
\begin{equation*}
    \boldsymbol{p}=\alpha\boldsymbol{E}
\end{equation*}
\paragraph{where $\alpha$ is called the \textcolor{blue}{atomic polarizability}.}
\paragraph{\indent v. Let's calculate the \textcolor{blue}{atomic polarizability} $\alpha$ assuming a spherical electron cloud has charge $-q$ uniformly distributed in sphere of radius $\alpha$. Assume the distortion of the electron distribution is tiny, so the electron density remains uniform. (remember $p=qd$).}
\paragraph{\indent $\cdot$ Let's suppose that the applied electric field $\boldsymbol{E}$ displaces the electron cloud a distance $d$. This applied field must equal the electric field at the nucleus if the system reaches equilibrium.}
\paragraph{\indent $\cdot$ The electric field produced at the nucleus will be given by Gauss' Law}
\begin{equation*}
    EA=E\cdot 4\pi d^2=\frac{Q_{encl}}{\epsilon_0}\rightarrow E=\frac{Q_{encl}}{4\pi\epsilon_0d^2}
\end{equation*}
\paragraph{\indent $\cdot$ The charge enclosed will be $q\cdot (\frac{d}{a})^3$. So, if $p=\alpha E$,}
\begin{equation*}
    E=\frac{Q_{encl}}{4\pi\epsilon_0d^2}=\frac{q\cdot(\frac{d}{a})^3}{4\pi\epsilon_0d^2}=\frac{qd}{4\pi\epsilon_0a^3}=\frac{p}{4\pi\epsilon_0a^3}
\end{equation*}
\paragraph{\indent $\cdot$ If $p=\alpha E$, then \textcolor{blue}{$\alpha =4\pi\epsilon_0a^3$}.}
\paragraph{\indent $\cdot$ This gives order-of-magnitude numbers.}
\paragraph{\indent vi. Let's estimate the size of $d$. Place a \textcolor{red}{hydrogen atom} in the uniform electric field $\boldsymbol{E}$ of a parallel-plate capacitor: $V=500$ volts, with $s=1$ mm apart.}
\begin{equation*}
    E=\frac{V}{s}=\frac{500 V}{10^{-3}m}=5\times 10^5\frac{V}{m}
\end{equation*}
\paragraph{\indent $\cdot$ The electron distribution shifts relative to the proton such that an electric dipole moment $p$ is formed ($e$ is the charge on the electron):}
\begin{equation*}
    |\boldsymbol{p}|=\alpha|\boldsymbol{E}|=ed\rightarrow d=\frac{\alpha E}{e}
\end{equation*}
\paragraph{\indent $\cdot$ Using the polarizability $\alpha$ for hydrogen given in Table 4.1, we get }
\begin{equation*}
    d=\frac{(4\pi\epsilon_0)(0.667\times 10^{-30}m^3/4\pi\epsilon_0)(5\times10^5 V/m)}{1.6\times 10^{-19} C}
\end{equation*}
\begin{equation*}
    \rightarrow d \approx 0.2\times 10^{-15}m \rightarrow \frac{d}{R_0}=\frac{0.2\times 10^{-15}m}{0.5\times 10^{-15}m} \approx 4ppm
\end{equation*}
\paragraph{\indent $\cdot$ This is about 1/10th the diameter of a proton!}
\paragraph{\indent $\cdot$ So, in general, the displacement is a \underline{very} tiny shift. (To get $d\approx R_0$ for hydrogen, for example, it seems we would need $V\approx 10^8$ volts!)}
\paragraph{B. \textcolor{blue}{Oriental polarization}- some molecules have a "permanent" electric dipole moment $\boldsymbol{p}$ because of their bond geometry.}
\paragraph{\indent i. Such molecules are called \textcolor{blue}{polar molecules}. Examples of polar molecules include:}
\paragraph{\indent $\cdot$ Water - $H_2O$}
\paragraph{\indent $\cdot$ Hydrochloric Acid - $HCl$}
\paragraph{\indent $\cdot$ Hydrogen Sulfide - $H_2S$}
\paragraph{\indent $\cdot$ Sulfur Dioxide - $SO_2$}
\paragraph{\indent $\cdot$ Ammonia - $NH_3$}
\paragraph{\indent $\cdot$ Chloromethane (R-40) - $CClH_3$}
\paragraph{\indent $\cdot$ Ethanol }
\paragraph{\indent ii. Carbon Dioxide is \textcolor{blue}{not} polar}
\paragraph{\indent iii. The electric dipole moment of a polar molecule placed in an applied electric field receives a torque given by $\boldsymbol{N}=\boldsymbol{p}\times \boldsymbol{E}$.}
\paragraph{\indent iv. Suppose a water molecule is placed in the same  capacitor as above. For water, $|p|=6\times 10^{-30} C\cdot m$. The maximum torque would be}
\begin{equation*}
    N_{max}=|\boldsymbol{p}|\boldsymbol{E}|=(6\times 10^{-30}C\cdot m )(5\times 10^{5}\frac{J/C}{m})
\end{equation*}
\begin{equation*}
    N_{max}=3\times10^{-24}N\cdot m
\end{equation*}
\paragraph{This looks so tiny. How quickly would the molecule rotate with this torque? Let's estimate the moment of inertia for $H_2O$ with $I\approx mR^2$:}
\begin{equation*}
    I\approx (2m_{H})(R_{O-H})^2 =(2\cdot 1.67\times 10^{-27}kg)(\approx10^{-10}m)^2
\end{equation*}
\begin{equation*}
    I\approx 3\times 10^{-47} kg\cdot m^2
\end{equation*}
\begin{equation*}
    \rightarrow N=I\dot{\omega}\rightarrow \dot{\omega}=\frac{N}{I}=\frac{\approx 3\times 10^{-24}N\cdot m}{\approx 3\times10^{-47}kg\cdot m^2}\approx 10^{23} rad/s^2
\end{equation*}
\paragraph{The torque is indeed tiny, but the molecule will orient almost "instantaneously" to the local electric field. Microwave ovens use this property to put the water molecules into rapid motion - heat.}
\paragraph{c. \textcolor{blue}{ Molecular Polarization} - In crystalline materials, electrons effectively shift between atoms, but not between molecules of the material.One \underline{atom} is net positive (a \textcolor{blue}{cation}) and the other \underline{atom} net negative (an \textcolor{blue}{anion}), but the \underline{molecule} remains neutral. (The solid is said to be held together with \textcolor{red}{ionic bonds}.) So the crystal is an assembly of electric dipole moments $\boldsymbol{p}$}
\paragraph{\indent i. When an electric field is applied to a crystal, the \textcolor{red}{cations} and \textcolor{red}{anions} move slightly in opposite directions in the crystal until the net force is zero.}
\paragraph{\indent ii. The shifts in positions of these cation-anion pairs change $\boldsymbol{p}$ at each crystal site.}
\paragraph{\indent iii. The distance the atoms can move can be different for different orientaions of the applied electric field relative to the crystal.}
\paragraph{\indent iv. Thus, the expression $\boldsymbol{p}=\alpha\boldsymbol{E}$ may depend on the crystal direction, and $\alpha$ becomes a \textcolor{blue}{polarizability tensor} rather than a simple scalar.}
\subsection{When the electric field in the material exceeds the \textcolor{blue}{dielectric strength} of the material, charges become unbound and move through the material. (Dielectric strength: the maximum electric field that can be sustained in a dielectric material without electrical breakdown, resulting in high electrical conduction.)}
\subsection{Dielectric strength decreases with}
\paragraph{\indent $\cdot$ Thickness of dielectric (inhomogeneiteies, defects, heating)}
\paragraph{\indent $\cdot$ temperature (thermal motion coupling)}
\paragraph{\indent $\cdot$ humidity (water as a contaminant)}
\paragraph{\indent $\cdot$ frequency}
\subsection{Some common objects or phenomena where dielectric\\ strength is critical in understanding behavior}
\subsubsection{Atmospheric physics}
\paragraph{The Earth may be represented as a capacitor of two concentric conducting spheres (the surface of the Earth and the ionosphere) filled with a dielectric (the lower atmosphere) between the plates.}
\paragraph{\indent Photomultiplier tubes}
\paragraph{\indent Spark plugs in internal combustion engines $15MV/m$}
\paragraph{\indent Oil-impregnated paper in capacitors}
\paragraph{\indent Lighting - Florescent tubes}
\paragraph{\indent Sandpaper production}
\paragraph{\indent Insulators on power lines}
\paragraph{\indent Photocopiers}
\paragraph{\indent and many more... }
\
\subsection{Fields due to bound charges in materials}
\subsubsection{Electric fields due to bound charges}
\paragraph{1. Suppose we have a neutral chunk of material that is polarized. What is the electric potential outside the material produced by the polarized materials?}
\paragraph{\indent a. Each molecule of the polarized material is a little dipole $\boldsymbol{p}$ with a potential}
\begin{equation*}
    V_{dipole}(\boldsymbol{r}) =\frac{1}{4\pi\epsilon_0}\frac{\boldsymbol{p(r')}\cdot\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r^2}}\quad:\quad \mathfrak{r}=\boldsymbol{r-r'}
\end{equation*}
\paragraph{\indent b. Let's say the material has $N(\boldsymbol{r'})$ molecules per unit volume. By superposition, the total electric potential $V$ for all the molecules in the material would be }
\begin{equation*}
    V=\sum_i (V_{dipole})_i
\end{equation*}
\begin{equation*}
    \rightarrow V=\frac{1}{4\pi\epsilon_0}\int_V N(\boldsymbol{r'})\cdot \frac{\boldsymbol{p}(\boldsymbol{r'})\cdot \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'
\end{equation*}
\begin{equation*}
    \rightarrow V=\frac{1}{4\pi\epsilon_0}\int_V  \frac{\boldsymbol{P}(\boldsymbol{r'})\cdot \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'
\end{equation*}
\paragraph{where we've defined the \textcolor{blue}{electric polarization $\boldsymbol{P}(\boldsymbol{r'})$}}
\begin{equation*}
    \boldsymbol{P}(\boldsymbol{r'})\equiv N(\boldsymbol{r'})\boldsymbol{p}(\boldsymbol{r'})
\end{equation*}
\paragraph{The electric polarization $\boldsymbol{P}(\boldsymbol{r'})$}
\paragraph{\indent i. is the electric dipole volume density, or, in other words, the \textcolor{blue}{electric dipole moment per unit volume}}
\paragraph{\indent ii. has units (in the MKS system) system of coulombs/meter$^2$}
\paragraph{\indent iii. measures the degree to which a material is polarized \textcolor{blue}{and} the direction in which it is polarized}
\paragraph{\indent iv. is one of the fundamental quantities to be used in this chapter. Make sure you know this inside and out!}
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int_V  \frac{\boldsymbol{P}(\boldsymbol{r'})\cdot \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'
\end{equation*}
\paragraph{\indent c. We can get deeper physical insight into this integral:}
\paragraph{\indent \indent i. Recall from previous classes that }
\begin{equation*}
    \nabla \bigg( \frac{1}{\mathfrak{r}}\bigg) =\frac{-\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\quad :\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r-r'}
\end{equation*}
\paragraph{where the derivatives are with respect to the \underline{unprimed} (\textcolor{blue}{field}) coordinates.}
\paragraph{Let's instead differentiate with respect to the \underline{primed} (\textcolor{blue}{source}) coordinates. We'll use the symbol \textcolor{blue}{$\nabla'$} to indicate differentiation with respect to primed coordinates. Since $\boldsymbol{\mathfrak{r}}=\boldsymbol{r-r'}$, then }
\begin{equation*}
    \textcolor{blue}{\nabla'}\bigg(\frac{1}{\boldsymbol{\mathfrak{r}}}\bigg)=\frac{-\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{So now we can write the potential of the electric polarization as }
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int_V \frac{\boldsymbol{P}(\boldsymbol{r'})\cdot \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'=\frac{1}{4\pi\epsilon_0}\int_V \boldsymbol{P}(\boldsymbol{r'})\cdot \textcolor{blue}{\nabla'}\bigg(\frac{1}{\mathfrak{r}}\bigg) d\tau'
\end{equation*}
\paragraph{\indent \indent ii. Product rule 5 says $\textcolor{blue}{\nabla'\cdot (f\boldsymbol{A})}=\textcolor{green}{f(\nabla'\cdot\boldsymbol{A})}+\textcolor{red}{A\cdot (\nabla'f)}$, so}
\begin{equation*}
    \textcolor{red}{\boldsymbol{P}\cdot \nabla'\bigg(\frac{1}{\mathfrak{r}}\bigg)}=\textcolor{blue}{\nabla'\cdot \bigg(\frac{\boldsymbol{P}}{\mathfrak{r}}\bigg)}-\textcolor{green}{\frac{\nabla'\cdot \boldsymbol{P}}{\mathfrak{r}}}
\end{equation*}
\paragraph{\indent \indent iii. With the Divergence Theorem of Gauss applied to the first term, we get}
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int_S \frac{\boldsymbol{P}\cdot \boldsymbol{da'}}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V \frac{-(\nabla'\cdot\boldsymbol{P})}{\mathfrak{r}}d\tau'
\end{equation*}
\paragraph{Let's re-write this by defining some new quantities:}
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int_S \frac{\sigma_b da'}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V\frac{\rho_b d\tau'}{\mathfrak{r}}
\end{equation*}
\paragraph{where $\sigma_b=\boldsymbol{P}\cdot\hat{\boldsymbol{n'}}$ and $\rho_b=-\nabla'\cdot \boldsymbol{P}$ are called \textcolor{blue}{bound charge densities}.}
\paragraph{\textcolor{purple}{Note: Note that $\sigma_b =\boldsymbol{P}\cdot \hat{\boldsymbol{n'}}$ is evaluated only at the surface of the volume.}}
\paragraph{Some important things to note about this result:}
\begin{equation*}
    V=\frac{1}{4\pi\epsilon_0}\int_S \frac{\sigma_b da'}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V\frac{\rho_b d\tau'}{\mathfrak{r}}\quad:\begin{cases}
        \sigma_b & =\boldsymbol{P}\cdot \hat{\boldsymbol{n'}}\\
        \rho_b & =-\nabla'\cdot\boldsymbol{P}\\
    \end{cases}
\end{equation*}
\paragraph{\indent $\cdot$ \textcolor{blue}{These bound charge densities are actual distributions of charge within the material}.}
\paragraph{\indent $\cdot$ We can use them the same way we used other charge distributions in the previous chapters to calculate electric potentials and electric fields.}
\paragraph{\indent $\cdot$ All charge in the polarized material arises from the pairs of positive and negative charges in the individual electric dipoles. Thus, if we integrate these charge densities over all the material in the (neutral) dielectric, we should get zero.}
\begin{equation*}
    q_{net}=\int_S \sigma_b da'+\int_V \rho_b d\tau'=\int_S \boldsymbol{P}\cdot\boldsymbol{da'}+\int_V (-\nabla'\cdot \boldsymbol{P})d\tau'
\end{equation*}
\begin{equation*}
    q_{net}=\int_S \boldsymbol{P}\cdot\boldsymbol{da'}-\int_S \boldsymbol{P}\cdot\boldsymbol{da'}=0
\end{equation*}
\paragraph{\indent \indent iv. The electric potential $V(\boldsymbol{r})$ that arises from these bounds charge densities is}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int_S \frac{\sigma_b da'}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V \frac{\rho_b d\tau'}{\mathfrak{r}}\quad:\begin{cases}
        \sigma_b & =\boldsymbol{P}\cdot \hat{\boldsymbol{n'}}\\
        \rho_b & =-\nabla'\cdot\boldsymbol{P}\\
    \end{cases}
\end{equation*}
\paragraph{\indent\indent $\cdot$ You've done integrals with charge distributions before. As we've said: These bound charge distributions are real charge distributions - they are no different from what you've worked with before.}
\paragraph{\indent\indent $\cdot$ So in some cases, you'll find it straightforward to calculate the electric potential $V(r,\theta,\phi)$ due to a bound charge distribution by just performing these integrals, particularly if you find that the bounds charge distribution is comparatively simple.}
\paragraph{\indent \indent $\cdot$ But watch out! Sometimes these integrals can be \textcolor{blue}{really} hard -even impossible- even in cases where the charge distribution seems to be comparatively simple. In such cases, you may find it necessary to use either}
\paragraph{\indent\indent \indent a. the tools you developed in the last chapter to find the electric potential by solving Laplace's equation for a region of interest OR}
\paragraph{\indent\indent \indent b. numerical software tools to perform the integrals to see if you can either come up with a closed form or a numerical solution to the particular problem you're interested in.}
\paragraph{\indent \indent v. As usual, the electric field $\boldsymbol{E}(\boldsymbol{r})$ produced by the bound charge densities is found with $\boldsymbol{E}(\boldsymbol{r})=-\nabla V$, where we're taking the gradient of}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int_S \frac{\sigma_b da'}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V \frac{\rho_b d\tau'}{\mathfrak{r}}\quad:\begin{cases}
        \sigma_b & =\boldsymbol{P}\cdot \hat{\boldsymbol{n'}}\\
        \rho_b & =-\nabla'\cdot\boldsymbol{P}\\
    \end{cases}
\end{equation*}
\paragraph{The gradient is with respect to \textcolor{blue}{field coordinates}. So, we write}
\begin{equation*}
    \boldsymbol{E}(\boldsymbol{r})=-\nabla V(\boldsymbol{r})=-\nabla \bigg\{ \frac{1}{4\pi\epsilon_0}\int_S\frac{\sigma_b da'}{\mathfrak{r}}d\tau'+\frac{1}{4\pi\epsilon_0}\int_V\frac{\rho_b d\tau'}{\mathfrak{r}}\bigg\}
\end{equation*}
\paragraph{Formally, this differentiation is a lot easier than it looks. The only variable in the integrands that has anything but \textcolor{blue}{source} coordinates is $\mathfrak{r}$, and we know}
\begin{equation*}
    \nabla\bigg(\frac{1}{\boldsymbol{\mathfrak{r}}}\bigg)=\frac{-\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{so we get}
\begin{equation*}
    \boldsymbol{E}=\frac{1}{4\pi\epsilon_0}\int_S \frac{\sigma_b da'\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}+\frac{1}{4\pi\epsilon_0}\int_V \frac{\rho_b d\tau'\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{\textcolor{red}{Example:} \textcolor{blue}{Suppose we have a uniformly polarized sphere (radius $R$) with $\boldsymbol{P=P_0\hat{z}}$. What are the electric potentials and electric fields inside/outside the sphere from the charges in the sphere? [Assume the center of the sphere is at the origin.]}}
\paragraph{\indent 1. First, we calculate the bound charge densities for $r<R$:}
\begin{equation*}
    \sigma_b=\boldsymbol{P}\cdot\hat{\boldsymbol{n'}}=P_0\hat{\boldsymbol{z}}\cdot \hat{\boldsymbol{n'}}=P_0\cos\theta' \quad\text{for}\quad r'=R
\end{equation*}
\begin{equation*}
    \rho_b=-\nabla'\cdot \boldsymbol{P}=0 \quad\text{for} \quad r\leq R
\end{equation*}
\paragraph{\indent 2. Remember: These are real charge densities just like we used in the previous chapters, so we could now do the integrals to find the electric potential inside and outside the sphere.}
\paragraph{\indent 3. But it you think about it, these integrals are going to be REALLY hard. We will need to integrate over an angular-dependent charge density on a 3-dimensional surface where our field point can be anywhere inside or outside. YIKES!!!}
\paragraph{\indent 4. But we previously, used our skills in solving Laplace's equation to find $V(r,\theta)$ inside and outside a sphere for $\sigma_b=K\cos\theta$ in the previous chapter.}
\paragraph{\indent So we can take advantage of that solution here}
\begin{equation*}
    V(r,\theta)= \begin{cases}
        \frac{K}{3\epsilon_0}r\cos\theta=\frac{K}{3\epsilon_0}z\rightarrow\frac{P_0z}{3\epsilon_0} & :r\leq R\\
        \frac{K}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta\rightarrow\frac{P_0}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta & :r\geq R\\
    \end{cases}
\end{equation*}
\paragraph{\indent 5. As usual, the electric field is $\boldsymbol{E}=-\nabla V$.}
\paragraph{Thus, \textcolor{blue}{inside} this sphere where \textcolor{blue}{$\boldsymbol{P}=P_0\hat{\boldsymbol{z}}$} using $V(r,\theta)$ for $r\leq R$, we get}
\begin{align*}
    \boldsymbol{E}_{in}&=-\nabla V_{in}\\
    \boldsymbol{E}_{in}&=-\frac{\partial}{\partial z}\bigg( \frac{P_0z}{3\epsilon_0}\bigg) \hat{\boldsymbol{z}}\\
    \boldsymbol{E}_{in}&=-\frac{P_0}{3\epsilon_0}\hat{\boldsymbol{z}}=-\frac{\boldsymbol{P}}{3\epsilon_0}\\
\end{align*}
\paragraph{The electric field inside the sphere $\boldsymbol{E}_{in}$ is completely uniform - it's simply a constant times $\hat{\boldsymbol{z}}$.}
\paragraph{\indent 5. What's the electric field outside the sphere $\boldsymbol{E}_{out}$?}
\paragraph{We can take the gradient of the potential for $r\geq R$. But let's first examine $V(r,\theta)$ outside the sphere:}
\begin{equation*}
    V(r,\theta)=\frac{P_0}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta
\end{equation*}
\paragraph{If the total electric dipole moment of the sphere is $p$, then $P_0=p/\frac{4}{3}\pi R^3$.}
\paragraph{Thus, we can rewrite $V(r,\theta)$ for $r\geq R$ as }
\begin{equation*}
    V(r,\theta)=\frac{P_0}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta=\frac{p}{\frac{4}{3}\pi R^3}\cdot\frac{R^3}{3\epsilon_0r^2}\cos\theta
\end{equation*}
\begin{equation*}
    V(r,\theta)= \frac{p}{4\pi\epsilon_0r^2}\cos\theta=\frac{\boldsymbol{p}\cdot\hat{\boldsymbol{r}}}{4\pi \epsilon_0 r^2}\quad\text{\textcolor{blue}{a "pure" dipole}}
\end{equation*}
\paragraph{Outside the sphere, then, the electric field must be that for the "pure" dipole we derived in the previous chapter:}
\begin{equation*}
    \boldsymbol{E}_{out}=\boldsymbol{E}_{dipole}=\frac{p}{4\pi\epsilon_0 r^3}\{ 2\cos\theta \hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}
\end{equation*}
\paragraph{\indent 6. So, putting everything together, we have}
\begin{equation*}
    V(r,\theta)= \begin{cases}
        \frac{K}{3\epsilon_0}r\cos\theta=\frac{K}{3\epsilon_0}z\rightarrow\frac{P_0z}{3\epsilon_0} & :r\leq R\\
        \frac{K}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta\rightarrow\frac{P_0}{3\epsilon_0}\frac{R^3}{r^2}\cos\theta & :r\geq R\\
    \end{cases}
\end{equation*}
\paragraph{and}
\begin{equation*}
    \boldsymbol{E}=\begin{cases}
        -\frac{P_0\hat{\boldsymbol{z}}}{3\epsilon_0}=-\frac{\boldsymbol{P}}{3\epsilon_0} & :r\leq R\\
        \frac{p}{4\pi\epsilon_0 r^3}\{ 2\cos\theta \hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\} & : r\geq R\\
    \end{cases}
\end{equation*}
\subsection{The Electric Displacement (a.k.a. electric flux density) $\boldsymbol{D}$}
\subsubsection{Suppose we add an electric charge density to our (initially neutral) dielectric material. We thus have two volume charge densities in the material}
\paragraph{\indent a. The charge attribution to bound charge: $\rho_{bound}=-\nabla \cdot \boldsymbol{P}$}
\paragraph{\indent b. The additional charge density - a "free" charge density $\rho_f$.}
\subsubsection{Then the total charge density $\rho$ in the material would be given by}
\begin{equation*}
    \textcolor{blue}{\rho}=\rho_f +\rho_{bound}=\rho_f-\nabla\cdot\boldsymbol{P}
\end{equation*}
\subsubsection{\textcolor{blue}{Charge is charge}. This total charge density $\rho$ is the same quantity we had in earlier chapters. More specifically, this total charge density is exactly the same quantity we used previously in the differential form of Gauss' Law}
\begin{equation*}
    \nabla\cdot\boldsymbol{E}=\frac{\textcolor{blue}{\rho}}{\epsilon_0}
\end{equation*}
\paragraph{and in the integral form of Gauss' Law}
\begin{equation*}
    \oiint_S\boldsymbol{E}\cdot d\boldsymbol{a}=\oiiint_V \frac{\rho}{\epsilon_0}d\tau'=\frac{Q_{enc}}{\epsilon_0}
\end{equation*}
\subsubsection{The differential form of Gauss' Law can be rewritten to incorporate consideration of the bound charge and resulting polarization:}
\begin{equation*}
    \textcolor{blue}{\rho}=\rho_f+\rho_{b}\quad:\quad \rho_b=-\nabla\cdot \boldsymbol{P}
\end{equation*}
\begin{align*}
    \nabla\cdot\boldsymbol{E}&=\frac{\textcolor{blue}{\rho}}{\epsilon_0}=\frac{1}{\epsilon_0}\bigg( \rho_f+\rho_b\bigg)\\
    \epsilon_0\nabla\cdot\boldsymbol{E}&=\rho_f+\rho_b\\
    \epsilon_0\nabla\cdot\boldsymbol{E}&=\rho_f-\nabla\cdot\boldsymbol{P}\\
    \nabla\cdot(\epsilon_0\boldsymbol{E})+\nabla\cdot\boldsymbol{P}&=\rho_f\\
    \nabla\cdot (\textcolor{red}{\epsilon_0\boldsymbol{E}+\boldsymbol{P}})&=\rho_f\\
\end{align*}
\paragraph{\textcolor{purple}{Notice}:}
\begin{equation*}
    \nabla\cdot \textcolor{red}{\boldsymbol{D}}=\rho_f\quad:\quad \textcolor{red}{\boldsymbol{D}\equiv\epsilon_0\boldsymbol{E}+\boldsymbol{P}}
\end{equation*}
\paragraph{\indent a. The vector \textcolor{blue}{$\boldsymbol{D}=\epsilon_0\boldsymbol{E}+\boldsymbol{P}$} is called various things, and those names are generally based on the wrong reasons.}
\paragraph{\indent \indent i. Maxwell called \textcolor{blue}{$\boldsymbol{D}$} the \textcolor{blue}{electric displacement}, as most physicists do, because he thought polarization displaced an aether filling all space.}
\paragraph{\indent \indent ii. Most engineers call this the electric flux density, but, as you see, this is actually only the \textcolor{blue}{free} electric flux density.}
\paragraph{\indent \indent iii. Some authors refuse to give \textcolor{blue}{$\boldsymbol{D}$} a name at all!}
\paragraph{\indent b. The equation \textcolor{blue}{$\nabla\cdot \boldsymbol{D}=\rho_f$} is sometimes called the "dielectric version" of the differential form of Gauss' Law.}
\paragraph{\indent c. Note how $\boldsymbol{E}$ and $\boldsymbol{P}$ are related by $\boldsymbol{E}=(\boldsymbol{D}-\boldsymbol{P})/\epsilon_0$}
\paragraph{\indent d. The vectors $\boldsymbol{D}$ and $\boldsymbol{E}$ suggestively show up in similar-looking equations. They are not the same thing. For example:}
\paragraph{\indent \indent i. In electrostatics, $\nabla\times \boldsymbol{E}=0$. However, $\nabla\times \boldsymbol{D}\neq 0$ necessarily because $\nabla\times \boldsymbol{P}$ can be non-zero. (This will be important here soon!)}
\paragraph{\indent \indent ii. Also, $\boldsymbol{D}$ and $\boldsymbol{E}$ don't even have the same units! The MKS units of $\boldsymbol{D}$ are coulombs/meter$^2$ while the units of $\boldsymbol{E}$ are Newton/coulomb.}
\subsubsection{Integrating $\nabla\cdot \boldsymbol{D}=\rho_f$ over the volume of the dielectric gives}
\begin{equation*}
    \oiiint_V\nabla\cdot\boldsymbol{D}d\tau=\oiiint_V\rho_f d\tau'=Q_{free}
\end{equation*}
\paragraph{Using the Divergence Theorem of Gauss, the left-hand side becomes what is sometimes called the "\textcolor{blue}{dielectric version}" of the integral form of Gauss' Law:}
\begin{equation*}
    \oiiint_V\nabla\cdot\boldsymbol{D}d\tau=\oiint_S\boldsymbol{D}\cdot\boldsymbol{da}=Q_{free}
\end{equation*}
\paragraph{\textcolor{purple}{Remember that}:}
\begin{equation*}
    \oiint_S\boldsymbol{E}\cdot\boldsymbol{da}=\frac{Q_{encl}}{\epsilon_0}
\end{equation*}
\paragraph{\indent a. The integral form of Gauss' Law - whether the dielectric form or the form we saw previously - is "\textcolor{blue}{Always true. Sometimes useful}". If the symmetry of the problem is simple and you can get the free charge enclosed, this integral form of Gauss' Law gives you a quick way to find $\boldsymbol{D}$- and then perhaps $\boldsymbol{E}$ and $\boldsymbol{P}$.}
\paragraph{\indent b. Ponder what this relation shows about how $\boldsymbol{E}$ and $\boldsymbol{E}$ relate:}
\begin{equation*}
    \oiint_S \boldsymbol{D}\cdot \boldsymbol{da}=\oiint_S (\epsilon_0\boldsymbol{E}+\boldsymbol{P})\cdot\boldsymbol{da}=Q_{free}
\end{equation*}
\paragraph{\textcolor{red}{Example}: Suppose we have a wire carrying a linear charge density $\lambda$ surrounded by a rubber insulator. What is the electric displacement $\boldsymbol{D}$? What is the electric field $\boldsymbol{E}$ outside the wire?}
\paragraph{In this case we clearly have \underline{cylindrical symmetry}, so we can use the "dielectric version" of the integral from of Gauss' Law:}
\begin{equation*}
    \oiint_S \boldsymbol{D}\cdot\boldsymbol{da} =2\pi sl\cdot D_r=Q_{free}=\lambda l
\end{equation*}
\begin{equation*}
    \rightarrow \boldsymbol{D}=\frac{\lambda}{2\pi s}\hat{\boldsymbol{s}}=\epsilon_0\boldsymbol{E}+\boldsymbol{P}
\end{equation*}
\paragraph{This formula holds \textcolor{blue}{everywhere} in this problem, even in regions with no dielectric (where $\boldsymbol{P}=0$).}
\paragraph{Thus, \textcolor{blue}{outside}, where there is no dielectric, $\boldsymbol{P}=0$ and }
\begin{equation*}
    \boldsymbol{D}=\epsilon_0\boldsymbol{E}\rightarrow \boldsymbol{E}=\frac{\boldsymbol{D}}{\epsilon_0}=\frac{\lambda}{2\pi\epsilon_0s}\hat{\boldsymbol{s}}
\end{equation*}
\paragraph{\textcolor{blue}{Inside}, we haven't been given $\boldsymbol{P}$, so all we can say there, is that $\boldsymbol{D}=\lambda\hat{\boldsymbol{s}}/2\pi s$. If we are given (or find) $\boldsymbol{P}$ or $\boldsymbol{E}$, we can then find the other.}
\paragraph{\textcolor{red}{Example}: Suppose we have a dielectric sphere of radius $R$ with $\boldsymbol{P}=kr\hat{\boldsymbol{r}}$ located at the origin. No free charge is present anywhere. What is the electric field inside and outside the sphere?}
\paragraph{We have \underline{spherical symmetry}, so we can use the integral form of Gauss' Law to find our electric displacement.}
\paragraph{This time we have no free charge. The electric displacement will be}
\begin{equation*}
    \oiint_S\boldsymbol{D}\cdot\boldsymbol{da}=4\pi r^2D_s=Q_{free}=0
\end{equation*}
\begin{equation*}
    \rightarrow\boldsymbol{D}=\epsilon_0\boldsymbol{E}+\boldsymbol{P}=0
\end{equation*}
\begin{equation*}
    \rightarrow\boldsymbol{E}=-\frac{\boldsymbol{P}}{\epsilon_0}
\end{equation*}
\paragraph{In this case, $\boldsymbol{D}=0$ everywhere. Just as before, this equation holds \textcolor{blue}{everywhere} in this problem.}
\paragraph{\textcolor{blue}{Inside} the sphere, then, the electric field must be}
\begin{equation*}
    \boldsymbol{E}=-\frac{\boldsymbol{P}}{\epsilon_0}=-\frac{kr\hat{\boldsymbol{r}}}{\epsilon_0}
\end{equation*}
\paragraph{\textcolor{blue}{Outside} the sphere, we have $\boldsymbol{P}=0$. So we also must have $\boldsymbol{E}=0$.}
\paragraph{What if we had chosen to do the problem using the bound charge densities instead of Gauss' Law? The bound charge densities are}
\begin{equation*}
    \sigma_b=\boldsymbol{P}\cdot \hat{\boldsymbol{r}}=kr\quad \text{and}\quad \rho_b=-\nabla\cdot\boldsymbol{P}=-\frac{1}{r^2}\frac{\partial}{\partial r}(r^2\cdot kr)=-3k
\end{equation*}
\paragraph{These are real charge densities. \textcolor{blue}{Inside the sphere}, with the ordinary Gauss' Law}
\begin{equation*}
    \oiint_S\boldsymbol{E}\cdot\boldsymbol{da}=\frac{Q_{encl}}{\epsilon_0}\quad :\quad\text{Gauss' Law}
\end{equation*}
\begin{equation*}
    \oint\boldsymbol{E}\cdot\boldsymbol{da}=\frac{Q_{encl}}{\epsilon_0}\rightarrow E_r\cdot 4\pi r^2=\frac{-3k}{\epsilon_0}\cdot\frac{4}{3}\pi r^3
\end{equation*}
\begin{equation*}
    \boldsymbol{E}=-\frac{kr\hat{\boldsymbol{r}}}{\epsilon_0}=-\frac{\boldsymbol{P}}{\epsilon_0}\quad\text{just as above}
\end{equation*}
\paragraph{\textcolor{blue}{Outside the sphere}, with no free charge present, the integral of the bound charge densities over the volume is zero. So, $Q_{encl}=0\rightarrow \boldsymbol{E}=0$.}
\paragraph{The bound charge densities give the same results as we found with the "dielectric version" of Gauss' Law. Gauss' Law was quicker. "Sometimes useful".}
\subsubsection{The boundary conditions for $\boldsymbol{D}$}
\paragraph{a. With the "dielectric version" of the integral of Gauss' Law, we can determine boundary conditions for the \textcolor{blue}{perpendicular component} of the electric displacement $\boldsymbol{D}$ just as we did with the electric field $\boldsymbol{E}$.}
\paragraph{Since $\nabla\cdot\boldsymbol{D}=\rho_f$, take a small pillbox to find}
\begin{equation*}
    \oiint \boldsymbol{D}\cdot\boldsymbol{da}=Q_{free}
\end{equation*}
\begin{equation*}
    \int_{top}\boldsymbol{D}_{above}\cdot\boldsymbol{da}+\int_{bottom}\boldsymbol{D}_{below}\cdot\boldsymbol{da}+\int_{side}\boldsymbol{D}_{side}\cdot\boldsymbol{da}=\sigma_f\cdot da
\end{equation*}
\paragraph{If we shrink the sides of the pillbox to zero, the last term goes to zero and, after cancelling $da$, we get}
\begin{equation*}
    D_{\perp}^{above}-D_{\perp}^{below}=\sigma_f
\end{equation*}
\paragraph{Which we could compare to}
\begin{equation*}
    E_{\perp}^{above}-E_{\perp}^{below}=\frac{\sigma}{\epsilon_0}\quad:\quad \text{where} \quad \sigma=\sigma_f+\sigma_b
\end{equation*}
\paragraph{b. The boundary condition for the \textcolor{blue}{parallel component} of the electric displacement $\boldsymbol{D}$ can be found in a way similar to what was done for the electric field. For electrostatics, we had $\nabla\times\boldsymbol{E}=0$, and we took a line integral above an below the boundary. Let's do the same here for $\boldsymbol{D}$.}
\begin{equation*}
    \text{We have}\quad \nabla\times\boldsymbol{D}=\nabla\times(\epsilon_0\boldsymbol{E}+\boldsymbol{P})=\nabla\times\boldsymbol{P}
\end{equation*}
\paragraph{Taking a line integral above and below the boundary, we get}
\begin{equation*}
    \oint\boldsymbol{D}\cdot\boldsymbol{dl}=\oint\boldsymbol{P}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{which yields}
\begin{equation*}
    D_{\parallel}^{above}-D_{\parallel}^{below}=P_{\parallel}^{above}-P_{\parallel}^{below}
\end{equation*}
\paragraph{which compares to}
\begin{equation*}
    E_{\parallel}^{above}-E_{\parallel}^{below}=0
\end{equation*}
\paragraph{\textcolor{blue}{Boundary conditions for the electric displacement $\boldsymbol{D}$}}
\begin{equation*}
     D_{\parallel}^{above}-D_{\parallel}^{below}=P_{\parallel}^{above}-P_{\parallel}^{below}\quad\text{\textcolor{blue}{and}}\quad D_{\perp}^{above}-D_{\perp}^{below}=\sigma_f
\end{equation*}
\paragraph{\textcolor{blue}{Boundary conditions for the electric field $\boldsymbol{E}$}}
\begin{equation*}
     E_{\parallel}^{above}-E_{\parallel}^{below}=0\quad\text{\textcolor{blue}{and}}\quad E_{\perp}^{above}-E_{\perp}^{below}=\frac{\sigma}{\epsilon_0}
\end{equation*}
\paragraph{c. When dielectrics are present, the boundary conditions for $\boldsymbol{D}$ may prove to be more useful that those for $\boldsymbol{E}$. You likely may have to try both to see.}
\paragraph{d. These relations will be very important when you look at electric fields (e.g., electromagnetic waves) crossing boundaries $\rightarrow$ Snell's Law}
\paragraph{\textcolor{purple}{Aside: If you are wearing glasses, this is how they work!}}
\subsection{Linear Dielectric materials}
\subsubsection{Boundary-value problems (BVPs) with linear dielectrics}
\paragraph{1. In a region with a linear dielectric, the volume bound charge density is }
\begin{equation*}
    \rho_b=-\nabla\cdot \boldsymbol{P}
\end{equation*}
\begin{equation*}
    \rho_b=-\nabla\cdot (\epsilon_0\chi_e\boldsymbol{E})\quad \text{since}\quad \boldsymbol{P}=\chi_e\epsilon_0\boldsymbol{E}
\end{equation*}
\begin{equation*}
    \rho_b=-\nabla\cdot\bigg(\epsilon_0\chi_e\frac{\boldsymbol{D}}{\epsilon}\bigg)\quad \text{since}\quad \boldsymbol{D}=\epsilon\boldsymbol{E}
\end{equation*}
\begin{equation*}
    \rho_b=-\bigg(\frac{\epsilon_0\chi_e}{\epsilon}\bigg)\nabla\cdot\boldsymbol{D}
\end{equation*}
\begin{equation*}
    \textcolor{red}{\rho_b=-\bigg(\frac{\chi_e}{1+\chi_e}\bigg)\rho_f}\quad\text{since}\quad \epsilon_r=\frac{\epsilon}{\epsilon_0}=1+\chi_e
\end{equation*}
\paragraph{\indent a. Thus, in a linear dielectric, if $\rho_f=0$ then $\rho_b=0$.}
\paragraph{\indent b. The total charge density in the region with the linear dielectric material is $\rho=\rho_f+\rho_b$. Thus, within a linear dielectric with $\rho_f=0$, we have a charge free region, and we have $\nabla^2V=0$.}
\paragraph{\indent c. The electric potential $V$ inside a linear dielectric with no free charge is a solution to Laplace's equation meeting all boundary conditions.}
\paragraph{\indent d. We will need to use one of the uniqueness theorems to ensure a unique solution.}
\paragraph{2. Uniqueness theorems require that the electric potential $V$ must satisfy a set of boundary conditions at the boundary of the region of interest $\mathfrak{R}$. What are the boundary conditions when $\mathfrak{R}$ bounds a linear dielectric material?}
\paragraph{\indent a. Recall that, since $\boldsymbol{E}=-\nabla V$, we know that the electric potential must be \textcolor{blue}{continuous} across any boundary of the region of interest (indeed, continuous everywhere): \textcolor{blue}{$V^{above}=V^{below}$}.}
\paragraph{\indent b. Earlier, we found the boundary conditions for the perpendicular component of $\boldsymbol{D}$ is }
\begin{equation*}
    \textcolor{blue}{D_{\perp}^{above}-D_{\perp}^{below}=\sigma_f}
\end{equation*}
\paragraph{\indent\indent i. For linear dielectrics, $\boldsymbol{D}=\epsilon\boldsymbol{E}$, so the boundary condition becomes}
\begin{equation*}
    \textcolor{blue}{\epsilon_{above}\boldsymbol{E}_{\perp}^{above}-\epsilon_{below}\boldsymbol{E}_\perp^{below}=\sigma_f}
\end{equation*}
\paragraph{\indent\indent ii. Since $\boldsymbol{E}=-\nabla V$, this boundary condition also can be written as}
\begin{equation*}
    \textcolor{blue}{\epsilon_{above}\frac{\partial V^{above}}{\partial n}-\epsilon_{below}\frac{\partial V^{below}}{\partial n}=-\sigma_f}
\end{equation*}
\paragraph{\indent\indent iii. In cases where we have $\sigma_f=0$, then $\textcolor{blue}{\epsilon_{above}\frac{\partial V^{above}}{\partial n}=\epsilon_{below}\frac{\partial V^{below}}{\partial n}}$}
\paragraph{$\cdot$ For problems with spherical and azimuthal symmetry, we can solve Laplace's equation in a charge-free region $\mathfrak{R}$ with the \textcolor{blue}{method of separation of variables} if we know the value of the electric potential on all boundaries of $\mathfrak{R}$. (That is, we have a Dirichlet problem.)}
\paragraph{$\cdot$ If we assume an ansatz for the potential $V$ to be $V(r,\theta)=R(r)\Theta(\theta)$, we find that the solution for $V(r,\theta)$ will \textcolor{blue}{always} be}
\begin{equation*}
    V(r,\theta)=\sum_{l=0}^{\infty}\bigg(A_l r^l+ \frac{B_l}{r^{l+1}}\bigg) P_l(\cos\theta)
\end{equation*}
\paragraph{where the \textcolor{blue}{$P_l(\cos\theta)$} are the Legendre polynomials.}
\paragraph{$\cdot$ Exploiting the \textcolor{blue}{orthogonality} and \textcolor{blue}{completeness} properties of the Legendre polynomials, we will use the boundary conditions of our problem to get a unique solution for the electric potential.}
\paragraph{$\cdot$ We must watch for implicit boundary conditions which might result in either the first or second term in the parentheses to behave badly.}
\paragraph{\textcolor{red}{Reminder: In cases with spherical and azimuthal symmetry, we use the standard strategy:}}
\paragraph{\textcolor{red}{STEP 1.} Make sure that there are \textcolor{blue}{no charges in the region} of interest $\mathfrak{R}$.}
\paragraph{\textcolor{red}{STEP 2.} \textcolor{blue}{Determine the boundary conditions for $S$} enclosing $\mathfrak{R}$. (E.g., Dirichlet boundary conditions require that we specify $V$ \textcolor{blue}{everywhere} on $S$.)}
\paragraph{\textcolor{red}{STEP 3.} \textcolor{blue}{Determine what symmetries exist} in the problem and use the appropriate coordinate system.}
\paragraph{\textcolor{red}{STEP 4.} \textcolor{blue}{Identify the coordinate(s) with periodic boundary conditions}. With spherical coordinates, that's already fixed for you: The angular dependence is periodic. The potential will be periodic in angle, and the solution will look like}
\begin{equation*}
    V(r,\theta)=\sum_{l=0}^{\infty}\bigg(A_l r^l +\frac{B_l}{r^{l+1}}\bigg)P_l\cos\theta
\end{equation*}
\paragraph{\textcolor{red}{STEP 5.} Applying the boundary conditions, \textcolor{blue}{use the orthogonality of the harmonic functions to determine the coefficients}.}
\paragraph{\textcolor{blue}{Example:(Griffith's Example 4.7)} A sphere of homogeneous liner dielectric material is placed in an other wise uniform electric field $\boldsymbol{E}_0$. Find the electric field inside the sphere.}
\paragraph{\textcolor{red}{STEP 1.} There are no \textbf{free} charges in $\mathfrak{R}$, so we have Laplace's equation.}
\paragraph{\textcolor{red}{STEP 2.} Based on the information given, the boundary conditions are}
\begin{align*}
    \textcolor{red}{\text{\textcircled{1}}} &\textcolor{red}{\quad V_{in}(R,\theta)=V_{out}(R,\theta)}\quad\text{because $V$ must be continuous}\\
    \textcolor{red}{\text{\textcircled{2}}} &\textcolor{red}{\quad \epsilon\frac{\partial V_{in}}{\partial r} =\epsilon_0\frac{\partial V_{out}}{\partial r}}\quad \text{because} \quad \sigma_f=0\\
    \textcolor{red}{\text{\textcircled{3}}} &\quad \textcolor{red}{V(r>>R,\theta)=-\boldsymbol{E}_0z=-\boldsymbol{E}_0 r\cos\theta=-\boldsymbol{E}rP_1\cos\theta}\\
\end{align*}
\paragraph{\indent The potential or its derivative is specified on all boundaries of $\mathfrak{R}$, so we have \textcolor{blue}{Robin boundary conditions}. If a solution satisfies these boundary conditions, the uniqueness theorem says that's the only solution.}
\paragraph{\textcolor{red}{STEP 3.} With spherical and azimuthal symmetry, we use spherical coordinates.}
\paragraph{\textcolor{red}{STEP 4.} The solution is periodic in the angular variable, and our solution will be}
\begin{equation*}
    V(r,\theta)=\sum_{l=0}^{\infty}\bigg(A_l r^l+\frac{B_l}{r^{l+1}}\bigg)P_l\cos\theta
\end{equation*}
\paragraph{\textcolor{red}{STEP 5.} Now we're ready to apply the boundary conditions and then use orthogonality to find the coefficients.}
\paragraph{Recall that our ansatz is }
\begin{equation*}
    V(r,\theta)=\sum_{l=0}^{\infty}\bigg(A_l r^l+\frac{B_l}{r^{l+1}}\bigg)P_l\cos\theta
\end{equation*}
\paragraph{\underline{Inside the sphere}, the \textcolor{blue}{implicit boundary condition} that $V_{in}(r,\theta)$ must be finite at $r=0$ forces all but $B_l$ to vanish.}
\paragraph{Thus, inside the sphere, our solution simplifies to}
\begin{equation*}
    V_{in}(r,\theta)=\sum_{l=0}^{\infty} A_l r^l P_l(\cos\theta)
\end{equation*}
\paragraph{\underline{Outside the sphere}, $\textcolor{red}{\text{\textcircled{3}}} \quad \textcolor{red}{V(r>>R,\theta)=-\boldsymbol{E}_0z=-\boldsymbol{E}_0 r\cos\theta=-\boldsymbol{E}_0 rP_1(\cos\theta)}$ demands that}
\begin{equation*}
    V_{out}(r,\theta)=-E_0 r \cos\theta + \sum_{l=0}^{\infty}\frac{B_l}{r^{l+1}}P_l(\cos\theta)
\end{equation*}
\paragraph{so now our solutions look like:}
\begin{equation*}
    V_{in}(r,\theta)=\sum_{l=0}^{\infty} A_l r^l P_l(\cos\theta)
\end{equation*}
\begin{equation*}
    V_{out}(r,\theta)=-E_0 r \cos\theta +\sum_{l=0}^{\infty} \frac{B_l}{r^{l+1}}P_l(\cos\theta)
\end{equation*}
\paragraph{Boundary condition \textcolor{red}{\textcircled{1}} states \textcolor{red}{$V_{in}(R,\theta)=V_{out}(R,\theta)$}. Using this with our results thus far, we get}
\begin{equation*}
    \sum_{l=0}^{\infty}A_lR^lP_l(\cos\theta)=-E_0 R\cos\theta+\sum_{l=0}^{\infty}\frac{B_l}{R^{l+1}}P_l(\cos\theta)
\end{equation*}
\paragraph{So, with orthogonality, this boundary condition \textcolor{red}{\textcircled{1}} demands}
\begin{equation*}
    A_lR^l=\frac{B_l}{R^{l+1}}\rightarrow A_l=\frac{B_l}{R^{2l+1}}:\quad l\neq 1\quad \text{and} \quad A_l R=-E_0R+\frac{B_1}{R^2}
\end{equation*}
\paragraph{The boundary condition \textcolor{red}{\textcircled{2}} which applies at $r=R$ requires:}
\begin{equation*}
    \textcolor{red}{\epsilon\frac{\partial V_{in}}{\partial r}=\epsilon_0\frac{\partial V_{out}}{\partial r}}
\end{equation*}
\paragraph{Applying this boundary condition at $r=R$,}
\begin{equation*}
    \epsilon\frac{\partial V_{in}}{\partial r}=\epsilon\frac{\partial}{\partial r}\bigg\{ \sum_{l=0}^{\infty}A_lr^lP_l(\cos\theta)\bigg\}=\epsilon\sum_{l=0}^{\infty}lA_lR^{l-1}P_l(\cos\theta)
\end{equation*}
\begin{equation*}
    \epsilon_0\frac{\partial V_{out}}{\partial r}=\epsilon_0\frac{\partial}{\partial r}\bigg\{ -\epsilon_0 r\cos\theta +\sum_{l=0}^{\infty}\frac{B_l}{r^{l+1}}P_l(\cos\theta)\bigg\}
\end{equation*}
\begin{equation*}
    \epsilon_0\frac{\partial V_{out}}{\partial r}=-\epsilon_0E_0\cos\theta -\epsilon_0\sum_{l=0}^{\infty}(l+1)\frac{B_l}{R^{l+2}}P_l(\cos\theta)
\end{equation*}
\paragraph{These equations for boundary condition \textcolor{red}{\textcircled{2}} require for $l\neq 1$}
\begin{equation*}
    \epsilon lA_lR^{l-1}=-\epsilon_0(l+1)\frac{B_l}{R^{l+2}}\rightarrow A_l=-\frac{(l+1)}{l\epsilon_r}\frac{B_l}{R^{2l+1}}
\end{equation*}
\paragraph{For $l=1$ we get $\epsilon A_l=-\epsilon_0E_0-\epsilon_0\frac{2B_1}{R^3}$.}
\paragraph{So boundary condition \textcolor{red}{\textcircled{2}} has given us}
\begin{equation*}
    A_l=-\frac{(l+1)}{l\epsilon_r}\frac{B_l}{R^{2l+1}}:\quad l\neq 1\quad \text{and} \quad\epsilon_rA_1=-E_0-\frac{2B_1}{R^3}
\end{equation*}
\section{Magnetostatics}
\subsection{Magnetic Fields and Forces}
\subsubsection{The Lorentz Force}
\paragraph{1. Electrostatics and magnetostatics are special situations}
\paragraph{\indent a. We have explored electric fields for such situations where the fields are not changing in time - \textcolor{blue}{electrostatics}. In such cases, electric charges do not change their positions as a function of time ("static electric charges").}
\paragraph{\indent b. Now we want to explore magnetic fields in situations where the magnetic fields are not changing with time - \textcolor{blue}{magnetostatics}.}
\paragraph{\indent c. For magnetostatics, electric currents (which produce magnetic fields) do not change in magnitude or direction as a function of time ("steady electric currents").}
\paragraph{\indent d. This restriction to static charge distributions and static currents arises because, as you know from previous physics courses, moving charges and varying currents generate magnetic and electric fields, respectively "induction".}
\paragraph{\indent e. We will address situations with moving charges and varying currents later.}
\paragraph{2. We saw in last semester physics that a charge $q$ moving with a velocity $\boldsymbol{v}$ in electric and magnetic fields $\boldsymbol{E}$ and $\boldsymbol{B}$ experiences a force}
\begin{equation*}
    \boldsymbol{F}=q\boldsymbol{E}+q(\boldsymbol{v}\times \boldsymbol{B})\quad:\quad \text{\textcolor{blue}{"Lorentz-Coulomb force"}}
\end{equation*}
\paragraph{\indent a. For the record: This Lorentz-Coulomb force expression is correct regardless of whether the fields are changing, \textcolor{blue}{BUT} the $\boldsymbol{E}$ and $\boldsymbol{B}$ used in the expression must be the \underline{total} field(s) present (including any contributions to $\boldsymbol{E}$ and $\boldsymbol{B}$ induced by time-varying fields).}
\paragraph{\indent b. The magnetic portion of this expression is called the \textcolor{blue}{Lorentz force}, $F_{mag}$.}
\paragraph{3. Magnetic poles appear to only occur in pairs (dipoles).}
\paragraph{\indent a. Since magnetic monopoles are rare (non-existent?), we have no pressing need for a "Coulomb's Law" for magnetic charges. You may find that some older books mention it though.}
\paragraph{\indent b. However, if such monopoles / "magnetic charges" exist, they could be handled similarly to the way we handled electric charges in the preceding chapters.}
\paragraph{4. If the electric field $\boldsymbol{E}=0$, then the force experienced by a moving charge is just the \textcolor{blue}{Lorentz Force}: $\boldsymbol{F}=q(\boldsymbol{v}\times \boldsymbol{B})=\boldsymbol{F}_{mag}$}
\paragraph{\indent a. From last semester, we recall that if a force $\boldsymbol{F}$ performs work on an object, the kinetic energy $T$ of the object changes ("work-energy theorem")}
\begin{equation*}
    dW=dT=\boldsymbol{F}\cdot\boldsymbol{dr}\longrightarrow \frac{dW}{dt}=\frac{dT}{dt}:\quad T=\frac{1}{2}mv^2
\end{equation*}
\paragraph{\indent b. In the case of a charged particle, the work $dW$ performed by a constant magnetic field $\boldsymbol{B}$ on a particle with electric charge $q$ moving with velocity $\boldsymbol{v}$ would be given by }
\begin{align*}
    dW&=\boldsymbol{F}_{mag}\cdot\boldsymbol{dr}\\
    \frac{dW}{dt}=\frac{dT}{dt}&=\boldsymbol{F}_{mag}\cdot\frac{d\boldsymbol{r}}{dt}\\
    \frac{dW}{dt}&=q(\boldsymbol{v}\times\boldsymbol{B})\cdot\boldsymbol{v}\\
    \frac{dW}{dt}&=0\quad:\quad \text{\textcolor{blue}{Magnetic fields do no work!!!}}\\
    \frac{dW}{dt}=\frac{dT}{dt}&=\boldsymbol{F}_{mag}\cdot\frac{d\boldsymbol{r}}{dt}=q(\boldsymbol{v}\times\boldsymbol{B})\cdot\boldsymbol{v}=0\\
\end{align*}
\paragraph{\indent c. Since the Lorentz force $\boldsymbol{F_{mag}}$ cannot change the kinetic energy $T=\frac{1}{2}mv^2$ of a moving charged particle, a static magnetic field $\boldsymbol{B}$ cannot perform work on a charge.}
\paragraph{\indent d. Any work $dW$ performed on a moving charge by the Lorentz-Coulomb force must be performed by the electric field $\boldsymbol{E}$.}
\paragraph{\indent e. However, the Lorentz force $\boldsymbol{F}_{mag}$ \underline{can} change the momentum $\boldsymbol{p}=m\boldsymbol{v}$ since $\boldsymbol{F}=d\boldsymbol{p}/dt$.}
\paragraph{\indent f. This means a magnetic field $\boldsymbol{B}$ changes the \underline{direction} but not the magnitude of the moving charged particle's velocity $\boldsymbol{v}$.}
\paragraph{\indent g. This makes magnetic fields useful for measuring the velocities and momenta of moving charges.}
\paragraph{4. The product $q\boldsymbol{v}$ in $q(\boldsymbol{v}\times\boldsymbol{B})$ is the \textcolor{blue}{electric current} for a point charge.}
\paragraph{\indent a. The electric current for a single point charge cannot truly be "steady". Such a "current" is not something we can handle with magnetostatics.}
\paragraph{\indent b. But this $q\boldsymbol{v}$ expression can be generalized to extended lines, sheets (surfaces), and volumes of moving charge. Such extended distributions can carry a steady current.}
\paragraph{\indent c. Those generalizations would look like:}
\begin{equation*}
    \text{Lines of moving charge:}\quad\quad \lambda dl\boldsymbol{v}=\boldsymbol{I}dl'\quad:\quad \boldsymbol{I}=\lambda\boldsymbol{v}
\end{equation*}
\begin{equation*}
    \text{Surfaces of moving charge:}\quad\quad \sigma da\boldsymbol{v}=\boldsymbol{K}da'\quad:\quad \boldsymbol{K}=\sigma\boldsymbol{v}
\end{equation*}
\begin{equation*}
    \text{Volumes of moving charge:}\quad\quad \rho d\tau \boldsymbol{v}=\boldsymbol{J}d\tau'\quad:\quad \boldsymbol{J}=\rho\boldsymbol{v}
\end{equation*} 
\paragraph{\indent d. These expressions lead to generalizations for the Lorentz force $\boldsymbol{F}_{mag}$:}
\begin{equation*}
    \text{Point:} \quad\quad \boldsymbol{F}_{mag}=q(\boldsymbol{v}\times\boldsymbol{B})
\end{equation*}
\begin{equation*}
    \text{Filament/wire/line:} \quad\quad \boldsymbol{F}_{mag}=\int_C\boldsymbol{I}\times\boldsymbol{B}dl'=\int I\boldsymbol{dl'}\times \boldsymbol{B}
\end{equation*}
\begin{equation*}
    \text{Sheets/surface:}\quad\quad \boldsymbol{F}_{mag}=\int_S \boldsymbol{K}\times\boldsymbol{B}da'
\end{equation*}
\begin{equation*}
    \text{Volume:} \quad\quad \boldsymbol{F}_{mag}=\int_V\boldsymbol{J}\times\boldsymbol{B}d\tau'
\end{equation*}
\paragraph{5. \textcolor{blue}{An important aside:} Suppose we have a current density $J$ passing through an enclosed volume $V$ whose boundaries $S$ are not changing in time.}
\paragraph{\indent a. The current density is a flow of electric charge through the volume $V$.}
\paragraph{\indent b. The net flow of charge through the volume $V$ would be given by the integral of $\boldsymbol{J}$ through the surface $S$ bounding the volume $V$ ($\boldsymbol{da}$ points outward).}
\begin{equation*}
    \text{net flow of charge:} \quad\quad \oiint \boldsymbol{J}\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent c. Using the Divergence Theorem of Gauss, this is equivalent to }
\begin{equation*}
    \text{net flow of charge:}\quad\quad \oiint_S\boldsymbol{J}\cdot\boldsymbol{da}=\oiiint_V\nabla\cdot\boldsymbol{J}d\tau
\end{equation*} 
\paragraph{\indent d. But, within that volume $V$, if there is any change $dQ$ of net charge in that volume as a function of time, that change must show up as a change in the electric charge density $\rho$ from within that volume \textcolor{blue}{if electric charge is conserved} (note: $\boldsymbol{da}$ points outward).}
\begin{equation*}
    \frac{dQ}{dt}=-\frac{d}{dt}\bigg(\oiiint_V\rho d\tau\bigg)=-\oiiint_V\frac{d\rho}{dt}d\tau
\end{equation*}
\paragraph{\indent e. Evidently, then, \textcolor{blue}{if electric charge is conserved} we must have}
\begin{equation*}
    \oiiint_V\nabla\cdot\boldsymbol{J}d\tau=-\oiiint_V \frac{d\rho}{dt}d\tau
\end{equation*}
\begin{equation*}
    \oiiint_V \nabla\cdot\boldsymbol{J}d\tau+\oiiint_V \frac{d\rho}{dt}d\tau=0
\end{equation*}
\begin{equation*}
    \oiiint_V \bigg(\nabla\cdot\boldsymbol{J}+\frac{d\rho}{dt}\bigg)d\tau=0
\end{equation*}
\paragraph{\indent f. \textcolor{blue}{If electric charge is conserved} everywhere (i.e., for any volume we choose anywhere in the universe), then the integrand must always vanish:}
\begin{align*}
    \bigg(\nabla\cdot&\boldsymbol{J}+\frac{d\rho}{dt}\bigg)=0\\
    \nabla\cdot&\boldsymbol{J}=-\frac{d\rho}{dt}\quad\quad:\quad \text{\textcolor{blue}{Continuity equation}}\\
\end{align*}
\paragraph{\indent g. This \textcolor{blue}{continuity equation} is a result that can be generalized to apply for any flow of a conserved quantity (e.g., fluid dynamics, "color charge" current in quantum chromodynamics, etc.)}
\subsubsection{The Biot-Savart law and "magnetostatics"}
\paragraph{1. We have seen that the electric field $\boldsymbol{E}$ of an element of a line charge $\lambda dl'$ is}
\begin{equation*}
    \boldsymbol{E}(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int\frac{\lambda dl'}{\mathfrak{r}^2}\hat{\boldsymbol{\mathfrak{r}}}\quad:\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}'-\boldsymbol{r}
\end{equation*}
\paragraph{2. \textcolor{blue}{Biot and Savart} established a similar law for the magnetic field $\boldsymbol{B}$ arising from a line of current $I\boldsymbol{dl}'$.}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0 I}{4\pi}\int\frac{\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}:\quad \mu_0=4\pi\times 10^{-7}N/A^2
\end{equation*}
\paragraph{\indent a. The Biot-Savart Law is an inverse square law, but a very different one - and it has a cross product in it!}
\paragraph{\indent b. Physicists usually call $\boldsymbol{B}$ simply the magnetic field. Engineers are more prone to call $\boldsymbol{B}$ the magnetic flux density. You will want to check any textbook you use to see what they call $\boldsymbol{B}$.}
\paragraph{\indent c. \textcolor{red}{Procedurally, we always integrate over the current in the direction of the electric current!}}
\paragraph{\textcolor{red}{Example}: \textcolor{blue}{Find the magnetic field $\boldsymbol{B}$ generated by a finite straight wire carrying a steady electrical current $I$}.}
\paragraph{We will use the Biot-Savart Law:}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\int\frac{\textcolor{blue}{\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}}}{\textcolor{red}{\mathfrak{r}^2}}
\end{equation*}
\paragraph{Let the wire lie along the z-axis with the current moving in the direction of positive z: \textcolor{blue}{$\boldsymbol{dl}'=dz'\hat{\boldsymbol{z}}$}.}
\paragraph{The problem then has cylindrical symmetry, so cylindrical coordinates are appropriate to use.}
\paragraph{The various pieces of the Biot-Savart Law are:}
\begin{equation*}
    \textcolor{blue}{\boldsymbol{dl}'\times \hat{\boldsymbol{\mathfrak{r}}}=dz'\hat{\boldsymbol{z}}\times\hat{\boldsymbol{\mathfrak{r}}}=dz'\sin\alpha\hat{\boldsymbol{\phi}} }
\end{equation*}
\begin{equation*}
    \textcolor{blue}{z'=s\tan\theta'}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{dz'=\frac{s}{\cos^2\theta'} d\theta'}
\end{equation*}
\begin{equation*}
    \textcolor{red}{\cos\theta'=\frac{s}{\mathfrak{r}} \quad\longrightarrow\quad \frac{1}{\mathfrak{r}^2}=\frac{\cos^2\theta'}{s^2}}
\end{equation*}
\paragraph{Putting all the pieces together, we would have}
\begin{equation*}
    |d\boldsymbol{B}|=\frac{\mu_0I}{4\pi}\bigg|\frac{\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\bigg|=\frac{\mu_0I}{4\pi}\cdot\frac{\textcolor{blue}{dz'}\cdot\sin\alpha}{\textcolor{red}{\mathfrak{r}^2}}=\frac{\mu_0I}{4\pi}\textcolor{blue}{\frac{sd\theta'}{\cos^2\theta'}}\cdot\sin\alpha\cdot\textcolor{red}{\frac{\cos^2\theta'}{s^2}}
\end{equation*}
\begin{equation*}
    \sin\alpha=\sin(180-(90-\theta'))=\sin(90-\theta')=\cos\theta'
\end{equation*}
\begin{align*}
    \boldsymbol{B}&=\frac{\mu_0I}{4\pi s}\int_{\theta_1}^{\theta_2}d\theta'\cos\theta'\hat{\boldsymbol{\phi}}\\
    \boldsymbol{B}&=\frac{\mu_0I}{4\pi s}(\sin\theta_2-\sin\theta_1)\hat{\boldsymbol{\phi}}\\
\end{align*}
\paragraph{Suppose we have an infinite wire. In that case,}
\begin{equation*}
    \theta_1=-\frac{\pi}{2}\quad\text{and}\quad\theta_2=\frac{\pi}{2}
\end{equation*}
\begin{equation*}
    \boldsymbol{B}=\frac{\mu_0I}{2\pi s}\hat{\boldsymbol{\phi}}
\end{equation*}
\paragraph{4. We saw earlier that the force on a current carrying wire was}
\begin{equation*}
    \boldsymbol{F}_{mag}=\int_C l\boldsymbol{dl}'\times \textcolor{blue}{\boldsymbol{B}(\boldsymbol{\mathfrak{r}})}
\end{equation*}
\paragraph{\indent a. The force between \textbf{two} current-carrying wires would be found using the result from the Biot-Savart Law for \textcolor{blue}{$\boldsymbol{B}_1(\boldsymbol{\mathfrak{r}})$} for the field generated by \textcolor{blue}{wire 1}.}
\begin{equation*}
    \textcolor{blue}{\boldsymbol{B}_1(\boldsymbol{\mathfrak{r}}) = \frac{\mu_0I_1}{4\pi} \int_{C_1} \frac{\boldsymbol{dl}_1'\times \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\quad:\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}'-\boldsymbol{r}}
\end{equation*}
\paragraph{\indent and then performing the integral for $\boldsymbol{F}_{mag}$ over the current in \underline{wire 2}:}
\begin{equation*}
    \boldsymbol{F}_{mag}=\int_{C_2}I_2\boldsymbol{dl}_2''\times \textcolor{blue}{B_1(\boldsymbol{\mathfrak{r}}})
\end{equation*}
\begin{equation*}
    \boldsymbol{F}_{mag}=\int_{C_2}I_2\boldsymbol{dl}_2''\times \bigg\{ \textcolor{blue}{\frac{\mu_0I_1}{4\pi}\int_{C_1} \frac{\boldsymbol{dl}_1'\times \hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}}\bigg\}\quad:\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}'-\boldsymbol{r}
\end{equation*}
\begin{equation*}
    \boldsymbol{F}_{mag}=\frac{\mu_0I_1I_2}{4\pi}\int_{C_2}\textcolor{blue}{\int_{C_1}}\frac{\boldsymbol{dl}_2''\times\textcolor{blue}{(\boldsymbol{dl}_1'\times\hat{\boldsymbol{\mathfrak{r}}})}}{\textcolor{blue}{\mathfrak{r}^2}}
\end{equation*}
\paragraph{\indent b. But suppose we have the simple case of two straight, parallel, current-carrying wires a distance $s$ apart, each carrying current in the positive $z$ direction.}
\paragraph{\indent \indent i. For a single wire, we found $\textcolor{blue}{B_1=\frac{\mu_0I}{2\pi s}\hat{\boldsymbol{\phi}}}$, where the current ran along the z-axis and $s$ was the perpendicular distance of the field point from the wire.}
\paragraph{\indent \indent ii. If $\boldsymbol{I}_2=I_2\boldsymbol{dl}_2=I_2dl_2\hat{\boldsymbol{z}}$, then the \textcolor{blue}{force per unit length} of wire 2 would be}
\begin{equation*}
    \frac{d\boldsymbol{F}_{mag}}{dl_2}=\frac{I_2d\boldsymbol{l}_2''}{dl_2}\times \textcolor{blue}{B_1}=\frac{\textcolor{blue}{\mu_0I_1}I_2}{\textcolor{blue}{2\pi s}}\hat{\boldsymbol{z}}\times \textcolor{blue}{\hat{\boldsymbol{\phi}}}=-\frac{\mu_0I_1I_2}{2\pi s}\hat{\boldsymbol{s}}
\end{equation*}
\paragraph{\indent $\cdot$ The force between the two wires is an \textcolor{blue}{attractive} force.}
\paragraph{\indent $\cdot$ If we reversed one of the currents, the force would be repulsive.}
\paragraph{\indent $\cdot$ This approach can be used to define the MKS unit of current (the ampere). Adjust the currents and measure the force on a parallel set of 1-meter-long wires a distance $s=1$m apart:}
\begin{equation*}
    \boldsymbol{F}_{mag}=I_1I_2\cdot \frac{4\pi\times10^{-7}}{2\pi \times1 m}\frac{N}{A^2}\cdot 1m=I_1I_2\cdot 2\times 10^{-7} \frac{N}{A^2}
\end{equation*}
\paragraph{5. Last time, we found we could get the magnitude of the magnetic field of a current carrying wire (with a steady current) using the Biot-Savart Law}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{2}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\int\frac{\boldsymbol{dl'}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{can usually be applied in a straightforward manner for currents with simple geometric shapes.}
\paragraph{\indent a. If we establish the direction of $\boldsymbol{B}$ by symmetry, then the problem becomes one of finding the magnitude of the Biot-Savart Law and then taking components.}
\paragraph{\indent b. The geometry of $\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}$ can make things tedious, but often (as we saw last time) the integrand will be a single variable sweeping over the entire current distribution using $\boldsymbol{dl}'$.}
\paragraph{\indent c. Let's try a few examples using the Biot-Savart Law for current loops with steady currents. We'll find the magnetic field $\boldsymbol{B}$ for the following three examples of current carrying loops where the loop \textcolor{blue}{lies in the $xy$ plane}, is \textcolor{blue}{centered on the $z$-axis}, and carries a \textcolor{blue}{steady current $\boldsymbol{I}$ counter-clockwise}.}
\paragraph{\indent\indent $\cdot$ Above a circular loop}
\paragraph{\indent\indent $\cdot$ At the center of a square current loop}
\paragraph{\indent\indent $\cdot$ At the center of a regular polygon loop}
\paragraph{\textcolor{red}{Be sure to note: Each loop lies in the $xy$ plane, is centered on the $z$-axis, and carries a steady current $I$ counter-clockwise.}}
\paragraph{\textcolor{blue}{Example 1: Find the magnetic field $\boldsymbol{B}$ a distance $z$ above the center of a circular loop of radius $\boldsymbol{R}$, which carries a steady current $I$.}}
\paragraph{\indent We will use the Biot-Savart Law to find the magnetic field $\boldsymbol{B}$:}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{2}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\int\frac{\boldsymbol{dl'}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{Look at the picture. Our problem is cylindrically symmetric, so cylindrical coordinates make sense. The $z$-axis is a symmetry axis for the problem, and we are being asked to find the magnetic field along that axis.}
\paragraph{Think about this: Using the \textcolor{blue}{right-hand rule for magnetic fields}, in what direction will the magnetic field $\boldsymbol{B}$ point if we are at a point on the $z$-axis?}
\paragraph{Using the \textcolor{blue}{right-hand rule for magnetic fields}, the magnetic field $\boldsymbol{B}$ must point in the direction of positive $z$. By symmetry, components of the magnetic field $\boldsymbol{B}$ that are perpendicular to the $z$-axis cancel each other.}
\paragraph{Since we know the direction of $\boldsymbol{B}$, all we need to do is find the magnitude of $\boldsymbol{B}$ (which will be a function of $z$), and then find the $z$-component:}
\begin{equation*}
    \boldsymbol{B}=B(z)\cos\theta\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{so let's find $B(z)$, the magnitude of the electric field $\boldsymbol{B}$.}
\paragraph{We will get the magnitude from the Biot-Savart Law:}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{2}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\int\frac{\boldsymbol{dl'}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{As a general practice, when you have to work with the Biot-Savart Law, it usually pays to begin by figuring out the cross product in the numerator. Let's start there.}
\paragraph{In this case, the cross product is easy: $\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}=dl'$ in this case since the angle between $\boldsymbol{dl}'$ and $\hat{\boldsymbol{\mathfrak{r}}}$ is always 90 degrees.}
\paragraph{Each infinitesimal piece of $\boldsymbol{dB}$ of the Biot-Savart Law along the $z$-axis becomes}
\begin{equation*}
    \boldsymbol{dB}=\frac{\mu_0}{4\pi}\frac{\boldsymbol{dI}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\frac{\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0I}{4\pi}\frac{\textcolor{red}{dl'}}{\mathfrak{r}^2}\hat{\boldsymbol{dB}}
\end{equation*}
\paragraph{As we go around the loop, the direction of $\boldsymbol{dB}$ changes, but already we know that only the $z$-component survives.}
\paragraph{So we can find the $z$-component of each $\boldsymbol{dB}$ with}
\begin{equation*}
    (\boldsymbol{dB})_z=\frac{\mu_0I}{4\pi}\frac{\textcolor{red}{dl'}}{\mathfrak{r}^2}\cos\theta
\end{equation*}
\paragraph{But, looking at the figure, we see that $\cos\theta$ is constant around the loop. So the magnitude of the total magnetic field will be }
\begin{equation*}
    B(z)=\frac{\mu_0I}{4\pi}\int\frac{\textcolor{red}{dl'}}{\mathfrak{r}^2}\cdot\cos\theta
\end{equation*}
\paragraph{What is \textcolor{red}{$dl'$}? We get \textcolor{red}{$dl'$} by sweeping out a little bit of the current distribution by using a bit of the azimuthal angle \textcolor{red}{$d\phi$}:}
\begin{equation*}
    \textcolor{red}{dl'=R\cdot d\phi}
\end{equation*}
\paragraph{So the total $z$-component of the magnetic field is going to be}
\begin{equation*}
    B_z(z)=\frac{\mu_0I}{4\pi}\int\frac{\textcolor{red}{dl'}}{\mathfrak{r}^2}\cdot \cos\theta=\frac{\mu_0I}{4\pi}\int_0^{2\pi}\frac{\textcolor{red}{R\cdot d\phi}}{\mathfrak{r}^2}\cdot \cos\theta
\end{equation*}
\paragraph{Based on the geometry, we see that}
\begin{equation*}
    \mathfrak{r}^2=R^2+z^2\quad\text{and}\quad \cos\theta=\frac{R}{\mathfrak{r}}=\frac{R}{\sqrt{(R^2+z^2)}}
\end{equation*}
\paragraph{Putting these together, we get}
\begin{align*}
     B_z(z)&=\frac{\mu_0I}{4\pi}\int_0^{2\pi}\frac{\textcolor{red}{R\cdot d\phi}}{\mathfrak{r}^2}\cos\theta\\
    B_z(z)&=\frac{\mu_0I}{4\pi}\int_0^{2\pi}\frac{\textcolor{red}{R\cdot d\phi}}{(R^2+z^2)}\cdot\frac{R}{\sqrt{R^2+z^2}}\\
    B_z(z)&=\frac{\mu_0I}{4\pi}\frac{R^2}{(R^2+z^2)^{\frac{3}{2}}}\int_0^{2\pi}d\phi\\
    B_z(z)&=\frac{\mu_0I}{4\pi}\frac{2\pi R^2}{(R^2+z^2)^{\frac{3}{2}}}\\
    B_z(z)&=\frac{\mu_0I}{2}\frac{R^2}{(R^2+z^2)^{\frac{3}{2}}}\\
    \boldsymbol{B}&=\frac{\mu_0I}{2}\frac{R^2}{(R^2+z^2)^{\frac{3}{2}}}\hat{\boldsymbol{z}}\\
\end{align*}
\paragraph{What do we get with this formula, for the case where we are at the center of the loop in the $xy$-plane ($z=0$)?}
\paragraph{We'd have:}
\begin{equation*}
    B_z(z=0)=\frac{\mu_0I}{2R}\longrightarrow \boldsymbol{B}(\boldsymbol{r}=0)=\frac{\mu_0I}{2R}\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{6. \textcolor{blue}{A Prelude}: We found the result on the $z$-axis for a current-carrying ring to be}
\begin{equation*}
    \boldsymbol{B}=\frac{\mu_0I}{2}\frac{R^2}{(R^2+z^2)^{\frac{3}{2}}}\hat{\boldsymbol{z}}
\end{equation*}
\begin{equation*}
    \boldsymbol{B}=2\bigg(\frac{\mu_0}{4\pi}\bigg)\frac{I\cdot\pi R^2}{\mathfrak{r}^3}\hat{\boldsymbol{z}}=2\bigg(\frac{\mu_0}{4\pi}\bigg)\frac{\textcolor{blue}{m}}{\mathfrak{r}^3}\quad:\quad\textcolor{blue}{m}=I\cdot\pi R^2=I\cdot(\text{area})
\end{equation*}
\paragraph{\indent a. But we've seen that the electric field on the $z$-axis for an \textcolor{blue}{electric dipole} is}
\begin{equation*}
    \boldsymbol{E}=\bigg(\frac{1}{4\pi\epsilon_0}\bigg)\frac{\textcolor{blue}{p}}{\mathfrak{r}^3}(2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}})=2\bigg(\frac{1}{4\pi\epsilon_0}\bigg)\frac{p}{\mathfrak{r}^3}\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{where $p$ is the electric dipole moment.}
\paragraph{\indent b. This suggests \textcolor{blue}{$m$} could be called the \textcolor{blue}{magnetic dipole moment}.}
\paragraph{\indent c. This further suggests we could have a multipole expansion for a "potential" from which $\boldsymbol{B}$ is derived (as $\boldsymbol{E}$ was derived from $V:\boldsymbol{E}=-\nabla V$).}
\paragraph{\indent d. Since there are no "magnetic charges", the \textcolor{blue}{magnetic dipole term} would be the first non-vanishing term in the multipole expansion of the "potential" from which $\boldsymbol{B}$ is derived. We will follow up on this later in this chapter.}
\subsection{The magnetic field $\boldsymbol{B}$ and the vector potential $\boldsymbol{A}$}
\subsubsection{Ampere's Law and $\boldsymbol{B}$}
\paragraph{1. The divergence of $\boldsymbol{B}$}
\paragraph{\indent a. The Biot-Savart Law for a volume current density $\boldsymbol{J}(\boldsymbol{r}')$ would be written as}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r}')=\frac{\mu_0}{4\pi}\int_V\frac{\boldsymbol{J}(\boldsymbol{r}')\times\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r',r})}{\mathfrak{r}^2(\boldsymbol{r',r})}d\tau'\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}'-\boldsymbol{r}
\end{equation*}
\paragraph{with the explicit coordinate dependence of the pieces as indicated.}
\paragraph{\indent b. Recall that the field divergence operator \textcolor{blue}{$\nabla\cdot$} is, for example,}
\begin{equation*}
    \textcolor{blue}{\nabla\cdot\boldsymbol{C}=\frac{\partial C_x}{\partial x}\hat{\boldsymbol{x}}+\frac{\partial C_y}{\partial y}\hat{\boldsymbol{y}}+\frac{\partial C_z}{\partial z}\hat{\boldsymbol{z}}}
\end{equation*}
\paragraph{involving only the field (\textcolor{blue}{unprimed}) coordinates $\boldsymbol{r}$. This divergence operator \textcolor{blue}{$\nabla\cdot$} does \textcolor{blue}{not} operate on source (primed) coordinates.}
\paragraph{\indent c. If we take the divergence of the magnetic field $\nabla\cdot \boldsymbol{B}(\boldsymbol{r})$, we have}
\begin{equation*}
    \textcolor{blue}{\nabla\cdot} \boldsymbol{B}(\boldsymbol{r})=\textcolor{blue}{\nabla\cdot} \bigg\{ \frac{\mu_0}{4\pi}\int_V\frac{\boldsymbol{J}(\boldsymbol{r}')\times\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r',\textcolor{blue}{r}})}{\mathfrak{r}^2(\boldsymbol{r',\textcolor{blue}{r}})}d\tau'\bigg\}
\end{equation*}
\begin{equation*}
    \textcolor{blue}{\nabla\cdot} \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int_V\textcolor{blue}{\nabla\cdot}\bigg(\boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r',\textcolor{blue}{r}})}{\mathfrak{r}^2(\boldsymbol{r',\textcolor{blue}{r}})}\bigg)d\tau'
\end{equation*}
\paragraph{\indent d. Product rule for operators states, $\nabla\cdot(\boldsymbol{C}\times\boldsymbol{D})=\boldsymbol{D}\cdot(\nabla\times\boldsymbol{C})-\boldsymbol{C}\cdot(\nabla\times\boldsymbol{D})$. So,}
\begin{equation*}
    \textcolor{blue}{\nabla\cdot}\bigg(\boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r',\textcolor{blue}{r}})}{\mathfrak{r}^2(\boldsymbol{r',\textcolor{blue}{r}})}\bigg)=\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\cdot(\textcolor{blue}{\nabla\times}\boldsymbol{J}(\boldsymbol{r}'))-\boldsymbol{J}(\boldsymbol{r}')\cdot\textcolor{blue}{\nabla\times}\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r',\textcolor{blue}{r}})}{\mathfrak{r}^2(\boldsymbol{r',\textcolor{blue}{r}})}
\end{equation*}
\paragraph{\indent\indent i. The \textcolor{red}{first term} on the right vanishes because the curl operator operates only on field coordinates \textcolor{blue}{$r$}, but the current density is a function solely of source coordinates ($\boldsymbol{r}'$).}
\paragraph{\indent\indent ii. The \textcolor{red}{second term} also vanishes because}
\begin{equation*}
    \textcolor{blue}{\nabla}\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}=0
\end{equation*}
\paragraph{You can prove this to yourself from scratch. But also you can recall from Classical Physics I that we showed (in a couple ways) that forces like gravity and the Coulomb force are conservative using $\nabla\times\boldsymbol{F}=0$:}
\begin{equation*}
    \nabla\times\boldsymbol{F}=\nabla\times\bigg\{ k\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}\bigg\}=k\nabla\times\bigg\{ \frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}\bigg\} =0 \quad: \quad\begin{cases}
        -GMm & \text{Gravity}\\
        \frac{Qq}{4\pi\epsilon_0} & \text{Coulomb}\\
    \end{cases}
\end{equation*}
\paragraph{\indent e. Thus we have the result that}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int_V \nabla\cdot\bigg(\boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}\bigg)d\tau'=0
\end{equation*}
\paragraph{\indent\indent i. No restrictions were placed on the volume current density $\boldsymbol{J}(\boldsymbol{r}')$.}
\paragraph{\indent\indent ii. In words: The \textcolor{blue}{net source density} of the magnetic field $\boldsymbol{B}(\boldsymbol{r})$ is always and everywhere zero.}
\paragraph{\indent\indent iii. As we've said before, this is not surprising. This is equivalent to the statement that \textcolor{blue}{there are no magnetic monopoles}.}
\paragraph{\indent f. Vector product identity states that, for any vector function $\boldsymbol{C}$, the divergence of the curl of $\boldsymbol{C}$ vanishes: $\nabla\cdot(\nabla\times\boldsymbol{C})=0$. Since we found that $\nabla\cdot\boldsymbol{B}(\boldsymbol{r})=0$, the vector identity implies that we could write the magnetic field as $\boldsymbol{B}=\nabla\times\boldsymbol{A}$. STAY TUNED!}
\paragraph{2. The curl of $\boldsymbol{B}(\boldsymbol{r})$}
\paragraph{\indent a. As before, we use the Biot-Savart Law for $\boldsymbol{B}(\boldsymbol{r})$ }
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int_V \boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}d\tau'
\end{equation*}
\paragraph{but this time we take the cross product $\nabla\times\boldsymbol{B}$}
\begin{equation*}
    \textcolor{blue}{\nabla}\times\boldsymbol{B}(\boldsymbol{r})=\textcolor{blue}{\nabla}\times\frac{\mu_0}{4\pi}\int_V \boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}d\tau'
\end{equation*}
\begin{equation*}
    \textcolor{blue}{\nabla}\times\boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int_V\textcolor{blue}{\nabla}\times\bigg(\boldsymbol{J}(\boldsymbol{r}')\times\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}\bigg) d\tau'
\end{equation*}
\paragraph{\textcolor{red}{We will now work on simplifying the integrand in this expression. Be patient.}}
\paragraph{\indent b. Vector product identity says we'll have four pieces to the integrand.}
\begin{equation*}
    \nabla\times(\boldsymbol{C}\times\boldsymbol{D})=(\boldsymbol{D}\cdot\nabla)\boldsymbol{C}-(\boldsymbol{C}\cdot\nabla)\boldsymbol{D}+\boldsymbol{C}(\nabla\cdot\boldsymbol{D})-\boldsymbol{D}(\nabla\cdot\boldsymbol{C})
\end{equation*}
\paragraph{with $\boldsymbol{C}=\boldsymbol{J}(\boldsymbol{r}')$ and $\boldsymbol{D}=\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})/\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})$, the integrand can we rewritten as}
\begin{equation*}
    \textcolor{blue}{\nabla}\times\bigg(\boldsymbol{J}\times\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\bigg)=\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\cdot\textcolor{blue}{\nabla}\bigg)\boldsymbol{J}(\boldsymbol{r}')-(\boldsymbol{J}\cdot\textcolor{blue}{\nabla})\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}+\boldsymbol{J}\bigg(\textcolor{blue}{\nabla}\cdot\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}\bigg)-\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}(\textcolor{blue}{\nabla}\cdot\boldsymbol{J}(\boldsymbol{r}'))
\end{equation*}
\paragraph{\indent\indent i. The \textcolor{red}{first and last terms} are zero because the operator \textcolor{blue}{$\nabla$} is acting on a quantity that is purely a function of the source coordinates.}
\paragraph{\indent\indent ii. In the \textcolor{red}{second term}, switch from \textcolor{blue}{$\nabla$} to $\nabla'$ for the "cost" of a minus sign:}
\begin{equation*}
    -(\boldsymbol{J}\cdot\nabla)\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=(\boldsymbol{J}\cdot\nabla')\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\quad:\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}-\boldsymbol{r}'
\end{equation*}
\paragraph{Further, with the vector product rule, this can be expressed as}
\begin{equation*}
    (\boldsymbol{J}\cdot\nabla')\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\nabla'\cdot\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\boldsymbol{J}\bigg)-\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}(\nabla'\cdot\boldsymbol{J})
\end{equation*}
\paragraph{\indent\indent iii. In the \textcolor{red}{third term}, recall that }
\begin{equation*}
    \textcolor{blue}{\nabla}\cdot\frac{\hat{\boldsymbol{\mathfrak{r}}}(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}{\mathfrak{r}^2(\boldsymbol{r}',\textcolor{blue}{\boldsymbol{r}})}=\textcolor{blue}{\nabla}\cdot\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=4\pi\delta^3(\boldsymbol{\mathfrak{r}})\quad:\quad \boldsymbol{\mathfrak{r}}=\boldsymbol{r}-\boldsymbol{r}'
\end{equation*}
\paragraph{\indent d. Hence, our equation for $\nabla\times\boldsymbol{B}(\boldsymbol{r})$ becomes}
\begin{equation*}
    \nabla\times\boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\bigg\{ \nabla'\cdot\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\boldsymbol{J}\bigg)-\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}(\nabla'\cdot\boldsymbol{J})+\boldsymbol{J}(\boldsymbol{r}')4\pi\delta^3(\boldsymbol{\mathfrak{r}})\bigg\}d\tau'
\end{equation*}
\begin{equation*}
    =\frac{\mu_0}{4\pi}\int_V\nabla'\cdot\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\boldsymbol{J}\bigg)d\tau'-\frac{\mu_0}{4\pi}\int_V\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}(\nabla'\cdot\boldsymbol{J})d\tau'+\frac{\mu_0}{4\pi}\int_V\boldsymbol{J}(\boldsymbol{r}')4\pi\delta^3(\boldsymbol{\mathfrak{r}})d\tau'
\end{equation*}
\paragraph{\indent e. This three-term expression can be simplified.}
\paragraph{\indent\indent i. Earlier, we derived the continuity equation $\nabla\cdot\boldsymbol{J}=-\frac{d\rho}{dt}$.}
\paragraph{\indent\indent $\cdot$ With steady currents, the divergence $\nabla\cdot\boldsymbol{J}$ must be zero.}
\paragraph{\indent\indent $\cdot$ Thus, the \textcolor{red}{second term} vanishes, and we are left with}
\begin{equation*}
    \nabla\times\boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int_V\nabla'\cdot\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\boldsymbol{J}\bigg)d\tau'+\frac{\mu_0}{4\pi}\int_V\boldsymbol{J}(\boldsymbol{r}')4\pi\delta^3(\boldsymbol{\mathfrak{r}})d\tau'
\end{equation*}
\paragraph{\indent\indent ii. Applying the Divergence Theorem of Gauss on the first term, we have}
\begin{equation*}
    \nabla\times\boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\oint_S\bigg(\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}\cdot\boldsymbol{J}\bigg)\cdot\boldsymbol{da}'+\frac{\mu_0}{4\pi}\oint_V \boldsymbol{J}(\boldsymbol{r}')4\pi\delta^3(\boldsymbol{\mathfrak{r}})d\tau'
\end{equation*}
\paragraph{\indent\indent $\cdot$ What volume $V$ should we use for these integrations? To be completely general, let's integrate over all space.}
\paragraph{\indent\indent $\cdot$ Integrating, the last term over all space (remember: $d\tau$ is in source coordinates), the $\delta^3(\boldsymbol{\mathfrak{r}}=\boldsymbol{r}-\boldsymbol{r}'$ function will "sift" out $\mu_0\boldsymbol{J}(\boldsymbol{r})$.}
\paragraph{\indent\indent $\cdot$ If the current density $\boldsymbol{J}$ is \textcolor{blue}{finite}, and, as we did for $V$, we integrate over all space, the first term will vanish on the surface $S$ because the current density $\boldsymbol{J}$ will be zero at infinity.}
\paragraph{\indent f. Thus, we (at last!) get the expression }
\begin{equation*}
    \textcolor{blue}{\nabla\times\boldsymbol{B}(\boldsymbol{r})=\mu_0\boldsymbol{J}(\boldsymbol{r})\quad:\quad \text{Ampere's Law (Differential form)}}
\end{equation*}
\paragraph{\indent g. We can recast this "differential form" of Ampere's Law into an integral form.}
\paragraph{\indent\indent i. First take the component of each side of this equation through some particular surface of interest.}
\begin{equation*}
    \nabla\times\boldsymbol{B}(\boldsymbol{r})=\mu_0\boldsymbol{J}(\boldsymbol{r})\rightarrow\iint_S(\nabla\times\boldsymbol{B}(\boldsymbol{r}))\cdot\boldsymbol{da}=\iint_S\mu_0\boldsymbol{J}(\boldsymbol{r})\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent\indent ii. Next, apply Stokes' Theorem to the left hand side of this expression:}
\begin{equation*}
    \iint_S(\nabla\times\boldsymbol{B}(\boldsymbol{r}))\cdot\boldsymbol{da}=\oint_C \boldsymbol{B}(\boldsymbol{r})\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent\indent iii. The right hand side of the expression in (i) is the current enclosed by the loop defined by contour $C$ in the Stokes' theorem result.}
\begin{equation*}
    \iint_S \mu_0\boldsymbol{J}(\boldsymbol{r})\cdot\boldsymbol{da}=\mu_0 I_{encl}
\end{equation*}
\paragraph{\indent\indent iv. Putting the results from (ii) and (iii) together, we arrive at the \textcolor{blue}{integral form of Ampere's Law}:}
\begin{equation*}
    \textcolor{blue}{\oint_C \boldsymbol{B}(\boldsymbol{r})\cdot\boldsymbol{dl}=\mu_0 I_{encl}\quad:\quad \text{Ampere's Law (Integral form)}}
\end{equation*}
\paragraph{\indent\indent $\cdot$ Note this relationship between $S$ and $C$.}
\begin{equation*}
    \oint_C\boldsymbol{B}(\boldsymbol{r})\cdot\boldsymbol{dl}=\iint_S\mu_0\boldsymbol{J}(\boldsymbol{r})\cdot\boldsymbol{da}=\mu_0 I_{encl}
\end{equation*}
\paragraph{\indent\indent \textcolor{blue}{The direction of $\boldsymbol{J}(\boldsymbol{r})$ (and hence the direction of $I_{encl}$) will determine the direction of $\boldsymbol{B}(\boldsymbol{r})$}. This is because the right hand convention for doing the contour integration determines the sign/sense of $\boldsymbol{dl}$ and $\boldsymbol{da}$.}
\paragraph{\indent\indent $\cdot$ \textcolor{blue}{If} a symmetry is present in the current distribution for a problem, the contour $C$ can be chosen such that $\boldsymbol{B}(\boldsymbol{r})$ is constant during the integration. (This contour $C$ would be called an "\textcolor{blue}{Amperian loop}".)}
\paragraph{\indent\indent $\checkmark$ If such a choice is possible, the left hand side is simply $B\oint dl=BL$, where $L$ is the length of the contour $C$. The right hand side is just $\mu_0I_{encl}$.}
\paragraph{\indent\indent $\checkmark$ This is analogous to the utility of the integral form of Gauss' Law. We found the electric field $\boldsymbol{E}$ easily if a symmetry was present in a charge distribution.}
\paragraph{\indent\indent $\checkmark$ If the symmetry is not present, the relationship above is still true.}
\paragraph{\indent h. We can make a number of analogies/comparisons between $\boldsymbol{E}$ and $\boldsymbol{B}$.}
\paragraph{\indent\indent i. We have both differential and integral defining relationships for electrostatics and magnetostatics - \textcolor{blue}{Maxwell's equations for static charges and currents}:}
\begin{align*}
    \nabla\cdot\boldsymbol{E}&=\frac{\rho}{\epsilon_0}\rightarrow \oiint \boldsymbol{E}\cdot\boldsymbol{da}=\frac{Q_{encl}}{\epsilon_0}\quad:\quad \text{\textcolor{blue}{Gauss' Law}}\\
    \nabla\cdot\boldsymbol{B}&=0\rightarrow \oiint\boldsymbol{B}\cdot\boldsymbol{da}=0\quad:\quad \text{\textcolor{blue}{The $B$ Law with No Name}}\\
    \nabla\times\boldsymbol{E}&=0\rightarrow \oint\boldsymbol{E}\cdot\boldsymbol{dl}=0\quad:\quad \text{\textcolor{blue}{The $E$ Law with No Name}}\\
    \nabla\times\boldsymbol{B}&=\mu_0\boldsymbol{J}\rightarrow\oint\boldsymbol{B}\cdot\boldsymbol{dl}=\mu_0I_{encl}\quad:\quad \text{\textcolor{blue}{Ampere's Law}}\\
\end{align*}
\paragraph{\indent\indent ii. Each named law stems from an experimental law: Gauss' Law comes from \textcolor{blue}{Coulomb's Law}. Ampere's Law comes from the \textcolor{blue}{Biot-Savart Law}.}
\paragraph{\indent\indent iii. We derive boundary conditions for the magnetic field $\boldsymbol{B}$ as we did for the electric field $\boldsymbol{E}$: Look at \textcolor{blue}{(1)} little volumes (pillboxes) with the Divergence Theorem of Gauss, and look at \textcolor{blue}{(2)} little contours (little square loops) with Stokes' Theorem for the Curl.}
\paragraph{\indent\indent iv. We will use the Helmholtz theorem later to establish uniqueness for $\boldsymbol{B}$.}
\subsubsection{The vector potential $\boldsymbol{A}$}
\paragraph{1. We noted earlier that, since $\nabla\cdot\boldsymbol{B}=0$, we can define a \textcolor{blue}{vector potential $A$} using $\boldsymbol{B}=\nabla\times\boldsymbol{A}$, since $\nabla\cdot(\nabla\times\boldsymbol{A})=0$ automatically.}
\paragraph{\indent a. Because $\nabla\times(\nabla\boldsymbol{F})=0$ is also true, defining the vector potential as $\boldsymbol{B}=\nabla\times\boldsymbol{A}$ means that, in principle, an infinite number of choices exist for the vector potential $\boldsymbol{A}$ that will give precisely the same as $\boldsymbol{B}$:}
\begin{equation*}
    \boldsymbol{A'}=\boldsymbol{A}+\nabla f\rightarrow \boldsymbol{B}=\nabla\times\boldsymbol{A}=\nabla\times\boldsymbol{A'}
\end{equation*}
\paragraph{\indent b. The freedom to arbitrarily adjust the vector potential $\boldsymbol{A}$ as we like is called "\textcolor{blue}{gauge invariance}" or "\textcolor{blue}{gauge freedom}".}
\paragraph{\indent\indent i. With the vector product rule, we get}
\begin{equation*}
    \nabla\times\boldsymbol{B}=\nabla\times(\nabla\times\boldsymbol{A})=\nabla(\nabla\cdot\boldsymbol{A})-\nabla^2\boldsymbol{A}=\mu_0\boldsymbol{J}
\end{equation*}
\paragraph{\indent\indent ii. We can use gauge freedom to make $\nabla\cdot\boldsymbol{A}=0$. This choice is called the "\textcolor{blue}{Coulomb gauge}" or "\textcolor{blue}{transverse gauge}".}
\paragraph{\indent\indent iii. Other choices for $\nabla \cdot \boldsymbol{A}$ might prove to be useful in other circumstances.}
\paragraph{\indent c. If we \textcolor{blue}{choose} $\nabla\cdot\boldsymbol{A}=0$, then we find}
\begin{equation*}
    \nabla\times\boldsymbol{B}=\nabla\times(\nabla\times\boldsymbol{A})=\nabla(\nabla\cdot\boldsymbol{A})-\nabla^2\boldsymbol{A}=\mu_0\boldsymbol{J}\rightarrow \textcolor{red}{\nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J}} \quad\text{(in Couloumb Gauge)}
\end{equation*}
\paragraph{\indent\indent i. This expression using the \textcolor{blue}{Coulomb gauge} yields \textcolor{blue}{a set of Poisson equations}, one for each component of the current density vector.}
\paragraph{\indent\indent ii. In previous chapters, we saw that, for a finite \textcolor{blue}{charge} distribution $\rho(\boldsymbol{r}')$, Poisson's equation led to a definition of the electric potential $V(\boldsymbol{r})$}
\begin{align*}
    \nabla^2V&=-\frac{\rho}{\epsilon_0}\\
    \rightarrow V(\boldsymbol{r})&=\frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r}')}{\mathfrak{r}}d\tau'
\end{align*}
\paragraph{\indent\indent iii. Evidently, then, for a finite \textcolor{blue}{current} distribution $\boldsymbol{J}(\boldsymbol{r}')$ we will have}
\begin{align*}
    \nabla^2\boldsymbol{A}&=-\mu_0\boldsymbol{J}\\
    \rightarrow \boldsymbol{A}(\boldsymbol{r})&=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{J}(\boldsymbol{r}')}{\mathfrak{r}}d\tau'
\end{align*}
\begin{equation*}
    \nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J}\longrightarrow\boldsymbol{A}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{J}(\boldsymbol{r}')}{\mathfrak{r}}d\tau'
\end{equation*}
\paragraph{\indent\indent $\cdot$ As we said, this is equivalent to a set of Poisson equations, one for each vector component of the current density. We could also write}
\begin{equation*}
    \boldsymbol{A}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{I}(\boldsymbol{r}')}{\mathfrak{r}}dl'\quad\text{and}\quad \boldsymbol{A}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{K}(\boldsymbol{r}')}{\mathfrak{r}}da'
\end{equation*}
\paragraph{\indent\indent $\cdot$ $\boldsymbol{A}(\boldsymbol{r)}$ depends linearly on $\boldsymbol{J}(\boldsymbol{r}')$, so \textcolor{blue}{superposition} applies to $\boldsymbol{A}(\boldsymbol{r})$. For any composite current distribution, we can put together a composite $\boldsymbol{A}(\boldsymbol{r})$.}
\paragraph{\indent\indent $\cdot$ Since $\boldsymbol{A}(\boldsymbol{r})$ is a vector, the vector potential is not as easy to use for magnetostatics as the electric potential $V$ was for electrostatics.}
\paragraph{\indent\indent $\cdot$ Even so, $\boldsymbol{A}(\boldsymbol{r})$ will be very useful for your studies in electromagnetic waves.}
\paragraph{\indent\indent $\cdot$ $\boldsymbol{A}(\boldsymbol{r})$ also is useful for Lagrangian or Hamiltonian formulations of mechanics (and quantum mechanics). (For example, go back and look at how we used the vector potential $\boldsymbol{A}(\boldsymbol{r})$ in Classical Physics 1 while we discussed the Lagrangian approach to the Lorentz force.)}
\paragraph{\indent\indent $\cdot$ $\boldsymbol{A}$ or $\boldsymbol{B}$: Which is "real" and which is a mathematical convenience? (Give this some thought.)}
\paragraph{\indent d. Suppose we have a uniform magnetic field $\boldsymbol{B}=B_0\hat{\boldsymbol{z}}$. What might be the vector potential $\boldsymbol{A}$ that gives rise to this magnetic field $\boldsymbol{B}$?}
\paragraph{\indent\indent i. Each of the following vector potentials will generate $\boldsymbol{B}=B_0\hat{\boldsymbol{z}}:$}
\begin{equation*}
    \boldsymbol{A}_1=\frac{B_0}{2}(-y\hat{\boldsymbol{x}}+x\hat{\boldsymbol{y}})\quad \text{or}\quad \boldsymbol{A}_2=-B_0y\hat{\boldsymbol{x}}\quad\text{or}\quad \boldsymbol{A}_3=B_0x\hat{\boldsymbol{y}}
\end{equation*}
\paragraph{\indent\indent $\cdot$ $\boldsymbol{A}_1$ looks like a solenoidal current density.}
\paragraph{\indent\indent $\cdot$ $\boldsymbol{A}_2$ and $\boldsymbol{A}_3$ are like current sheets... but in orthogonal directions!}
\paragraph{\indent\indent $\cdot$ Notice that these satisfy $\boldsymbol{A}_1=\boldsymbol{A}_2+\nabla(\frac{B_0}{2}xy)$... gauge freedom.}
\paragraph{\indent\indent ii. So \underline{very different} geometries of current sources can produce \underline{identical} magnetic fields $\boldsymbol{B}$!}
\paragraph{\indent\indent iii. The current sources are the physical objects, so this suggests that the vector potential $\boldsymbol{A}$ may be the fundamental quantity, while the magnetic field $\boldsymbol{B}$ is a mathematical convenience for Newtonian mechanics.}
\paragraph{\indent\indent iv. In quantum mechanics, the \textcolor{blue}{Aharonov-Bohm effect} suggests the same point: the vector potential $\boldsymbol{A}$ seems to be the fundamental entity.}
\paragraph{\indent \textcolor{red}{Note: A uniform magnetic field also comes from $\boldsymbol{A}=-\frac{1}{2}\boldsymbol{r}\times\boldsymbol{B}$. Try it!}}
\paragraph{\indent e. The net flux and the circulation of the vector fields $\boldsymbol{A}$ and $\boldsymbol{B}$.}
\paragraph{\indent \indent i. The \textcolor{blue}{net flux} of a vector field $\boldsymbol{G}(\boldsymbol{r})$ through a surface $S$ is given by}
\begin{equation*}
    d\Phi=\boldsymbol{G}\cdot\boldsymbol{da}\longrightarrow\iint_S\boldsymbol{G}\cdot\boldsymbol{da}=\Phi_G
\end{equation*}
\paragraph{\indent $\cdot$ For example, the net flux of the current density $\boldsymbol{J}$ through a surface $S$ (what we normally call the current $I$) is}
\begin{equation*}
    \iint_S\boldsymbol{J}\cdot\boldsymbol{da}=\Phi_J=I
\end{equation*}
\paragraph{\indent $\cdot$ The net flux of $\boldsymbol{J}$ through a closed surface $S'$ would be written as}
\begin{equation*}
    \oiint_S\boldsymbol{J}\cdot\boldsymbol{da}=\Phi_J
\end{equation*}
\paragraph{\indent $\cdot$ The net fluxes of the electric field $\boldsymbol{E}$ and the magnetic field $\boldsymbol{B}$ through a surface $S$ would be written, respectfully, as}
\begin{equation*}
    \iint_S\boldsymbol{E}\cdot\boldsymbol{da}=\Phi_E\quad\text{and}\quad \iint_S\boldsymbol{B}\cdot\boldsymbol{da}=\Phi_B
\end{equation*}
\paragraph{\indent \indent ii. The \textcolor{blue}{circulation} of a vector field $\boldsymbol{G}(\boldsymbol{r})$ about/around the closed contour $C$ is }
\begin{equation*}
    \oint_C\boldsymbol{G}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent $\cdot$ For example, the circulation of the electric field $\boldsymbol{E}$ about the closed contour $C$ is }
\begin{equation*}
    \oint_C\boldsymbol{E}\cdot\boldsymbol{dl} \equiv \varepsilon \quad \text{\textcolor{blue}{electromotive force}}
\end{equation*}
\paragraph{\indent $\cdot$ The circulation of the magnetic field $\boldsymbol{B}$ around the closed contour $C$ is }
\begin{equation*}
    \oint_C\boldsymbol{B}\cdot\boldsymbol{dl} \equiv \mu_0I_{encl}\quad \text{\textcolor{blue}{Ampere's Law}}
\end{equation*}
\paragraph{\indent $\cdot$ The circulation of the magnetic vector potential $\boldsymbol{A}$ on the closed contour is}
\begin{equation*}
    \oint_C\boldsymbol{A}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent\indent iii. We know that the magnetic field $\boldsymbol{B}$ can be written as $\boldsymbol{B}=\nabla\times\boldsymbol{A}$.}
\paragraph{\indent $\cdot$ Thus, the flux of the magnetic field $\boldsymbol{B}$ through the surface $S$ is}
\begin{equation*}
    \Phi_B=\iint_S\boldsymbol{B}\cdot\boldsymbol{da}=\iint_S(\nabla\times\boldsymbol{A})\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent $\cdot$ But with Stoke's Theorem of the Curl, we can write this as}
\begin{equation*}
    \Phi_B=\iint_S(\nabla\times\boldsymbol{A})\cdot\boldsymbol{da}=\oint_C\boldsymbol{A}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent $\cdot$ Thus, if there is \underline{any} net flux $\Phi_B$ of the magnetic field $\boldsymbol{B}$ through the surface $S$, then the circulation of the vector potential $\boldsymbol{A}$ will be equal to that flux (i.e., the circulation of $\boldsymbol{A}$ will be non-zero).}
\paragraph{\indent $\cdot$ So, thanks to Stokes' Theorem of the Curl, we could say that the curl of a vector field is the "\textcolor{blue}{circulation per unit area}" of that vector field.}
\paragraph{\indent \indent When we study changing electric and magnetic fields in later chapters, these concepts will be very important. But we can use them now as well.}
\subsubsection{Comparison of electrostatics and magnetostatics}
\paragraph{1. The Helmholtz theorem: When is a vector field $\boldsymbol{G}(\boldsymbol{r})$ uniquely defined?}
\paragraph{\indent a. For a vector field $\boldsymbol{G}(\boldsymbol{r)}$, IF}
\paragraph{\indent\indent i. The divergence $D(\boldsymbol{r})$ and the curl $\boldsymbol{C}(\boldsymbol{r})$ for $\boldsymbol{G}(\boldsymbol{r})$ are specified \textcolor{red}{AND}}
\paragraph{\indent\indent ii. Both $D(\boldsymbol{r})$ and $\boldsymbol{C}(\boldsymbol{r})$ go to zero faster than $1/r^2$ as $r\rightarrow \infty$ \textcolor{red}{AND}}
\paragraph{\indent \indent iii. $\boldsymbol{G}(\boldsymbol{r})$ goes to zero as $r\longrightarrow \infty$}
\paragraph{\indent b. \textcolor{blue}{THEN} $\boldsymbol{G}(\boldsymbol{r})$ is uniquely given by}
\begin{equation*}
    \boldsymbol{G}(\boldsymbol{r})=-\nabla V+\nabla\times\boldsymbol{W}
\end{equation*}
\paragraph{where}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi}\int\frac{D(\boldsymbol{r}')}{\mathfrak{r}}d\tau'\quad\text{and}\quad \boldsymbol{W}(\boldsymbol{r})\equiv\frac{1}{4\pi}\int \frac{\boldsymbol{C}(\boldsymbol{r}')}{\mathfrak{r}}d\tau'
\end{equation*}
\paragraph{Let's apply the Helmholtz theorem to the magnetic field $\boldsymbol{B}$ in magnetostatics. Recall that we have found that}
\begin{equation*}
    D(\boldsymbol{r})=\nabla\cdot\boldsymbol{B}(\boldsymbol{r})=0\quad\text{and}\quad \boldsymbol{C}(\boldsymbol{r})=\nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}(\boldsymbol{r})
\end{equation*}
\paragraph{\indent a. For the vector field $\boldsymbol{B}(\boldsymbol{r})$, \textcolor{blue}{IF}}
\paragraph{\indent\indent i. The divergence $D(\boldsymbol{r})$ and curl $\boldsymbol{C}(\boldsymbol{r})$ for $\boldsymbol{G}(\boldsymbol{r})$ are specified \textcolor{red}{AND}}
\paragraph{\indent\indent ii. Both $D(\boldsymbol{r})$ and $\boldsymbol{C}(\boldsymbol{r})$ go to zero faster than 1/$r^2$ as $r\rightarrow \infty$ \textcolor{red}{AND}}
\paragraph{\indent \indent \checkmark \quad $D(\boldsymbol{r})$ is zero all the time}
\paragraph{\indent\indent \checkmark \quad We require that $\boldsymbol{J}(\boldsymbol{r})\rightarrow 0 $ faster than $\frac{1}{r^2}$}
\paragraph{\indent\indent iii. $\boldsymbol{G}(\boldsymbol{r})$ goes to zero as $r\rightarrow\infty$}
\paragraph{\indent \textcolor{blue}{Then} $\boldsymbol{G}(\boldsymbol{r})$ is uniquely given by}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=-\nabla V+\nabla\times \boldsymbol{A}\rightarrow \boldsymbol{B}=\nabla\times\boldsymbol{A}
\end{equation*}
\paragraph{Where}
\begin{equation*}
    V(\boldsymbol{r})\equiv\frac{1}{4\pi}\int\frac{D(\boldsymbol{r})}{\mathfrak{r}}d\tau'\quad\text{and}\quad \boldsymbol{A}(\boldsymbol{r})\equiv\frac{1}{4\pi}\int\frac{\mu_0\boldsymbol{J}(\boldsymbol{r})}{\mathfrak{r}}d\tau'
\end{equation*}
\paragraph{2. The magnetostatic triangle}
\paragraph{\indent a. In electrostatics, we established a triangle of relationships for}
\paragraph{\indent $\cdot$ Electric Field $\boldsymbol{E}(\boldsymbol{r})$,}
\paragraph{\indent $\cdot$ Electric potential $V(\boldsymbol{r})$, and }
\paragraph{\indent $\cdot$ "static" (i.e., stationary) charge density $\rho(\boldsymbol{r})$.}
\paragraph{\indent b. In magnetostatics, we have established a triangle of relationships involving the}
\paragraph{\indent $\cdot$ Magnetic field $\boldsymbol{B}(\boldsymbol{r})$,}
\paragraph{\indent $\cdot$ magnetic vector potential $\boldsymbol{A}(\boldsymbol{r})$, and}
\paragraph{\indent $\cdot$ "steady" current density $\boldsymbol{J}(\boldsymbol{r})$.}
\paragraph{3. The multipole expansion of the vector potential $\boldsymbol{A}(\boldsymbol{r})$}
\paragraph{\indent a. We have seen that the magnetic vector potential $\boldsymbol{A}(\boldsymbol{r})$ may be written}
\begin{equation*}
    \boldsymbol{A}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{J}(\boldsymbol{r'})}{\mathfrak{r}}d\tau'\quad\text{or}\quad\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{K}(\boldsymbol{r}')}{\mathfrak{r}}da'\quad\text{or}\quad\frac{\mu_0I}{4\pi}\int\frac{\boldsymbol{dl}'}{\mathfrak{r}}:\mathfrak{r}=\boldsymbol{r}-\boldsymbol{r}'
\end{equation*}
\paragraph{\indent b. For an \textcolor{blue}{azimuthally-symmetric charge distribution}, we found it useful to write the electric (scalar) potential $V(\boldsymbol{r})$ as a \textcolor{blue}{multipole expansion}}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int\frac{\rho(\boldsymbol{r}')}{\mathfrak{r}}d\tau'=\frac{1}{4\pi\epsilon r}\sum_{n=0}^{\infty}\frac{Q_n}{r^n}P_n(\cos\theta)
\end{equation*}
\paragraph{where $Q_n\equiv\int dQ'(\boldsymbol{r}')r'^nP_n(\cos\theta)$.}
\paragraph{How is this useful?}
\paragraph{\indent i. This multipole expansion formalism allowed us to approximate $V(\boldsymbol{r})$ for complicated charge distributions.}
\paragraph{\indent ii. This formalism also established the behavior of $V(\boldsymbol{r})$ at large distances.}
\paragraph{\indent iii. This formalism bolstered our confidence in (and smoothed the path to) the results obtained in earlier chapters for electric fields in materials.}
\paragraph{\indent c. Following this approach, we expect it will be useful for \textcolor{blue}{azimuthally-symmetric current distributions} to write a multipole expansion of the magnetic vector potential $\boldsymbol{A}(\boldsymbol{r})$ for a loop of current as }
\begin{equation*}
    \boldsymbol{A}(\boldsymbol{r})=\frac{\mu_0}{4\pi r}\sum_{n=0}^{\infty}\frac{\mathfrak{I}_n}{r_n}P_n(\cos\theta)
\end{equation*}
\paragraph{where $\mathfrak{I}_n\equiv I\oint d\boldsymbol{l}r'^nP_n(\cos\theta')$ (here we are using a script I)}
\paragraph{\indent i. If $\theta=0$, we get the wimpy result in most physics textbooks}
\paragraph{\indent ii. The vector nature of this expression complicates things quite a bit.}
\paragraph{\indent iii. For non-azimuthally-symmetric current distributions, one would need much mathematical tools: \textcolor{blue}{vector spherical harmonics}. multipole moment tensors, etc.}
\paragraph{\indent iv. At very large distances (i.e., $r$ is much greater than the dimensions of the current distribution), the first non-vanishing term of this expression for $\boldsymbol{A}(\boldsymbol{r})$ will dominate the higher-order terms.}
\paragraph{\indent d. Looking at the \textcolor{blue}{monopole} n=0 term $\mathfrak{I}_n$ for a current loop, we see that}
\begin{equation*}
    \mathfrak{I}_0=\oint\boldsymbol{dl}'r'^0P_0(\cos\theta')=\oint\boldsymbol{dl}'=0
\end{equation*}
\paragraph{\indent i. What can we say about the magnetic field $\boldsymbol{B}$?}
\paragraph{\indent $\cdot$ The electric field was found with $\boldsymbol{E}=-\nabla V(\boldsymbol{r})$ using the multipole expansion of $V(\boldsymbol{r})$. At large distances, $\boldsymbol{E}$ was dominated by the term arising from the monopole moment of the charge distribution \textcolor{blue}{if} that monopole moment did not vanish (i.e., a net charge).}
\paragraph{\indent $\cdot$ Similarly, for the magnetic field $\boldsymbol{B}$, we would use $\boldsymbol{B}=\nabla\times\boldsymbol{A}$ with the multipole expansion for $\boldsymbol{A}$. At large distances, $\boldsymbol{B}$ would be dominated by the contribution from the first non-vanishing term of the multipole expansion of the vector potential $\boldsymbol{A}$.}
\paragraph{\indent ii. Since the integral in $\mathfrak{I}_0$ is zero for a loop (why?), this is no monopole term in the expansion of $\boldsymbol{A}$ and \textcolor{blue}{no monopole contribution term in $\boldsymbol{B}$}.}
\paragraph{\indent iii. For an arbitrary $\boldsymbol{J}(\boldsymbol{r})$, we could compose $\boldsymbol{J}(\boldsymbol{r})$ from little loops, provided there are no sources or sinks of $\boldsymbol{J}(\boldsymbol{r})$ (i.e., $\nabla\cdot\boldsymbol{J}=0$).}
\paragraph{\indent iv. Now let's focus on just the \textcolor{blue}{dipole} term $(n=1$ term: $\mathfrak{I}_1$) in the multipole expansion of the vector potential $\boldsymbol{A}$ for a current loop.}
\paragraph{\indent\indent i. Following the expansion formula,}
\begin{equation*}
    \mathfrak{I}_n\equiv\oint d\boldsymbol{l}r'^n P_n(\cos\theta')
\end{equation*}
\paragraph{we would get for $n=1$}
\begin{equation*}
    \mathfrak{I}_1=I\oint\boldsymbol{dl}'(r')^1\cdot P_1(\cos\theta')=I\oint\boldsymbol{dl}'\cdot r'\cdot\cos\theta'
\end{equation*}
\paragraph{\indent\indent ii. The $n=1$ dipole term in the multipole expansion of the vector potential $\boldsymbol{A}$ would be}
\begin{align*}
    \boldsymbol{A}_1&=\frac{\mu_0}{4\pi r}\cdot\frac{\mathfrak{I}_1}{r}\cdot P_1(\cos\theta)  \\
    \boldsymbol{A}_1&=\frac{\mu_0 I}{4\pi r^2}\oint\boldsymbol{dl}'r'\cos\theta'\cos\theta \\
    \boldsymbol{A}_1&=\frac{\mu_0 I}{4\pi r^2}\oint\boldsymbol{dl}'(\boldsymbol{r}'-\hat{\boldsymbol{r}})\\
    \boldsymbol{A}_1&=\frac{\mu_0 I}{4\pi r^2}(-\hat{\boldsymbol{r}})\times\int_S \boldsymbol{da}\\
    \boldsymbol{A}_1&=\frac{\mu_0}{4\pi r^2} \boldsymbol{m}\times\hat{\boldsymbol{r}}\quad:\quad \boldsymbol{m}=\int_S I\boldsymbol{da}\\
\end{align*}    
\paragraph{where $\boldsymbol{m}$ is the \textcolor{blue}{magnetic dipole moment} of the current loop. The term $\boldsymbol{A}_1$ is the first possible non-vanishing term of the multipole expansion for the vector potential $\boldsymbol{A}$.}
\paragraph{\indent\indent iii. Compare this $\boldsymbol{A}_1$ term with the electric dipole term for $V(r)$}
\begin{equation*}
    V_{dipole}=\frac{1}{4\pi\epsilon_0r^2}\boldsymbol{p}\cdot\hat{\boldsymbol{r}}\quad:\quad \text{Longitudinal}
\end{equation*}
\begin{equation*}
    \boldsymbol{A}_{dipole}=\frac{\mu_0}{4\pi r^2}\boldsymbol{m}\times\hat{\boldsymbol{r}}\quad:\quad \text{Transverse}
\end{equation*}
\paragraph{\indent e. We could, in principle, break any current distribution $\boldsymbol{J}(\boldsymbol{r}')$ into a series of flat loops, and then use the principle of superposition to get the total magnetic vector potential $\boldsymbol{A}$ for that distribution. We would need to keep track of which way the loops were pointed.}
\paragraph{\indent f. \textcolor{blue}{The electron's gyro-magnetic ratio}: Find the ratio of the magnetic dipole moment of a thin uniform donut of mass $M$ and radius $R$ which carries a charge $Q$, rotating about its axis. Then take the ratio of that magnetic dipole moment to the angular momentum of the donut.}
\paragraph{\indent\indent i. If the donut spins with angular momentum $\omega$, then the current $I$ generated by the donut would be equal to}
\begin{equation*}
    I=Q\cdot\frac{\omega}{2\pi}
\end{equation*}
\paragraph{\indent\indent ii. The \textcolor{blue}{cross sectional area} of the donut shaped loop (not the area of the donut) is $\boldsymbol{a}=\pi R^2\hat{\boldsymbol{z}}$.}
\paragraph{\indent\indent iii. The magnetic dipole moment for the donut current loop will be}
\begin{equation*}
    \boldsymbol{m}=I\boldsymbol{a}=Q\cdot\frac{\omega}{2\pi}\cdot\pi R^2\hat{\boldsymbol{z}}
\end{equation*}
\begin{equation*}
    \boldsymbol{m}=\frac{Q}{2}\omega R^2\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{\indent\indent iv. The angular momentum \textcolor{blue}{L} of the donut will be given by $\textcolor{blue}{\boldsymbol{L}=\boldsymbol{r}\times\boldsymbol{p}=M\omega R^2\hat{\boldsymbol{z}}}$.}
\paragraph{\indent\indent v. The magnetic dipole moment $\boldsymbol{m}$ thus could be written as}
\begin{equation*}
    \boldsymbol{m}=\frac{Q}{2}\omega R^2\hat{\boldsymbol{z}}=\frac{Q}{2M}\textcolor{blue}{M\omega R^2}\hat{\boldsymbol{z}}
\end{equation*}
\begin{equation*}
\boldsymbol{m}=\bigg(\frac{Q}{2M}\bigg)\boldsymbol{L}=g\boldsymbol{L}\quad:\quad\textcolor{blue}{g=\frac{Q}{2M}}\quad\text{"gyromagnetic ratio"}
\end{equation*}
\paragraph{\indent\indent vi. The result for the donut contains \textcolor{blue}{nothing specific about the geometry} of the donut: $R$ appears nowhere in the result. Thus, any object we can build from donuts will have the same gyromagnetic ratio.}
\paragraph{\indent\indent vii. For example, we can certainly build a \textcolor{blue}{solid sphere} with mass $M$ and charge $Q$ rotating with angular velocity $\omega$ from a series of donuts with mass $dM$ and charge $dQ$. The gyromagnetic ratio for the solid sphere would still be $\textcolor{blue}{g=Q/2M}$.}
\paragraph{\indent\indent viii. Imagine \textcolor{blue}{the electron} is a solid sphere with charge $Q=-e$ spinning about its axis with angular momentum $\boldsymbol{L}=\hbar/2$.}
\paragraph{\indent\indent ix. The \textcolor{blue}{classical} prediction for the \textcolor{blue}{magnetic dipole moment of the electron} would thus be}
\begin{equation*}
    |\boldsymbol{m}_e|=\bigg(\frac{Q}{2M}\bigg)|\boldsymbol{L}|=\frac{1}{2}\bigg(\frac{e\hbar}{2m_e}\bigg)
\end{equation*}
\paragraph{\indent\indent x. But the experimental value for $|\boldsymbol{m}_e|$ is almost exactly (but not quite) \textcolor{blue}{twice} this value!}
\paragraph{\indent\indent xi. By incorporating quantum mechanics into this calculation (the theory called "\textcolor{blue}{quantum electrodynamics}" or QED), Julian Schwinger in 1948 accurately predicted $|\boldsymbol{m}_e|$ to 6 significant digits!}
\paragraph{\indent\indent xii. The current (fifth-order) QED result for $|\boldsymbol{m}_e|$ agrees with experiment to \textcolor{blue}{12 significant digits}!}
\paragraph{\indent g. The magnetic field $\boldsymbol{B}_{dipole}$ due to the magnetic vector potential dipole $n=1$ term $\boldsymbol{A}_{dipole}$ would be given by}
\begin{equation*}
    \boldsymbol{B}_{dipole}=\nabla\times\boldsymbol{A}_{dipole}=\nabla\times\{ \frac{\mu_0}{4\pi r^2}\boldsymbol{m}\times\hat{\boldsymbol{r}}\}
\end{equation*}
\begin{equation*}
    \boldsymbol{B}_{dipole}=\frac{\mu_0|\boldsymbol{m}|}{4\pi r^3}\{ 2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}
\end{equation*}
\paragraph{\indent\indent i. Compare with $\boldsymbol{E}_{dipole}$}
\begin{equation*}
    \boldsymbol{E}_{dipole}=\frac{p}{4\pi\epsilon_0 r^3}\{2\cos\theta\hat{\boldsymbol{r}}+\sin\theta\hat{\boldsymbol{\theta}}\}
\end{equation*}
\paragraph{\indent\indent ii. In both cases, the expression for the field is a very good approximation when $r$ is much larger than the dimensions of the source. Close to the distribution, the fields will have higher-order terms and look very different.}
\section{Magnetic Fields in Matter}
\subsection{Magnetization phenomena in materials}
\subsubsection{Magnetic Materials and Magnetization}
\paragraph{1. General considerations - Within matter, there are usually a few hundred billion trillion ($~10^{23}$) or so electrons in every gram of material. These negatively charged electrons orbit a nucleus.}
\paragraph{There is a similar number of nuclei in every gram of matter. The nucleus is composed of charged (protons) and uncharged (neutrons) particles swirling around, too.}
\paragraph{Protons and neutrons are composed of charged quarks moving around inside them.}
\paragraph{So we have lots of subatomic electric currents in materials. \textcolor{blue}{Since this is a \underline{classical} physics course, we'll speak in very general \underline{classical} terms about how magnetic phenomena arise from these currents.}}
\paragraph{\indent a. From your introductory physics and chemistry classes, you know electrons move about the nucleus in orbitals within atomic shells. The periodic table is based on this orbital and shell structure.}
\paragraph{\indent b. When electrons "pair", the angular momentum for one electron in a pair aligns in the opposite direction of the other electron, such that the total angular momentum for the pair adds to zero.}
\paragraph{\indent c. However, \textcolor{blue}{Hund's rule} states that, within an orbital, electrons "prefer" \textcolor{blue}{not} to pair: An atom in its ground state adopts the electron configuration having the \underline{greatest number of unpaired electrons}.}
\paragraph{\indent\indent i. Groups \textcolor{blue}{2A},\textcolor{blue}{2B}, and \textcolor{blue}{8A} of the periodic table have \textcolor{blue}{all electrons paired}. \underline{All other groups have one} \underline{or more unpaired electrons}. (We need more quantum mechanics to be more specific that this.)}
\paragraph{\indent\indent ii. A neutral atom with an \textcolor{blue}{odd} number of electrons (i.e., an \textcolor{blue}{odd} atomic number) \underline{must} have at least one unpaired electron.}
\paragraph{\indent\indent iii. A neutral atom with an \textcolor{blue}{even} number of electrons (i.e., an \textcolor{blue}{even} atomic number) will have \underline{at least one unpaired electron if it is not in Group 2A, 2B, or 8A}.}
\paragraph{2. The magnetic properties of a material arise from several sources:}
\paragraph{\indent a. An electron in orbit about the nucleus has orbital angular momentum. This orbital motion generates an electric current. Thus each electron adds a contribution to the magnetic moment of the atom.}
\paragraph{\indent b. The motion of protons and neutrons within the nucleus also generate currents, which in turn generate magnetic moments. Since the radius of the nucleus is $~10^5$ the radius of a typical electron orbit, the nuclear magnetic moment contribution can usually be ignored.}
\paragraph{\indent c. The electrons, protons, and neutrons have intrinsic magnetic moments. We'll ignore these contributions, too, since those would demand a quantum treatment.}
\paragraph{3. Preview of magnetic susceptibility}
\paragraph{\indent a. We saw in previous chapters that for linear dielectric materials, the \textcolor{blue}{electric polarization} $\boldsymbol{P}$ (electric dipole moment per unit volume) is given by}
\begin{equation*}
    \boldsymbol{P}=\epsilon_0\chi_e\boldsymbol{E}
\end{equation*}
\paragraph{where $\chi_e$ - a dimensionless number - was called the \textcolor{blue}{electronic susceptibility}}
\paragraph{\indent\indent i. We saw that for \underline{linear} dielectric materials, the electronic susceptibility $\chi_e$ was \underline{always positive}.}
\paragraph{\indent\indent ii. Thus, for \underline{linear} dielectric materials, $\boldsymbol{P}$ was always parallel to (and in the \underline{same} direction as) the external electric field $\boldsymbol{E}$.}
\paragraph{\indent b. Similarly, we will see that for linear magnetic materials, we can define a \textcolor{blue}{magnetization} $\boldsymbol{M}$ (magnetic dipole moment per unit volume) given by}
\begin{equation*}
    \boldsymbol{M}=\chi_m\frac{\boldsymbol{B}}{\mu}\quad:\quad \mu=\mu_0(1+\chi_m)
\end{equation*}
\paragraph{where $\chi_m$ - a dimensionless number - is called the \textcolor{blue}{magnetic susceptibility}.}
\paragraph{\indent\indent i. Unlike the electric case, the magnetic susceptibility can be \underline{positive or negative}.}
\paragraph{\indent\indent ii. For \underline{linear} magnetic materials,}
\paragraph{\indent\indent $\cdot$ If the response of the material enhances the local magnetic field, then $\chi_m>0$ and the material is said to be \textcolor{blue}{paramagnetic}.}
\paragraph{\indent\indent $\cdot$ If the response of the material reduces the local magnetic field, then $\chi_m<0$ and the material is said to be \textcolor{blue}{diamagnetic}.}
\paragraph{\indent c. Thoughts on values for magnetic susceptibilities $\chi_m$}
\paragraph{\indent\indent i. For paramagnetic materials, $\chi_m$ ranges from $\approx 10^{-6}\rightarrow 10^{-1}$}
\paragraph{\indent\indent ii. For diamagnetic materials, $\chi_m$ ranges from $\approx 10^{-9}\rightarrow 10^{-4}$}
\paragraph{\indent\indent iii. The typical $\chi_m$ for paramagnetic materials is about $10^3$ to $10^5$ times greater than the typical $\chi_m$ for diamagnetic materials. We will see how that difference arises in a classical fashion later on.}
\paragraph{4. \textcolor{blue}{Paramagnetism} $(\chi_m>0)$: In paramagnetism, the internal atomic magnetic moments align with the external magnetic field, so the local magnetic field increases. Let's look at the torque on a current loop.}
\paragraph{\indent a. A rectangular current loop carrying a steady current $I$ is in a uniform magnetic field $\boldsymbol{B}$ as shown in the figure. Let $\boldsymbol{B}$ be in the x-direction and the "2-4" axis of the loop be in the z-direction.}
\paragraph{\indent\indent i. Each side experiences a magnetic force given by}
\begin{equation*}
    \boldsymbol{F}=I\int\boldsymbol{dl}\times\boldsymbol{B}
\end{equation*}
\paragraph{\indent\indent ii. The torques on sides 2 and 4 are equal, opposite and cancel.}
\paragraph{\indent\indent iii. The forces on sides 1 and 3 are equal to $Ib$, and provide torques that add together.}
\begin{equation*}
    \boldsymbol{N}=\boldsymbol{N}_1+\boldsymbol{N}_3=\boldsymbol{r}_1\times\boldsymbol{F}_1+\boldsymbol{r}_3\times\boldsymbol{F}_3
\end{equation*}
\begin{equation*}
    =2\cdot Ib\frac{a}{2}\sin\theta B(-\hat{\boldsymbol{z}})=Iab\sin\theta B(\hat{\boldsymbol{z}})
\end{equation*}
\begin{equation*}
    \boldsymbol{N}=\boldsymbol{m}\times\boldsymbol{B}\quad :\quad \boldsymbol{m}=I\boldsymbol{A}=\text{current}\times\text{area}
\end{equation*}
\paragraph{\indent\indent iv. This torque will align the magnetic moment with the magnetic field.}
\paragraph{\indent\indent v. We saw a similar phenomenon associated with electric dipoles. The torque in an electric field on an electric dipole aligned the dipole with the electric field: $\boldsymbol{N}=\boldsymbol{p}\times\boldsymbol{E}$.}
\paragraph{\indent\indent vi. With respect to potential energy and work, we saw there was a potential energy associated with an electric dipole in an electric field given by $U_{Ed}=-\boldsymbol{p}\cdot\boldsymbol{E}$.}
\paragraph{\indent\indent vii. An analogous potential energy associated with a magnetic dipole in a magnetic field is $U_{Bd}=-\boldsymbol{m}\cdot\boldsymbol{B}$.}
\paragraph{\indent\indent viii. This phenomenon is the basis of electric motors.}
\paragraph{\indent b. We stated earlier that atomic electrons moving in orbits generate current loops. These current loops in turn generate magnetic moments.}
\paragraph{\indent c. \textcolor{blue}{Paramagnetism} occurs when the orbits (and hence magnetic moments) of unpaired electrons align with the external magnetic field, leading to an increase in the local magnetic field.}
\paragraph{\indent\indent i. Atoms and molecules with an \textcolor{blue}{odd number of electrons} should exhibit paramagnetism since at least one electron will be unpaired.}
\paragraph{\indent\indent ii. Atoms \textcolor{blue}{not in Groups 2A, 2B, or 8A} should be paramagnetic because they will have unpaired electrons.}
\paragraph{\indent d. Since atoms are jostled in response to heat, we expect that the degree of alignment (and hence the degree of paramagnetism) exhibited by a material will decrease with temperature.}
\paragraph{\indent\indent i. This is called the \textcolor{blue}{Langevin-Curie law}: $\chi_m=\frac{C}{T}$.}
\paragraph{\indent\indent ii. Adiabatic demagnetization uses paramagnetism to cool materials to near-absolute-zero temperatures.}
\paragraph{\indent e. Since magnetic fields like to align with each other, a bar magnet will attract a paramagnetic material.}
\paragraph{5. \textcolor{blue}{Diamagnetism} occurs when all electrons are paired (Groups 2A, 2B, 8A). A pair of electrons have currents in opposite directions, so paramagnetic effects get cancelled in electron pairs. Let's see how diamagnetism works by looking at one electron in a pair at a time.}
\paragraph{\indent a. The magnetic moment of an electron in orbit with radius $R$ about the nucleus is}
\begin{equation*}
    m=Ia=\frac{-ev}{2\pi R}\cdot\pi R^2=\frac{-evR}{2}
\end{equation*}
\paragraph{\indent\indent i. For the sake of argument, let's say}
\begin{equation*}
    \boldsymbol{m}=-\frac{evR}{2}\hat{\boldsymbol{z}}
\end{equation*}
\paragraph{\indent\indent ii. With no external magnetic field, we know that our electron is in uniform circular motion so that}
\begin{equation*}
    \frac{Mv^2}{R}=\frac{Ze^2}{4\pi\epsilon_0R^2}
\end{equation*}
\paragraph{\indent\indent iii. If we apply a magnetic field such that $\boldsymbol{B}=B_0\hat{\boldsymbol{z}}$, then (assuming the radius of the orbit remains the same)}
\begin{equation*}
    \frac{Mv'^2}{R}=\frac{Ze^2}{4\pi\epsilon_0 R^2}+ev'B_0
\end{equation*}
\paragraph{\indent\indent iv. Since the right hand side of the equation has increased, the velocity on the left hand side must increase. However, since the magnetic force is so much weaker than the electric force, we suspect that $v'\approx v$.}
\begin{equation*}
    \frac{M(v'^2-v^2)}{R}=ev'B_0=\frac{M(v'+v)(v'-v)}{R}\approx \frac{2Mv'}{R}(\Delta v)
\end{equation*}
\begin{equation*}
    ev'B_0\approx\frac{2Mv'}{R}(\Delta v)\rightarrow \Delta v =\frac{eRB_0}{2M}
\end{equation*}
\paragraph{This $\Delta v$ is a positive number.}
\paragraph{\indent\indent v. The magnetic moment will change:}
\begin{equation*}
    \boldsymbol{m}'=\boldsymbol{m}+\Delta\boldsymbol{m}=\bigg\{ -\frac{evR}{2}-\frac{e(\Delta v)R}{2}\bigg\}\hat{\boldsymbol{z}}
\end{equation*}
\begin{equation*}
    \Delta m=\bigg\{ -\frac{e^2R^2B_0}{4M}\bigg\}\hat{\boldsymbol{z}}=\bigg\{ -\frac{e^2R^2}{4m}\bigg\} \boldsymbol{B}
\end{equation*}
\paragraph{\indent This change $\Delta m$ is \underline{opposite} the direction of the magnetic field, so \textcolor{blue}{the local field is reduced}.}
\paragraph{\textcolor{purple}{For note: The quantum mechanical result is that}}
\begin{equation*}
    \Delta\boldsymbol{m}=\bigg\{-\frac{e^2<R^2>}{6M}\bigg\}\boldsymbol{B}
\end{equation*}
\paragraph{\textcolor{purple}{So, even with quantum mechanics, the qualitative effects remains the same: \textcolor{blue}{the local field is reduced}}.}
\paragraph{\indent\indent vi. The orbit of the other electron in the pair is in the opposite direction, but \textcolor{blue}{yields the same effect: the local field is reduced}. So pairs of electrons will reduce the local field by twice this amount.}
\paragraph{\indent\indent vii. Since the local field is reduced, then the magnetic susceptibility for the material $\chi_m<0$. This is a classical picture of how diamagnetism works. \textcolor{blue}{If all electrons are paired, then diamagnetism should result}.}
\paragraph{\indent b. The size of this effect is small. Sticking in numbers}
\begin{equation*}
    \frac{\Delta m}{m}=\frac{\frac{-e^2R^2}{4M}}{\frac{-evR}{2}}=\frac{eRB}{2Mv}\sqrt{\frac{MR(4\pi\epsilon_0)}{Ze^2}}
\end{equation*}
\begin{equation*}
    \frac{\Delta m}{m}=\frac{R^{\frac{3}{2}}B}{2M^{\frac{1}{2}}}\sqrt{\frac{(4\pi\epsilon_0}{Z}}\approx 10^{-5}
\end{equation*}
\paragraph{for a 1 T magnetic field.}
\paragraph{4. \textcolor{blue}{Ferromagnetism} - Some materials (in bulk) can have a pre-existing or permanent magnetization with no external field applied.}
\paragraph{\indent a. Inter-atomic effects involving the exchange of electrons between atoms in certain materials result in ferromagnetism. \textcolor{blue}{We must use quantum mechanics to understand this phenomena}. There is no classical picture that explains the phenomenon of ferromagnetism.}
\paragraph{\indent b. Ferromagnetic materials are \textcolor{blue}{non-linear magnetic materials} by definition, since there is no proportionality between an applied field and the pre-existing or permanent magnetization.}
\paragraph{\indent c. \textcolor{blue}{We will not study ferromagnetic materials in extensive detail}. You will need to take a materials physics course to better understand these materials.}
\subsubsection{Fields due to bound currents in materials}
\paragraph{1. In \textcolor{blue}{electrostatics}, we saw for a polarized object that the electric potential $V(\boldsymbol{r})$ due to the electric polarization $\boldsymbol{P}(\boldsymbol{r}')$ (i.e., the electric dipole moment per unit volume) induced in the material was}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\sum_{i}\boldsymbol{P}_i \frac{\hat{\boldsymbol{\mathfrak{r}_i}}}{\mathfrak{r}_i^2}\rightarrow \frac{1}{4\pi\epsilon_0}\int\frac{\boldsymbol{P}(\boldsymbol{r}')\cdot\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'
\end{equation*}
\paragraph{\indent a. Using the relationship $\nabla'(\frac{1}{\mathfrak{r}})=\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}}$, we found we could re-write this potential as being due to "bound charge densities":}
\begin{equation*}
    V(\boldsymbol{r})=\frac{1}{4\pi\epsilon_0}\int_s\frac{\sigma_b(\boldsymbol{r}')da'}{\mathfrak{r}}+\frac{1}{4\pi\epsilon_0}\int_V\frac{\rho_b(\boldsymbol{r}')d\tau'}{\mathfrak{r}}:\begin{cases}
        \sigma_b=\boldsymbol{P\cdot\hat{\boldsymbol{n}'}}\\
        \rho_b=-\nabla\cdot\boldsymbol{P}\\
    \end{cases}
\end{equation*}
\paragraph{\indent b. We observed that the surface $\sigma_b$ and volume $\rho_b$ bound charge densities represented real charge densities in the polarized material.}
\paragraph{\indent c. With this potential, we could find the electric field produced by the polarization (i.e., $\sigma_b$ and $\rho_b$) with $\boldsymbol{E}(\boldsymbol{r})=-\nabla V(\boldsymbol{r})$.}
\paragraph{2. For \textcolor{blue}{magnetostatics}, we have a similar development beginning with the magnetic vector potential $A(\boldsymbol{r})$:}
\paragraph{\indent a. We can write the vector potential as the sum of all the magnetic dipole moments in the material.}
\begin{equation*}
    \boldsymbol{A}=\frac{\mu_0}{4\pi}\sum_{i}\frac{\boldsymbol{m}_i\times\hat{\boldsymbol{\mathfrak{r}_i}}}{\mathfrak{r}^2}\rightarrow\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{M}(\boldsymbol{r}')\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}d\tau'
\end{equation*}
\paragraph{\indent b. For \textcolor{blue}{magnetization} $\boldsymbol{M}(\boldsymbol{r}')$ is the magnetic dipole moment per unit volume.}
\paragraph{\indent c. With $\nabla'(\frac{1}{\mathfrak{r}})=\frac{\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}}$, the vector potential $\boldsymbol{A}(\boldsymbol{r})$ arising from this magnetization $\boldsymbol{M}(\boldsymbol{r}')$ can be written as being due to "bound current densities".}
\begin{equation*}
    \boldsymbol{A}(\boldsymbol{r})\frac{\mu_0}{4\pi}\int_s\frac{\boldsymbol{K}_b(\boldsymbol{r}')da'}{\mathfrak{r}}+\frac{\mu_0}{4\pi}\int_V\frac{\boldsymbol{J}_b(\boldsymbol{r}')d\tau'}{\mathfrak{r}}:\begin{cases}
        \boldsymbol{K}_b=\boldsymbol{M}\times\hat{\boldsymbol{n}'}(A/m)\\
        \boldsymbol{J}_b=\nabla\times\boldsymbol{M}(A/m^2)\\
    \end{cases}
\end{equation*}
\paragraph{\indent d. Both $\boldsymbol{J}_b$ and $\boldsymbol{K}_b$ are real current densities.}
\paragraph{\indent e. With this vector potential $\boldsymbol{A}(\boldsymbol{r})$, the magnetic field due to the magnetization (i.e., $\boldsymbol{K}_b$ and $\boldsymbol{J}_b$) is $\boldsymbol{B}=\nabla\times\boldsymbol{A}(\boldsymbol{r})$.}
\paragraph{\indent f. But since both $\boldsymbol{J}_b$ and $\boldsymbol{K}_b$ are \underline{real current densities}, we can, in fact, use any of the techniques for real currents developed in previous chapters to handle these bound current densities, as well:}
\paragraph{\indent\indent i. The Biot-Savart law:}
\begin{equation*}
    \boldsymbol{B}(\boldsymbol{r})=\frac{\mu_0}{4\pi}\int\frac{\boldsymbol{I}\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}=\frac{\mu_0 I}{4\pi}\int\frac{\boldsymbol{dl}'\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{\indent\indent ii. Ampere's Law}
\begin{equation*}
    \oint_C \boldsymbol{B}(\boldsymbol{r})\cdot\boldsymbol{dl}=\iint_S \mu_0\boldsymbol{J}(\boldsymbol{r})\cdot\boldsymbol{da}=\mu_0 I_{encl}
\end{equation*}
\paragraph{\indent\indent iii. The "flux law" with $\boldsymbol{A}$:}
\begin{equation*}
    \Phi_B=\iint_S \boldsymbol{B}\cdot\boldsymbol{da}=\iint_S(\nabla\times\boldsymbol{A})\cdot\boldsymbol{da}=\oint_C\boldsymbol{A}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent g. We should always look to exploit similarities in magnetic material problems with the results from current-carrying wires we saw in previous chapters.}
\subsection{The "auxiliary field" $\boldsymbol{H}$}
\subsubsection{Ampere's law in magnetized materials}
\paragraph{1. Let's reprise what we did in earlier lessons for dielectrics. We divided the electric charge density into two components, the \textcolor{blue}{bound charge} due to polarization $(\rho_{bound}=-\nabla\cdot\boldsymbol{P})$ and the \textcolor{blue}{free charge} density $\rho_f$.}
\paragraph{\indent a. The total charge density \textcolor{blue}{$\rho$ in the material was given by}}
\begin{equation*}
    \textcolor{blue}{\rho}=\rho_f+\rho_{bound}=\rho_f-\nabla\cdot \boldsymbol{P}
\end{equation*}
\paragraph{\indent b. We then re-wrote Gauss' Law in terms of $\rho_f$ and $\rho_{bound}$:}
\begin{align*}
    \epsilon_0\nabla\cdot\boldsymbol{E}&=\rho=\rho_f+\rho_{bound}\\
    \epsilon_0\nabla\cdot\boldsymbol{E}&=\rho_f-\nabla\cdot\boldsymbol{P}\\
    \nabla\cdot(\epsilon_0\boldsymbol{E})+\nabla\cdot\boldsymbol{P}&=\rho_f\\
    \nabla\cdot(\textcolor{red}{\epsilon_0\boldsymbol{E}+\boldsymbol{P}})=\nabla\cdot\textcolor{red}{\boldsymbol{D}}&=\rho_f\quad:\quad \textcolor{red}{\boldsymbol{D}\equiv \epsilon_0\boldsymbol{E}+\boldsymbol{P}}\\
\end{align*}
\paragraph{where the \textcolor{blue}{electric displacement} $\textcolor{red}{\boldsymbol{D}}$ was an "auxiliary field" that allowed us to focus on the effect of the free charge density $\rho_f$. Experimentally, it is usually the free charge that we can control.}
\paragraph{\indent c. An aside for later reference: Take note that $\boldsymbol{E}=(\boldsymbol{D}-\boldsymbol{P})/\epsilon_0$. This shows that the polarization $\boldsymbol{P}$ is \textcolor{blue}{anti-parallel} to the electric field $\boldsymbol{E}$.}
\paragraph{\indent d. Next, given this restatement of Gauss' Law in terms of the electric displacement $\boldsymbol{D}$, we integrated over some volume of interest to find}
\begin{equation*}
    \nabla\cdot\boldsymbol{D}=\rho_f\rightarrow \oiiint_V \nabla\cdot \boldsymbol{D}d\tau=\oiiint_V\rho_fd\tau'=Q_{\text{free enclosed}}=Q_{f \text{ encl}}
\end{equation*}
\paragraph{\indent e. Then using \textcolor{blue}{Gauss' Theorem for Divergence}, we wrote}
\begin{equation*}
    \oiiint_V \nabla\cdot \boldsymbol{D}d\tau=\oiint_S\boldsymbol{D}\cdot\boldsymbol{da}=Q_f
\end{equation*}
\begin{equation*}
    \oiint_S\boldsymbol{D}\cdot\boldsymbol{da}=\oiint_S (\epsilon_0\boldsymbol{E}+\boldsymbol{P})\cdot\boldsymbol{da}=Q_f
\end{equation*}
\paragraph{\indent f. This was the integral form of Gauss' Law for dielectric materials. As usual for Gauss' Law, we noted that this was \textcolor{blue}{"Always true, sometimes useful"}.}
\paragraph{2. In magnetic materials, we can rewrite Ampere's Law using an auxiliary field that allows us to focus on the effect of the \textcolor{blue}{free current density} $\boldsymbol{J}_f$. The total current density will be the sum of the \textcolor{blue}{free} and \textcolor{blue}{bound} current densities:}
\begin{align*}
    \boldsymbol{J}=\boldsymbol{J}_f+\boldsymbol{J}_b\quad&:\quad \boldsymbol{J}_b=\nabla\cdot\boldsymbol{M}\\
    \nabla\times\boldsymbol{B}&=\mu_0\boldsymbol{J}=\mu_0(\boldsymbol{J}_f+\boldsymbol{J}_b)\\
    \nabla\times\boldsymbol{B}&=\mu_0\boldsymbol{J}_f+\mu_0\nabla\times\boldsymbol{M}\\
    \nabla \times\textcolor{red}{\bigg(\frac{\boldsymbol{B}}{\mu_0}-\boldsymbol{M}\bigg)}&=\boldsymbol{J}_f\\
    \nabla\times\textcolor{red}{\boldsymbol{H}}&=\boldsymbol{J}_f\quad:\quad\textcolor{red}{\boldsymbol{H}=\bigg(\frac{\boldsymbol{B}}{\mu_0}-\boldsymbol{M}\bigg)}
\end{align*}
\paragraph{\indent a. Note that $\boldsymbol{B}=\mu_0(\boldsymbol{H}+\boldsymbol{M})$. In contrast to the case with $\boldsymbol{E}$ and $\boldsymbol{P}$, the magnetic field $\boldsymbol{B}$ is \textcolor{blue}{parallel} to the magnetization $\boldsymbol{M}$.}
\paragraph{\indent b. What we have derived above is the \underline{differential form of Ampere's Law for magnetic materials.} The equation says the auxiliary field $\boldsymbol{H}$ is directly related to the free current density in the material by}
\begin{equation*}
    \nabla \times\boldsymbol{H}=\boldsymbol{J}_f
\end{equation*}
\paragraph{\indent c. Physicists don't universally agree on what to call $\boldsymbol{H}$. We'll use the convention of calling it the "\textcolor{blue}{the auxiliary field $\boldsymbol{H}$}. \textcolor{red}{Beware: Many engineers call $\boldsymbol{H}$ the magnetic field and call $\boldsymbol{B}$ something else}. So, remember when you say "magnetic field" to someone, \underline{make clear} you mean $\boldsymbol{B}$ and not $\boldsymbol{H}$.}
\paragraph{\indent d. While the electric displacement $\boldsymbol{D}$ doesn't get mentioned much in the lab (and some don't even give it a name), the auxiliary field $\boldsymbol{H}$ is often used and discussed in experiments, primarily for two very pragmatic reasons:}
\paragraph{\indent\indent i. When you have a current, almost always assume there will be some magnetization in a material. That magnetization $\boldsymbol{M}$ is often very small and unless the material is ferromagnetic, and it can be \textcolor{blue}{very hard} to measure $\boldsymbol{M}$ accurately. The auxiliary field $\boldsymbol{H}$ \underline{automatically} incorporates any effects of $\boldsymbol{M}$, so why bother dealing with both $\boldsymbol{B}$ and $\boldsymbol{M}$?}
\paragraph{\indent\indent ii. In most experiments, it's usually practical to control and accurately measure the free current density $\boldsymbol{J}_f$ you are pushing through the material. The auxiliary field $\boldsymbol{H}$ is directly related to the free current that makes working with $\boldsymbol{H}$ relatively straightforward.}
\paragraph{3. With the differential from of Ampere's Law in terms of $\boldsymbol{H}$, we can use \textcolor{blue}{Stokes' Theorem of the Curl} to write}
\begin{equation*}
    \iint_S(\nabla\times\boldsymbol{H})\cdot\boldsymbol{da}=\iint\boldsymbol{J}_f\cdot\boldsymbol{da}=I_{f\text{  encl}}
\end{equation*}
\paragraph{\indent a. As we saw for the integral form of Gauss' Law in dielectric materials, this integral form of Ampere's Law in magnetic materials is "\textcolor{blue}{Always true, sometimes useful}".}
\paragraph{\indent b. If symmetries exist such that the integrand on the left-hand side of the equation is easy to obtain, this will far and away also be the quickest way to find the magnetic field $\boldsymbol{B}$ since}
\paragraph{\indent c. If $\boldsymbol{H}$ turns out to be zero, this expression underscores that any magnetic field $\boldsymbol{B}$ arises solely from the magnetization $\boldsymbol{M}$ present.}
\paragraph{4. A deceptive "parallel" between $\boldsymbol{H}$ and $\boldsymbol{B}$.}
\paragraph{\indent a. Within the similarity between Ampere's Law for $\boldsymbol{B}$ and $\boldsymbol{H}$}
\begin{equation*}
    \nabla\times\boldsymbol{H}=\boldsymbol{J}_f\quad:\quad \nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}
\end{equation*}
\paragraph{lurks the temptation to say something clever like "\textcolor{red}{$\boldsymbol{B}$ is just $\mu_0\boldsymbol{H}$ with $\boldsymbol{J}_f$ as the source}".}
\paragraph{\indent b. \textcolor{blue}{Don't be fooled!} The similarity falls apart when it hits the reality of the fundamental statement there are no magnetic monopoles:}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}=0
\end{equation*}
\paragraph{Such a result does NOT necessarily work for $\boldsymbol{H}$:}
\begin{equation*}
    \nabla\cdot \boldsymbol{H}=\nabla\cdot\bigg( \frac{\boldsymbol{B}}{\mu_0}-\boldsymbol{M}\bigg)=-\nabla\cdot\boldsymbol{M}
\end{equation*}
\paragraph{\indent c. The divergence $-\nabla\cdot\boldsymbol{M}$ may vanish due to the symmetry of a problem, but in general do not count on that happening.}
\paragraph{\indent d. \underline{Any} discontinuity in $\boldsymbol{M}$ will have a big (discontinuous) effect on the auxiliary field $\boldsymbol{H}$ but not on the magnetic field $\boldsymbol{B}$.}
\subsubsection{Boundary conditions on $\boldsymbol{H}$}
\paragraph{1. With the expressions for $\nabla\cdot\boldsymbol{H}$ and $\nabla\times\boldsymbol{H}$---}
\begin{equation*}
   \nabla\cdot\boldsymbol{H}=-\nabla\cdot\boldsymbol{M}\quad\text{and}\quad \nabla\times \boldsymbol{H}=\boldsymbol{K}_f 
\end{equation*}
\paragraph{--- we can derive the boundary conditions for $\boldsymbol{H}$ when crossing a boundary between two regions, just as we've done for the electric field $\boldsymbol{E}$, the electric displacement $\boldsymbol{D}$, and the magnetic field $\boldsymbol{B}$.}
\paragraph{2. With the $\nabla\cdot\boldsymbol{H}$ expression, a Gaussian pillbox allows us to find how the component of $\boldsymbol{H}$ perpendicular to the boundary behaves:}
\begin{equation*}
    \boldsymbol{H}_{\perp}^{above}-\boldsymbol{H}_{\perp}^{below}=-(\boldsymbol{M}_{\perp}^{above}-\boldsymbol{M}_{\perp}^{below})
\end{equation*}
\paragraph{3. With this curl expression, an Amperian loop across the boundary gives us: }
\begin{equation*}
    \boldsymbol{H}_{\parallel}^{above}-\boldsymbol{H}_{\parallel}^{below}=\boldsymbol{K}_f\times\hat{\boldsymbol{n}}
\end{equation*}
\subsection{Linear and non-linear magnetic materials}
\subsubsection{Linear magnetic materials}
\paragraph{1. We've seen that some materials respond to an applied magnetic field $\boldsymbol{B}$ by setting up a magnetization $\boldsymbol{M} $ linearly proportional to the strength of $\boldsymbol{B}$.}
\paragraph{\indent a. In \textcolor{blue}{para}magnetism, the response of the material set up $\boldsymbol{M}$ \textcolor{blue}{parallel} to $\boldsymbol{B}$.}
\paragraph{\indent \indent i. At the atomic level, an unpaired electron aligns its orbit (a current loop with magnetic momentum $\boldsymbol{m}$) with the applied field $\boldsymbol{B}$.}
\paragraph{\indent\indent ii. The momentum $\boldsymbol{m}$ of the unpaired electron sets up a magnetization $\boldsymbol{M}$ in the same direction as $\boldsymbol{B}$, so the local field \textcolor{blue}{increased}.}
\paragraph{\indent b. In \textcolor{blue}{dia}magnetism, the response set up a magnetization $\boldsymbol{M}$ \textcolor{blue}{dia}metrically opposed (\textcolor{blue}{anti-parallel}) to $\boldsymbol{B}$.}
\paragraph{\indent\indent i. Paired electrons in an atom align orbits (and magnetic moments $\boldsymbol{m}$) opposite each other.}
\paragraph{\indent\indent ii. An applied magnetic field causes a difference in each magnetic moment $\Delta\boldsymbol{M}$ that opposes $\boldsymbol{B}$, so the local field \textcolor{blue}{decreased}.}
\paragraph{2. Definitions for \textcolor{blue}{linear magnetic materials}}
\paragraph{\indent a. Rather than the applied magnetic field $\boldsymbol{B}$, pragmatism has led to the auxiliary field $\boldsymbol{H}$ being used for the "constitutive relations" for the various parameters. This is different from what happened with dielectric materials.}
\paragraph{\indent b. The \textcolor{blue}{magnetic susceptibility $\chi_m$} is defined by the relation}
\begin{equation*}
    \boldsymbol{M}=\chi_m\boldsymbol{H}
\end{equation*}
\paragraph{(For dielectrics, we used $\boldsymbol{P}=\epsilon_0\chi_m\boldsymbol{E}$, remember?)}
\paragraph{\indent c. The \textcolor{blue}{permeability $\boldsymbol{\mu}$} is defined by}
\begin{equation*}
    \boldsymbol{B}=\mu_0(\boldsymbol{H}+\boldsymbol{M})=\mu_0(\boldsymbol{H}+\chi_m\boldsymbol{H})=\textcolor{blue}{\mu_0(1+\chi_m)}\boldsymbol{H}
\end{equation*} 
\begin{equation*}
    \boldsymbol{B}=\mu\boldsymbol{H}\quad :\quad \mu=\mu_0(1+\chi_m)
\end{equation*}
\paragraph{(For dielectrics, we used $\boldsymbol{D}=\epsilon\boldsymbol{E}$, remember?)}
\paragraph{(Now you also see why $\mu_0$ is called the "permeability of free space".)}
\paragraph{2. In \textcolor{blue}{linear magnetic materials...}}
\paragraph{\indent a. Since $\boldsymbol{M}=\chi_m\boldsymbol{H}$, the bound current density $\boldsymbol{J}_b$ will be}
\begin{align*}
    \boldsymbol{J}_b&=\nabla\times\boldsymbol{M}=\nabla\times(\chi_m\boldsymbol{H})\\
    \boldsymbol{J}_b&=\chi_m\nabla\times\boldsymbol{H}\\
    \boldsymbol{J}_b&=\chi_m\boldsymbol{J}_f\\
\end{align*}    
\paragraph{\indent b. When this relation holds (i.e., if we have linear magnetic materials), Ampere's Law in terms of $\boldsymbol{H}$ becomes even more useful for situations where we actually want to know $\boldsymbol{B}$ and $\boldsymbol{M}$ rather than just $\boldsymbol{H}$ alone.}
\paragraph{\indent c. For example: Griffiths Example 6.2}
\paragraph{\indent\indent i. He had a copper rod, but didn't know how the magnetization behaved. In that case, he could find $\boldsymbol{H}$ inside the solenoid but not $\boldsymbol{B}$ or $\boldsymbol{M}$.}
\paragraph{\indent\indent ii. But knowing that copper is a linear magnetic material (diamagnetic), we can find $\boldsymbol{B}$ and $\boldsymbol{M}$ immediately from $\boldsymbol{H}$ with}
\begin{equation*}
    \boldsymbol{B}=\mu\boldsymbol{H}=\mu_0(1+\chi_m)\boldsymbol{H} \quad\text{and}\quad \boldsymbol{M}=\chi_m\boldsymbol{H}
\end{equation*}
\subsubsection{Non-linear magnetic materials (Ferromagnetism)}
\paragraph{1. We have noted that the magnetic properties of a material arise from several subatomic sources with magnetic moments. In quantum mechanics, we can express the magnetic effects of these sources as terms in the total Hamiltonian for each electron in the material:}
\begin{equation*}
    \hat{H}_{total}=\hat{H}_{orb}+\hat{H}_{spin}+\hat{H}_{exch}
\end{equation*}
\paragraph{\indent a. The orbital term $\hat{H}_{orb}$ is the contribution due to the orbital motions (and resulting current loops) of the atomic electrons. This term can result in \textcolor{blue}{paramagnetism} (an unpaired electron) or \textcolor{blue}{diamagnetism} (paired electrons), though the classical picture is too simple.}
\paragraph{\indent b. The intristic electron spin term $\hat{H}_{spin}$ is the contribution from the intrinsic spins (and magnetic moments) of the electrons. In most materials, this term also can contribute to \textcolor{blue}{paramagnetism} and \textcolor{blue}{diamagnetism}. However, this intrinsic spin contribution is absolutely non-classical and is a \underline{purely quantum-mechanical phenomenon}.}
\paragraph{\indent c. The exchange interaction $\hat{H}_{exch}$ is the contribution from the exchange of (indistinguishable) electrons between adjacent atoms. This is  the primary (and \underline{purely quantum-mechanical}) cause of \textcolor{blue}{ferromagnetism}.}
\paragraph{2. Looking deeper at $\hat{H}_{exch}$ }
\paragraph{\indent a. In $\hat{H}_{orb}+\hat{H}_{spin}$, an electron within a particular atom (say, electron 1) experiences effects of [i] Coulomb attraction to the nucleus of the atom and [ii] Coulomb repulsion (CR) and the Pauli Exclusion Principle (PEP) due to interactions with other electrons in the atom.}
\paragraph{\indent b. But, electron 1 also can interact [i] with the nucleus of \textcolor{blue}{an adjacent atom} through Coulomb attraction \textcolor{blue}{AND} [ii] also with an electron (say, electron 2) in \textcolor{blue}{an adjacent atom} through Coulomb repulsion (CR) and PEP.}
\paragraph{\indent c. Suppose \underline{both} atoms are considered as a \underline{single} system with a single Hamiltonian. If the orbits of electron 1 and electron 2 overlap to a high degree far away from the nuclei, we can see sizeable effects. }
\paragraph{\indent d. Due to the PEP, electrons midway between adjacent atoms \textcolor{blue}{with aligned spins} do not experience as much CR. This effect arises in the $\hat{H}_{exch}$ term, and can be modeled as a "spin-spin interaction" in the Hamiltonian}
\begin{equation*}
    \hat{H}_{exch}=E_{1 2}\boldsymbol{S}_1\cdot\boldsymbol{S}_2
\end{equation*}
\paragraph{where the exchange energy $E_{12}$ (magnitude and \underline{sign}!) depends on the orbital and spin quantum numbers, and where $\boldsymbol{S}_1$ and $\boldsymbol{S}_2$ are the spins of electron 1 and electron 2, respectively.}
\begin{equation*}
    \hat{H}_{exch}=-E_{12}\boldsymbol{S}_1\cdot\boldsymbol{S}_2
\end{equation*}
\paragraph{\indent e. If \textcolor{blue}{$E_{12}$ is positive} ($E_{12}>0$) for a particular pairing of electron 1 and electron 2, then the alignment of their intrinsic spins will be energetically favorable and \underline{spontaneous}- no external field will be necessary to yield a large magnetization. \textcolor{blue}{This is where ferromagnetism arises}.}
\paragraph{\indent f. As it turns out, $E_{12}>0$ only for some of the unpaired $d$ electrons in \textcolor{blue}{iron, cobalt, and nickel} atoms (plus a few rare-earth atoms -gadolinium and dysprosium- under some circumstances).}
\paragraph{\indent g. Compounds of these elements (for example, magnetite $Fe_3O_4$) can be ferromagnetic, too.}
\paragraph{\indent h. But the presence of a ferromagnetic element does not automatically make something ferromagnetic. (For example, hemoglobin $C_{2952}H_{4664}O_{832}N_{812}S_8Fe_4$ is not ferromagnetic).}
\paragraph{\indent i. Why is it that just \textcolor{blue}{iron, cobalt, and nickel} atoms are ferromagnetic?}
\paragraph{3. Domains- regions of magnetization in ferromagnetic materials}
\paragraph{\indent a. Within a magnetic material, atoms near each other can spontaneously align in some direction. This is an example of \textcolor{blue}{spontaneous symmetry breaking}.}
\paragraph{\indent b. Aligned atoms can induce other atoms near them to align, too. Regions of atoms where the magentization $\boldsymbol{M}$ points in the same direction are called \textcolor{blue}{domains}.}
\paragraph{\indent c. Eventually, the domains will grow large enough to come in contact with each other.}
\paragraph{\indent d. However, energetically, the magnetization $\boldsymbol{M}$ will prefer to be in different domains in different directions.}
\paragraph{\indent e. The net magnetization $\boldsymbol{M}$ for the entire sample (or summed over many regions) may be zero... or not.}
\paragraph{\indent f. When an \textcolor{blue}{external magnetic field is applied} to ferromagnetic material, the domains with magnetic moments aligned in the direction of the field will grow at the expense of those domains which do not align with the applied external field.}
\paragraph{\indent g. Thus, in ferromagnetic material, the net magnetization $\boldsymbol{M}=\boldsymbol{B}-\mu_0\boldsymbol{H}$ that is parallel to the applied field increases as more and more domains align with the external field.}
\paragraph{\indent h. BUT, as the applied magnetic field increases, at some point \textcolor{blue}{all} the domains in the ferromagnetic material will have become aligned with the applied field.}
\paragraph{\indent i. At that point, even though the applied field can still be increased, the magnetization can get no larger. The material is then said to be \textcolor{blue}{saturated}.}
\paragraph{4. Hysteresis}
\paragraph{\indent a. Once saturation is reached, if the applied magnetic field is reduced, then some domains in the material will return to having their moments misaligned with the original field direction. However, many will continue to be aligned with the original applied field direction.}
\paragraph{\indent b. At \underline{zero} applied field, much of the aligned magnetization will still remain pointed in the direction the applied field has pointed. There will thus be residual magnetism (a \textcolor{blue}{"remnant magnetization"}) in the material. This is how so-called "permanent" magnets are made.} 
\paragraph{\indent c. So, for a ferromagnetic material, the magnetization of the material at any point in time \underline{depends on} \underline{ the prior history} of the magnetic field applied to the material. The dependence of the magnetization of a ferromagnetic (from the Greek word -to be late, to lag behind).}
\paragraph{\indent d. With the applied field now zero, the direction of the applied magnetic field can be \underline{reversed} and then increased. When the field is high enough all the domains will point in the new direction (reverse saturation).}
\paragraph{\indent e. Now go to step "a" above and repeat. This generates a "\textcolor{blue}{hysteresis loop} in a plot of $\boldsymbol{B}$ versus $\boldsymbol{H}$.}
\section{Electrodynamics}
\subsection{Electromotive Force (emf)}
\subsubsection{Ohm's Law: $\boldsymbol{J}=\sigma\boldsymbol{E}$ (microscopic) and macroscopic ($V=IR$)}
\paragraph{1. Puzzles about the nature of conduction}
\paragraph{\indent a. Suppose we have a steady current of 1 ampere flowing through a copper wire 1 mm in radius and 7.25 meters long. How fast are electrons moving in the wire?}
\paragraph{\indent\indent i. The current in the wire would be}
\begin{equation*}
    I=J\cdot \pi r^2=\rho<\nu>\cdot \pi r^2=<\nu>\rho\pi r^2
\end{equation*}
\paragraph{\indent\indent ii. The charge density is $\rho=e\cdot\rho_e$ which is}
\begin{equation*}
    \rho=\bigg(1.6\times10^{-19}\frac{C}{e^-}\bigg)\bigg(9\frac{g}{cm^3}\bigg)\bigg(\frac{6\times10^{23}\frac{\text{atoms}}{\text{mole}}}{64\frac{g}{\text{mole}}}\bigg)\bigg(2\frac{e^-}{\text{atom}}\bigg)
\end{equation*}
\begin{equation*}
    \rho=e\cdot\rho_e=e\cdot 1.7\times 10^{23}(\text{electrons/}cm^3)=2.7\times10^4 \frac{C}{cm^3}
\end{equation*}
\paragraph{\indent\indent iii. The average velocity $<\nu>$ for an electron moving through this wire is}
\begin{equation}
    <\nu>=\frac{I}{\rho\pi r^2}=\frac{1}{2.7\times10^4\cdot\pi\cdot (0.1)^2}\frac{cm}{s}=1.2\times10^{-5}\frac{m}{s}
\end{equation}
\paragraph{\indent b. This average velocity $<\nu>=1.2\times10^{-5}m/s$ is very small compared to what we expect from the simple experiment of turning on a light. It's also ridiculously small compared to some other simple calculations.}
\paragraph{\indent\indent i. From your other classes, you can calculate the average thermal velocity $<\nu_T>$ of an electron. You know the mean kinetic energy of an electron at $T=300 K$ is $\frac{3}{2}kT=\frac{1}{2}m<\nu_{T}^{2}>\rightarrow<\nu_T>=1.2\times10^5$ m/s. This is \textcolor{blue}{ten orders of magnitude greater} than $<\nu>$.}
\paragraph{\indent\indent ii. If we place an electron in a 120-volt electric field $\boldsymbol{E}$, the instantaneous acceleration felt by the electron would be something like}
\begin{equation*}
    F=m_ea=eE\rightarrow a=\frac{eE}{m_e}\approx 2\times10^{13}m/s^2=130A.U./s^2
\end{equation*}
\paragraph{\indent c. So we have two puzzles from this simple estimate of $<\nu>$.}
\paragraph{\indent\indent i. Puzzle 1: Why is this simple estimate for $<\nu>$ so very small?}
\paragraph{\indent\indent ii. Puzzle 2: How can lights, telephones, computers, etc. work "instantaneously" when $\nu>$ appears to be small?}
\paragraph{2. The solution to Puzzle 1: the Drude model of electrical conduction}
\paragraph{\indent a. Let's suppose each electron moving within the copper wire undergoes \textcolor{blue}{frequent collisions}.}
\paragraph{\indent b. Each electron only goes a very small distance before it runs into something that kills off its forward velocity.}
\paragraph{\indent c. So what we actually estimated earlier in the wire with $<\nu>$ was merely the average forward speed after many collisions - what's called the "\textcolor{blue}{drift velocity}".}
\paragraph{\indent\indent i. These collisions could arise, for instance, in interactions with atoms, with other electrons, and with defects in the material.}
\paragraph{\indent\indent ii. Thermal vibrations of the lattice of atoms, the orientation of the material due to crystal symmetries, etc. also could affect the collision frequency, too.}
\paragraph{\indent\indent iii. The average distance travelled between collisions is called the \textcolor{blue}{mean free path} $\textsc{l}_{mfp}=<\nu>\boldsymbol{\tau}$, where \textcolor{blue}{$\boldsymbol{\tau}$} is the \textcolor{blue}{average time between collisions}.}
\paragraph{\indent d. Let's assume a uniform electric field $E$ throughout a uniform copper wire, with uniform constant temperature $T$. The drift velocity $<\nu>$ would be}
\begin{equation*}
    \nu=\nu_0+at=\nu_0+\bigg(\frac{eE}{m_e}\bigg)t
\end{equation*}
\begin{equation*}
    \rightarrow <\nu>=<\nu_0>+\frac{eE}{m_e}\textcolor{blue}{\boldsymbol{\tau}}
\end{equation*}
\begin{equation*}
    \textcolor{red}{<\nu>}=\frac{eE}{m_e}\textcolor{blue}{\boldsymbol{\tau}}
\end{equation*}
\paragraph{\indent e. Returning to our original expression for the current in the wire, the magnitude of the current density $J$ in the wire would be}
\begin{equation*}
    J=e\rho_e\textcolor{red}{<\nu>}=e\rho_e\bigg(\textcolor{red}{\frac{eE}{m_e}\boldsymbol{\tau}}\bigg)=\bigg(\frac{\rho_ee^2\boldsymbol{\tau}}{m_e}\bigg)E
\end{equation*}
\begin{equation*}
    J=\sigma E\quad:\quad \sigma=\frac{\rho_ee^2\boldsymbol{\tau}}{m_e}
\end{equation*}
\begin{equation*}
    \boldsymbol{J}=\sigma\boldsymbol{E}\quad :\quad\text{Ohm's Law (microscopic form)}
\end{equation*}
\paragraph{\indent\indent i. This is the "\textcolor{blue}{microscopic form}" of Ohm's Law}
\paragraph{\indent\indent ii. In words: The \textcolor{blue}{current density} in a conductor \textcolor{blue}{is linearly proportional to the electric field} within the conductor.}
\paragraph{\indent\indent iii. If a conductor obeys Ohm's Law, it's called an \textcolor{blue}{ohmic conductor}. Otherwise, it's called \textcolor{blue}{non-ohmic}.}
\paragraph{\indent\indent iv. The quantity $\sigma$ is the \textcolor{blue}{conductivity} of the material.}
\paragraph{\indent\indent $\cdot$ In general, $\sigma$ depends strongly on anything that affects the electron density in the material: number of conduction electrons per atom, temperature of conductor, purity of material, etc.}
\paragraph{\indent\indent $\cdot$ The MSKA unit for conductivity $\sigma$ is ampere per volt per meter $=S/m$, where $S=A/V=(\text{ohm})^{-1}$ is called a \textcolor{blue}{siemens} (sometimes called a "\textcolor{blue}{mho}" in Electrical Engineering.}
\paragraph{\indent\indent $\cdot$ This picture/model for the electrical conductivity is called the \textcolor{blue}{Drude Model} after Paul Drude, who proposed this model in 1900.}
\paragraph{3. A different form of Ohm's Law - Let's suppose}
\paragraph{\indent $\cdot$ A uniform electric field $E$ exists in a wire whose material obeys the microscopic form of Ohm's Law (i.e., an ohmic conductor) $\boldsymbol{J}=\sigma\boldsymbol{E}$.}
\paragraph{\indent $\cdot$ The current density $J$ is uniformly distributed across the cross-sectional area $\alpha$ of the wire.}
\paragraph{\indent $\cdot$ The wire is $L$ meters long.}
\paragraph{Then, since $E=V/L$, the current density $I$ in the wire will be}
\begin{equation*}
    I=J\alpha=(\sigma E)\alpha=\sigma\frac{V}{L}\alpha=\frac{\sigma\alpha}{L}V\rightarrow I=\frac{V}{R}\quad:\quad R=\frac{L}{\sigma\alpha}
\end{equation*}
\paragraph{\indent a. In words: The \textcolor{blue}{The current} in a conductor \textcolor{blue}{is linearly proportional to the potential difference $\boldsymbol{V}$} between the ends of the conductor.}
\paragraph{\indent b. This is called "\textcolor{blue}{macroscopic form}" of \textcolor{blue}{Ohm's Law}.}
\paragraph{\indent c. The quantity $R$ is called the \textcolor{blue}{resistance} of the wire (units: ohms$=\Omega$). The resistance $R$ depends on everything that affects the conductivity $\sigma$ (number of conduction electrons per atom, temperature of conductor, purity of material, etc.) \underline{as well as} the geometry of the conductor.}
\paragraph{\indent d. The quantity $1/\sigma$ is called the \textcolor{blue}{resistivity} (units: ohms $\cdot$ meter$=\Omega\cdot m$).}
\subsubsection{Electromotive force $\mathcal{E}$}
\paragraph{1. From our studies of Ohm's Law and our prior work on conductors in previous chapters. We can summarize what we know about conductors by saying that:}
\paragraph{\indent a. If there is no net charge on the conductor, the electric charges in that conductor distribute themselves so that there is no potential difference anywhere in the conductor. The charge distribution throughout the conductor is then held in place by electrostatic forces (albeit with continuous thermal motion.)}
\paragraph{\indent b. We know from previous chapters that the only place where net charge can build up is on the surface of the a conductor because that's where the charge has no place left to go.}
\paragraph{\indent c. From our studies last time on Ohm's Law, we know that, except for extremely good insulators, any free charges injected into a material very rapidly redistribute until no potential difference exists anywhere in the wire. Electrostatic forces are responsible for this redistribution. We also now know that this redistribution takes place very quickly.}
\paragraph{\indent d. When charges move in a conductor, any kinetic energy of the electrons is quickly lost to heating the material. ($P=IV$)}
\paragraph{\indent e. Any electric charges set in motion quickly come to rest unless something supplies additional mechanical energy - a \textcolor{blue}{motive force}.}
\paragraph{2. With that background, let's go back to the question we raised earlier in the chapter: How  can electric circuits become useful?}
\paragraph{\indent a. If electric current is to continue moving in a circuit, a motive force must perform work to keep the charge moving in the circuit. This motive force provides the kinetic energy to the charges in the conductor that are in motion.}
\paragraph{\indent b. The motive force \textcolor{blue}{cannot be a magnetic force} because we know that magnetic forces do not work.}
\paragraph{\indent c. If that motive force isn't a magnetic force, then the motive force \textcolor{blue}{must be an electric force}.}
\paragraph{\indent d. The motive force \textcolor{blue}{cannot come from an electrostatic field} $\boldsymbol{E}_c$ because $q\oint\boldsymbol{E}_c\cdot\boldsymbol{dl}=0$. As we saw last semester, electrostatic fields conserve mechanical energy, and thus cannot supply the mechanical energy needed to keep charge moving in a circuit.}
\paragraph{\indent e. Thus, this motive force is a force due to a non-conservative force electric field that provides kinetic energy for the charges in motion in our circuit. We'll label it \textcolor{blue}{$\boldsymbol{F}_{motive}$}.}
\paragraph{3. Looking at all possibilities, the total (i.e., net) force $\boldsymbol{F}_{net}$ acting on any charge in our circuit must be}
\begin{equation*}
    \boldsymbol{F}_{net}=\sum\boldsymbol{F}=q\boldsymbol{E}_c+q\boldsymbol{v}\times\boldsymbol{B}+\textcolor{blue}{\boldsymbol{F}_{motive}}
\end{equation*}
\paragraph{4. Since we're discussing the source of mechanical energy to move charges in our circuit, let's divide by the charge on each of our moving charges  and look at the net force per unit charge $\boldsymbol{\mathfrak{f}}_net$ around the loop:}
\begin{equation*}
    \boldsymbol{\mathfrak{f}}_net=\boldsymbol{E}_c+\boldsymbol{v}\times\boldsymbol{B}+\boldsymbol{\mathfrak{f}}_m
\end{equation*}
\paragraph{5. The work per unit charge (units: joules/coulomb=volts) performed in our circuit by the three forces is the integral of $\boldsymbol{\mathfrak{f}}_{net}$ along a displacement $\boldsymbol{dl}$ in our wire for the entire circuit (a loop).}
\begin{equation*}
    \oint\boldsymbol{\mathfrak{f}}_{net}\cdot\boldsymbol{dl}=\oint\boldsymbol{E}_c\cdot\boldsymbol{dl}+\oint(\boldsymbol{v}\times\boldsymbol{B})\cdot\boldsymbol{dl}+\oint\boldsymbol{\mathfrak{f}}_m\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{\indent a. The first term on the right-hand side is zero since electrostatic fields like $\boldsymbol{E}_c$ are conservative:\\  
$\quad\quad\oint\boldsymbol{E}_c\cdot\boldsymbol{dl}=0$.}
\paragraph{\indent b. The second term due to magnetic forces is zero because $(\boldsymbol{v}\times\boldsymbol{B})\perp\boldsymbol{dl}$.}
\paragraph{\indent c. Thus, the only possible non-zero term - and thus only possible source of mechanical energy - is the term due to the motive force $\boldsymbol{F}_{motive}=q\boldsymbol{\mathfrak{f}}_m$.}
\begin{equation*}
    \oint\boldsymbol{\mathfrak{f}}_{net}\cdot\boldsymbol{dl}=\oint\boldsymbol{\mathfrak{f}}_m\cdot\boldsymbol{dl}\equiv\textsc{E}
\end{equation*}
\paragraph{\indent\indent i. The integral $\mathcal{E}=\oint\boldsymbol{\mathfrak{f}}_{net}\cdot\boldsymbol{dl}$ has its own name: the \textcolor{blue}{Electromotive force}.}
\paragraph{\indent\indent $\cdot$ The units for $\mathcal{E}$ must be joules/coulomb = volts.}
\paragraph{\indent\indent $\cdot$ A truly horrible name: $\mathcal{E}$ is \underline{not} a force; it's a \textcolor{blue}{potential difference}!}
\paragraph{\indent\indent ii. While we integrated around the whole loop, $\boldsymbol{\mathfrak{f}}_m$ may have been present only in a small portion of the circuit. Regardless, \textcolor{blue}{$\boldsymbol{\mathfrak{f}}_{motive}$ must be the source of the mechanical energy that keeps charges moving}.}
\paragraph{\indent\indent iii. The force $\boldsymbol{\mathfrak{f}}_{motive}$ provides the kinetic energy that keeps charges in the circuit moving. Examples of $\boldsymbol{\mathfrak{f}}_{motive}$ include:}
\paragraph{\indent\indent $\cdot$ \textcolor{blue}{Electrochemical}: Batteries, fuel cells, etc.}
\paragraph{\indent\indent $\cdot$ \textcolor{blue}{Mechanical}: Pressure on crystals (piezoeletrical effect), motions of conductors in magnetic fields.}
\paragraph{\indent\indent $\cdot$ \textcolor{blue}{Thermal}: Temperature differences involving dissimilar metals - the Seebeck, Thomson, and Peltier effects.}
\paragraph{\indent\indent $\cdot$ \textcolor{blue}{Photonic}: Excitations of electrons by absorbing photons.}
\paragraph{6. We now have a plausible answer to the previously asked question. How can electric circuits become useful?}
\paragraph{\indent a. \textcolor{blue}{Electric current will move in a conductor when a motive force performs the work to keep the charge moving in the circuit}. This motive force provides the kinetic energy to the charges in the conductor that are in motion.}
\paragraph{\indent b. The motive force is an electric force that may be thought of as injecting free electric charge into the conductor where the motive force is acting. \textcolor{blue}{This injected charge results in an electrostatic potential difference within the conductor}.}
\paragraph{\indent c. All electric charges throughout the conductor respond to this injection of free charge by rearranging themselves through electrostatic forces to eliminate any potential differences within the conductor. \textcolor{blue}{This rearrangement happens very quickly except in the best insulators} (essentially, the speed propagation of an electric field in the conductor).}
\paragraph{\indent d. If the motive force continues to inject charge into the conductor, the motive force acts like a source of a continuous potential difference $\mathcal{E}$ in the circuit, and charge withing the conductor continually redistributes itself to try to eliminate this potential difference.}
\subsubsection{Motional emf}
\paragraph{1. \textcolor{blue}{Experiment 1}: A length of wire (length $h$) is moving at a constant velocity $\boldsymbol{v}$ in a uniform magnetic field $\boldsymbol{B}$. The wire is \textcolor{blue}{entirely contained within} the magnetic field. The velocity $\boldsymbol{v}$ is perpendicular to $\boldsymbol{B}$. For simplicity, let's assume the charges are positive and let $\boldsymbol{B}$ be into the page.}
\paragraph{\indent a. The positive charges are acted on by the Lorentz force $\boldsymbol{F}=q\boldsymbol{v}\times\boldsymbol{B}$.}
\paragraph{\indent b. With this particular configuration of things, the magnitude of the Lorentz force will be $\boldsymbol{F}=q\nu\boldsymbol{B}$, and the force will point upward.}
\paragraph{\indent c. Positive charge will pile up at the top of the wire, and there will be a deficit of positive charge at the bottom of the wire.}
\paragraph{\indent d. If the motion is constant, the pileup and deficit will be constant and result in an electrostatic field: There will be a potential difference - an electromotive force $\mathcal{E}$ - between the top and bottom of the wire.}
\paragraph{\indent e. This electromotive force (potential difference) $\mathcal{E}$ between the top and bottom of the wire will exist as long as the wire is in motion. The emf will be given by}
\begin{equation*}
    \mathcal{E}=\oint\boldsymbol{\mathfrak{f}}_{net}\cdot\boldsymbol{dl}=\oint\boldsymbol{E}_c\cdot\boldsymbol{dl}+\oint(\boldsymbol{v}\times\boldsymbol{B})\cdot\boldsymbol{dl}+\oint\boldsymbol{\mathfrak{f}}_m\cdot\boldsymbol{dl}
\end{equation*}
\begin{equation*}
    \mathcal{E}=\int_{bottom}^{top}\frac{1}{q}(q\boldsymbol{v}\times\boldsymbol{B})\cdot\boldsymbol{dl}=B\nu h
\end{equation*}
\paragraph{\indent f. \textcolor{blue}{Magnetic forces do no work}. The work to separate charge is being performed by whatever is acting to keep the wire in motion.}
\paragraph{2. \textcolor{blue}{Experiment 2}: Suppose we now have a wire \underline{loop} (a circuit) \textcolor{blue}{completely inside} a uniform magnetic field $\boldsymbol{B}$. The loop is pulled to the right at a constant velocity $\boldsymbol{V}$. What will happen now?}
\paragraph{\indent a. We have the pileup and deficit situation again, and both ends of the loop get a pileup/deficit. The electromotive force $\mathcal{E}$ gets two contributions, but taken around the entire loop, they cancel:}
\begin{equation*}
    \mathcal{E}=\oint\boldsymbol{\mathfrak{f}}_{net}\cdot\boldsymbol{dl}=0
\end{equation*}
\paragraph{\indent b. Once the pileups take place, \textcolor{blue}{no current can flow in the loop}.}
\paragraph{\indent c. This state of affairs will continue as long as the loop moves and all portions of the loop is in the magnetic field.}
\paragraph{3. \textcolor{blue}{Experiment 3}: Suppose we now have this same wire loop in a uniform magnetic field $\boldsymbol{B}$ being pulled to the right at a constant velocity $\boldsymbol{v}$ but \textcolor{blue}{a portion of the loop is outside the magnetic field}. What will happen now?}
\paragraph{\indent a. We have this pileup and deficit - the potential difference - set up again in the left side, but charge can freely flow elsewhere.}
\paragraph{\indent b. \textcolor{blue}{Charge can flow around the circuit in a clockwise direction}. We get an electric current in this circuit.}
\paragraph{\indent c. This current will continue as long as the loop moves \underline{and} some portion of the loop is in the magnetic field.}
\paragraph{4. Now, the only thing that changed between Experiment 2 and Experiment 3 is that the magnetic flux $\Phi$ through the loop}
\begin{equation*}
    \textcolor{red}{\Phi=\int_S\boldsymbol{B}\cdot\boldsymbol{da}}
\end{equation*}
\paragraph{\indent was changing in Experiment 3. The magnetic flux $\Phi$ did not change in Experiment 2.}
\paragraph{In Experiment 3, as the loop moved, the magnetic flux $\Phi$ through the loop \underline{decreased}. Apparently, there's a proportionality between the electromotive force $\mathcal{E}$ "generated" and the change in magnetic flux $\Phi$ through the loop:}
\begin{equation*}
    \mathcal{E}\approx-\frac{d\Phi}{dt}
\end{equation*}
\paragraph{\indent a. How is the magnetic flux $\Phi$ changing in the loop? The uniform magnetic field $\boldsymbol{B}$ is not changing. What \textcolor{blue}{is} changing is the area of the loop $a$ in the field, which is decreasing as the loop moved to the right at velocity $v$:}
\begin{equation*}
    \dot{a}=\frac{da}{dt}=-\nu h
\end{equation*}
\paragraph{\indent so the magnetic flux $\Phi$ is changing in the loop as $\frac{d\Phi}{dt}=B\dot{a}=-B\nu h$.}
\paragraph{\indent b. But we saw in Experiment 1 that $B\nu h$ was the emf $\mathcal{E}$ generated by the left-hand wire moving through the field. Evidently we have the relationship}
\begin{equation*}
    \mathcal{E}=B\nu h=-(-B\nu h)=-\frac{d\Phi}{dt}
\end{equation*}
\paragraph{\indent c. In other words,}
\begin{equation*}
    \mathcal{E}=-\frac{d\Phi}{dt}=-\frac{d}{dt}\int_S\boldsymbol{B}\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent\indent i. This is called the "\textcolor{blue}{flux rule for motional emf}".}
\paragraph{\indent\indent ii. This is the principle behind electric generators: We move a wire loop (a circuit) or some portion thereof through a magnetic field, and an electromotive force $\mathcal{E}$ results.}
\paragraph{\indent\indent iii. If we have a solid conducting surface rather than a wire loop moving through a magnetic field, currents are generated in the surface ("eddy currents"). These currents can heat the conductor through the Joule heating law ($P=I^2R$), even going so far as to melt the material. This may be desirable or not, but it will be present.}
\paragraph{\indent\indent iv. Remember: The magnetic field is \textcolor{blue}{not} doing work. Whatever is causing the motion of the wire loop (or, better, the change in the magnetic flux $\Phi$ in the circuit) is responsible for providing energy (doing the work) to get and keep the charges moving.}
\paragraph{\indent\indent v. Notice the sign of this relationship. IF the flux changes, an emf is generated that, through the current produced, tries to restore the lost magnetic flux. This is the phenomenon behind \textcolor{blue}{Lenz's Law: "Nature abhors a change in the magnetic flux"}.}
\subsection{Electromagnetic Induction}
\subsubsection{Faraday's Law}
\paragraph{1. We saw last time that an emf can be generated when the motion of a circuit through a static magnetic field $\boldsymbol{B}$ causes the magnetic flux through the circuit to change. The motion generated a "\textcolor{blue}{motional emf}".}
\paragraph{2. Experiments by Faraday in 1831 demonstrated conclusively that if the magnetic flux changes in a circuit \textcolor{blue}{because $\boldsymbol{B}$ changes}, an emf is generated in that instance, too - even if the circuit is not moving.}
\paragraph{3. In both cases, we have a magnetic flux through a loop $\Phi$ changing with time:}
\begin{equation*}
    \mathcal{E}=\oint_c\boldsymbol{f}\cdot\boldsymbol{dl}=-\frac{d\Phi}{dt}=-\frac{\partial}{\partial t}\iint_S\boldsymbol{B}\cdot\boldsymbol{da}
\end{equation*}
\paragraph{Faraday's experiments were more specific:}
\begin{equation*}
\mathcal{E}=-\iint_S\frac{\partial\boldsymbol{B}}{\partial t}\cdot \boldsymbol{da}
\end{equation*}
\paragraph{4. Faraday's famous insight (or guess):}
\paragraph{\indent a. Many people (including Faraday) had conducted experiments for years using the voltage (and electric field) from a battery to generate a current in a wire.}
\paragraph{\indent b. The common wisdom had come to be that \underline{an electric field is required to establish a current in}\\\underline{ a wire}. (We made a similar conclusion about what generates a current in the last lesson but for different reasons.)}
\paragraph{\indent c. When Faraday saw that his varying magnetic field and coil experiments produced currents in a wire, he hypothesized that the source of the emf in a loop within a changing magnetic field was also an electric field -\textcolor{blue}{ but an electric field $\boldsymbol{E}$ "induced" by the changing magnetic field}.}
\begin{equation*}
    \mathcal{E}=-\frac{d\Phi}{dt}=-\iint_S\frac{\partial\boldsymbol{B}}{\partial t}\cdot \boldsymbol{da}=\oint_C\boldsymbol{f}\cdot\boldsymbol{dl}=\oint_C\boldsymbol{E}\cdot\boldsymbol{dl}\neq 0
\end{equation*}
\paragraph{\indent d. If this is true, using Stoke's Theorem for the curl, we see that}
\begin{equation*}
    \oint_C\boldsymbol{E}\cdot\boldsymbol{dl}=-\iint_S(\nabla\times\boldsymbol{E})\cdot\boldsymbol{da}\neq 0\rightarrow \nabla\times\boldsymbol{E}\neq 0 \quad\text{!?!?!}
\end{equation*}
\paragraph{\indent\indent i. Since the curl of $\boldsymbol{E}$ is not zero, perhaps we should say that \underline{some portion} of this electric field $\boldsymbol{E}$ does not yield a "conservative" force.}
\paragraph{\indent\indent ii. Let's write the total electric field $\boldsymbol{E}$ as $\boldsymbol{E}_c+\boldsymbol{E}_{nc}$, where we have "conservative" and "non-conservative" parts, respectively, of the total electric field $\boldsymbol{E}.$}
\paragraph{\indent\indent $\cdot$ We know $\boldsymbol{E}_c$ is the gradient of a scalar electric potential: $\boldsymbol{E}_c=-\nabla V$.}
\paragraph{\indent\indent $\cdot$ We know from all our studies this semester of electrostatics that}
\begin{equation*}
    \oint_C\boldsymbol{E}_c\cdot\boldsymbol{dl}=0\quad:\quad \nabla\times\boldsymbol{E}_c=0
\end{equation*}
\paragraph{\indent\indent $\cdot$ We also said in the last section that, because the loop integral vanishes for $\boldsymbol{E}_c$, then $\boldsymbol{E}_c$ does not generate a motional emf.}
\paragraph{\indent\indent $\cdot$ Apparently, for this "non-conservative" $\boldsymbol{E}_{nc}$, we in fact must have}
\begin{equation*}
    \oint_C\boldsymbol{E}_{nc}\cdot\boldsymbol{dl}\neq 0\quad:\quad \nabla\times\boldsymbol{E}_{nc}\neq 0
\end{equation*}
\paragraph{5. Putting all this together, we have}
\begin{equation*}
    \mathcal{E}=\oint_C\boldsymbol{E}\cdot\boldsymbol{dl}=-\frac{d\Phi}{dt}=-\iint_S\frac{\partial\boldsymbol{B}}{\partial t}\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent Using Stoke's Theorem of the curl, we get}
\begin{align*}
    \mathcal{E}=\oint_C\boldsymbol{E}\cdot\boldsymbol{dl}&=\iint_S(\nabla\times\boldsymbol{E})\cdot\boldsymbol{da}=-\iint_S\frac{\partial\boldsymbol{B}}{\partial t}\cdot\boldsymbol{da}\\
    \iint_S\bigg(\nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}\bigg)\cdot\boldsymbol{da}&=0\\
    \nabla\times\boldsymbol{E}&=-\frac{\partial \boldsymbol{B}}{\partial t}
\end{align*}
\paragraph{\indent a. This is the differential form of Faraday's Law, one of Maxwell's Equations.}
\paragraph{\indent b. We can get the integral form of Faraday's Law from the line earlier.}
\begin{equation*}
    \oint_C\boldsymbol{E}\cdot\boldsymbol{dl}=-\iint_S\frac{\partial\boldsymbol{B}}{\partial t}\cdot \boldsymbol{da}
\end{equation*}
\paragraph{6. Looking more closely at the integral form, we had arrived at the result}
\begin{equation*}
    \iint_S\bigg( \nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}\bigg)\cdot\boldsymbol{da}=0
\end{equation*}
\paragraph{\indent a. But we could also write $\boldsymbol{B}=\nabla\times\boldsymbol{A}$. Using this we have}
\begin{equation*}
    \iint_S\bigg(\nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}\bigg)\cdot\boldsymbol{da}=\iint_S\bigg(\nabla\times\boldsymbol{E}+\frac{\partial}{\partial t}(\nabla\times\boldsymbol{A})\bigg)\cdot\boldsymbol{da}=0
\end{equation*}
\begin{equation*}
    \iint_S\bigg(\nabla\times\bigg\{ \boldsymbol{E}+\frac{\partial\boldsymbol{A}}{\partial t}\bigg\}\bigg)\cdot\boldsymbol{da}=0
\end{equation*}
\paragraph{\indent Recall that the curl of the gradient of a scalar function is zero:}
\begin{equation*}
    \nabla\times(\nabla f)=0
\end{equation*}
\paragraph{\indent b. Since $\nabla\times(\nabla f)=0$, we could write the quantity in braces as}
\begin{equation*}
    \bigg\{\boldsymbol{E}+\frac{\partial\boldsymbol{A}}{\partial t}\bigg\}=-\nabla V
\end{equation*}
\paragraph{\indent c. This gives us the definition of the electric field for Maxwell's Equations:}
\begin{equation*}
    \boldsymbol{E}=-\nabla V-\textcolor{red}{\frac{\partial\boldsymbol{A}}{\partial t}}
\end{equation*}
\paragraph{\indent\indent i. Remember that we said we wanted to write $\boldsymbol{E}=\boldsymbol{E}_c+\textcolor{red}{\boldsymbol{E}_nc}$.}
\paragraph{\indent\indent ii. We have also said that $\boldsymbol{E}_c=-\nabla V$}
\paragraph{\indent\indent iii. Evidently, the "non-conservative" portion of the total electric field - the "Faraday-induced electric field" - comes from the term}
\begin{equation*}
    \textcolor{red}{\boldsymbol{E}_{nc}=-\frac{\partial\boldsymbol{A}}{\partial t}}
\end{equation*}
\subsubsection{Inductance}
\paragraph{1. There is a "chain of causation" for the electromotive force \textcolor{red}{$\mathcal{E}_2$} in \textcircled{2} (the "secondary loop"):}
\paragraph{\indent a. The electromotive force \textcolor{red}{$\mathcal{E}_2$} generated in \textcircled{2} depends on the \textcolor{red}{change in magnetic flux $\Phi_2$} through \textcircled{2}.}
\begin{equation*}
    \textcolor{red}{\mathcal{E}_2}=-\frac{d\textcolor{red}{\phi_2}}{dt}
\end{equation*}
\paragraph{\indent b. The \textcolor{red}{flux $\phi_2$} depends on the strength of the \textcolor{red}{magnetic field $\boldsymbol{B}_1$} generated by \textcircled{1} (the "primary loop").}
\begin{equation*}
    \textcolor{red}{\phi_2}=\iint_{S_2}\textcolor{red}{\boldsymbol{B}_1}\cdot\boldsymbol{da}
\end{equation*}
\paragraph{\indent c. The strength of the \textcolor{red}{magnetic field $\boldsymbol{B}_1$} depends on the \textcolor{red}{current $I_1$} in \textcircled{1} (the "primary loop")}
\begin{equation*}
    \textcolor{red}{\boldsymbol{B}_1}(\boldsymbol{r})=\frac{\mu_0\textcolor{red}{I_1}}{4\pi}\int\frac{\boldsymbol{dl}_1'\times\hat{\boldsymbol{\mathfrak{r}}}}{\mathfrak{r}^2}
\end{equation*}
\paragraph{2. Based on this chain of causation, we should be able to say}
\begin{equation*}
    \mathcal{E}_2=-\frac{d\phi_2}{dt}\cdot\frac{dI_1}{dt}=-M_{21}\cdot\frac{dI_1}{dt}\quad\text{where}\quad M_{21}\equiv\frac{d\phi_2}{dI_1}  
\end{equation*}
\paragraph{\indent a. The quantity $M_{21}$ is called the \textcolor{blue}{mutual inductance} for the two circuits.}
\paragraph{\indent b. $M_{21}$ is related to the geometry of the circuit receiving the flux (circuit\textcircled{2}),the geometry of the circuit generating the field (circuit \textcircled{1}), and the orientation of those circuits with respect to each other.}
\paragraph{\indent c. If the geometries and relative orientations of the circuits remain fixed, the quantity $M_{21}$ should be constant. We can thus say}
\begin{equation*}
    \mathcal{E}_2=-M_{21}\frac{dI_1}{dt}
\end{equation*}
\paragraph{\indent d. If $M_{21}$ is a constant, then we can say}
\begin{equation*}
    M_{21}\equiv\frac{d\phi_2}{dI_1}\rightarrow d\phi_2=M_{21}\cdot dI_1\rightarrow \phi_2=M_{21}\cdot I_1
\end{equation*}
\paragraph{The last relationship yields the MKS unit for inductance: the \textcolor{blue}{henry}}
\paragraph{\indent 1 henry $=$ 1 Tesla m$^2$ per ampere $=$ volt second/ampere}
\paragraph{\indent e. We can more explicitly state how $M_{21}$ arises using the Biot-Savart Law (quasistatics again) and the relationship $\boldsymbol{B}=\nabla\times\boldsymbol{A}$. The resulting expression is called the \textcolor{blue}{Neumann formula}.}
\begin{equation*}
    M_{21}=\frac{\mu_0}{4\pi}\oint_{C_2}\oint_{C_1}\frac{\boldsymbol{dI_1}\cdot\boldsymbol{dI_2}}{\mathfrak{r}}
\end{equation*}
\paragraph{\indent\indent i. Only for simple geometries is this integral amenable to a closed solution, but it can always be done numerically.}
\paragraph{\indent\indent ii. Hmm... The labels 1 and 2 are arbitrary in this integral since the order of integration doesn't matter. That means we also must have $M_{21}=M_{12}$. Indeed, we can just call them both $M$, the mutual inductance.}
\paragraph{\indent f. If we go all the way back to where we started, we can now write}
\begin{equation*}
    \textcolor{red}{\mathcal{E}_2}=-\frac{d\textcolor{red}{\phi_2}}{dt}=-M_{21}\cdot\frac{dI_1}{dt}=-M\cdot\frac{dI_1}{dt}
\end{equation*}
\paragraph{\indent\indent i. Again, our labels are arbitrary. Thus, if we choose a particular \textcolor{blue}{$dI/dt$},}
\begin{align*}
    \textcolor{red}{\mathcal{E}_2}=-M_{21}\cdot\frac{dI_1}{dt}&=-M\cdot\frac{dI_1}{dt}=-M\cdot\textcolor{blue}{\frac{dI}{dt}}\\
    \textcolor{red}{\mathcal{E}_1}=-M_{12}\cdot\frac{dI_2}{dt}&=-M\cdot\frac{dI_2}{dt}=-M\cdot\textcolor{blue}{\frac{dI}{dt}}\\
    \textcolor{red}{\mathcal{E}_2}&\textcolor{red}{=\mathcal{E}_1}\\
\end{align*}
\paragraph{\indent\indent ii. We get the same emf $\textcolor{red}{\mathcal{E}}$ induced in either loop for a given $\textcolor{blue}{dI/dt}$.}
\paragraph{\indent\indent iii. This is the basis of the \textcolor{blue}{transformer equation} you studied in Intro-Physics.}
\begin{equation*}
    \frac{\mathcal{E}_1}{\mathcal{E}_2}=\frac{N_1}{N_2}
\end{equation*}
\paragraph{For a transformer, the flux in each circuit is boosted by increasing the number of loops $N$ in that circuit. The emf radio is adjusted by adjusting the number of loops in each circuit.}
\paragraph{3. We have been looking at what happens in circuit \textcircled{2} when we change the current $I_1$ in circuit \textcircled{1}:}
\begin{equation*}
    \mathcal{E}_2=-\frac{d\phi_2}{dt}=-M\cdot\frac{dI_1}{dt}
\end{equation*}
\paragraph{\indent But we've completely ignored what simultaneously must have been happening to the flux back in circuit \textcircled{1} when we change the current there.}
\paragraph{\indent a. If $I_1$ changes in \textcircled{1}, the magnetic flux $\phi_1$ in \textcircled{1} due to \textcolor{blue}{its own} magnetic field $\boldsymbol{B}_1$ also changes.}
\paragraph{\indent b. The changing $\phi_1$ due to changing $I_1$ must also induce an emf in \textcircled{1} --- in other words, we should consider a \textcolor{blue}{sef inductance} $L$ for \textcircled{1}.}
\begin{equation*}
    \mathcal{E}_1=-\frac{d\phi_1}{dt}=\frac{d\phi_1}{dI_1}\cdot\frac{dI_1}{dt}=-L\frac{dI_1}{dt}
\end{equation*}
\paragraph{\indent c. This is the origin of Lenz's Law! $\mathcal{E}$ \underline{opposes} flux change.}
\paragraph{\indent d. Much of what we said for $M$ applies to $L$: $L$ is related to the geometry of the circuit receiving the flux (in this case, circuit \textcircled{1}) and the geometry of the circuit generating the field (once again, circuit \textcircled{1}).}
\paragraph{\indent e. If the geometry of \textcircled{1} is fixed, then $L$ is a constant, and we can say}
\begin{equation*}
    \phi=LI
\end{equation*}
\paragraph{\indent\indent i. Calculating a self-inductance $L$ (BTW: $L$ is often just called "inductance") is much easier than calculating a mutual inductance $M$. All you need to do is find the flux generated by the magnetic field of the circuit through \textcolor{blue}{its own} area, and divide by the current $I$ used to produce that field.}
\begin{equation*}
    L=\frac{\phi}{I}
\end{equation*}
\paragraph{\indent\indent ii. \textcolor{red}{Example}: A long solenoid has $n$ turns per unit length, diameter $2R$, and is carrying a current $I$. What is its inductance $L$?}
\paragraph{\indent\indent $\cdot$ The uniform magnetic field within the solenoid is $B=\mu_0nI$.}
\paragraph{\indent\indent $\cdot$ The cross sectional area of the solenoid is $\pi R^2$.}
\paragraph{\indent\indent $\cdot$ The flux through the circuit will be $\phi=BA=\mu_0nI\cdot\pi R^2$.}
\paragraph{\indent\indent $\cdot$ Since we know the flux $\phi$ in terms of $I$, the inductance $L$ is simply}
\begin{equation*}
    L=\frac{\phi}{I}=\mu_0n\pi R^2
\end{equation*}
\paragraph{\indent\indent $\cdot$ If we make $n$ really big, we will produce a whopping "back emf": a "choke".}
\subsubsection{Energy in magnetic fields}
\paragraph{1. Establishing a current in a circuit takes energy (i.e., requires work). The rate at which we supply work to establish the current is the instantaneous power}
\begin{equation*}
    P=\frac{dW}{dt}=-\mathcal{E}I=-\bigg(-L\frac{dI}{dt}\bigg)I
\end{equation*}
\begin{equation*}
    \frac{dW}{dt}=L\frac{dI}{dt}\cdot I\rightarrow W=\frac{1}{2}LI^2
\end{equation*}
\paragraph{2. But we can also write}
\begin{equation*}
    \phi=LI=\iint_S\boldsymbol{B}\cdot\boldsymbol{da}=\iint_S(\nabla\times\boldsymbol{A})\cdot\boldsymbol{da}=\oint_C\boldsymbol{A}\cdot\boldsymbol{dl}
\end{equation*}
\paragraph{3. Based on the expression above for the work needed to establish the current $I$ in our circuit, the energy needed must be equal to}
\begin{equation*}
    W=\frac{1}{2}LI^2=W=\frac{1}{2}\phi I=\frac{1}{2}\bigg(\oint\boldsymbol{A}\cdot\boldsymbol{dl}\bigg)I=\frac{1}{2}\oint_C(\boldsymbol{A}\cdot\boldsymbol{I})dl
\end{equation*}
\paragraph{4. Generalizing this to a volume current density $\boldsymbol{J}$, we would write this as}
\begin{equation*}
    W=\frac{1}{2}\oint_C(\boldsymbol{A}\cdot\boldsymbol{I})dl\rightarrow W=\frac{1}{2}\oint_V(\boldsymbol{A}\cdot\boldsymbol{J})d\tau
\end{equation*}
\paragraph{5. From our magnetostatics work, we have Ampere's Law $\nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}$. So in the quasistatic approximation, we can re-write our energy expression as}
\begin{equation*}
    W=\frac{1}{2\mu_0}\oint_V\boldsymbol{A}\cdot(\nabla\times\boldsymbol{B})d\tau
\end{equation*}
\begin{equation*}
    W=\frac{1}{2\mu_0}\oint_V\{ \boldsymbol{B}\cdot(\nabla\times\boldsymbol{A})-\nabla\cdot(\boldsymbol{A}\times\boldsymbol{B})\} d\tau
\end{equation*}
\paragraph{\indent The first integrand is actually just $B^2d\tau$.}
\paragraph{\indent Next, we use the Divergence Theorem of Gauss on the second term and write}
\begin{equation*}
    W=\frac{1}{2\mu_0}\int_VB^2d\tau-\frac{1}{2\mu_0}\int_S(\boldsymbol{A}\times\boldsymbol{B})\cdot\boldsymbol{da}
\end{equation*}
\paragraph{6. If we have finite sources and use all space as our volume $V$, then $\boldsymbol{A}$ and $\boldsymbol{B}$ must vanish on the surface of $V$ at infinity.}
\paragraph{7. The second term will be zero, then, and we're left with}
\begin{equation*}
    W=\frac{1}{2\mu_0}\int_{all space}B^2d\tau
\end{equation*}
\paragraph{\indent Compare this with what we got for the electric fields in the first chapter.}
\subsection{Maxwell's Equations}
\subsubsection{The displacement current $\boldsymbol{J}_d$ (Maxwell's "fix")}
\paragraph{1. After a semester of work, we have arrived at the following \textcolor{blue}{quasi-static equations} equivalent to what the world knew circa 1850, all of which where based on experimental observations:}
\paragraph{\indent a. \textcolor{blue}{Gauss' Law}, based on observations and Coulomb's Law:}
\begin{equation*}
    \nabla\cdot\boldsymbol{E}=\frac{\rho}{\epsilon_0}
\end{equation*}
\paragraph{\indent b. The statement that there are \textcolor{blue}{no magnetic monopoles}, based on observations and the Biot-Savart Law:}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}=0
\end{equation*}
\paragraph{\indent c. \textcolor{blue}{Faraday's Law}, based on observations:}
\begin{equation*}
    \nabla\times\boldsymbol{E}=-\frac{\partial\boldsymbol{B}}{\partial t}
\end{equation*}
\paragraph{\indent d. \textcolor{blue}{Ampere's Law}, based on observations and the Biot-Savart Law:}
\begin{equation*}
    \nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}
\end{equation*}
\paragraph{2. In 1855, James Clark Maxwell (JCM) was appointed to the chair of Natural Philosophy of Marischal College in Aberdeen, Scotland. JCM had been a math prodigy, presenting papers in his teens to the Royal Society.}
\paragraph{\indent a. He threw himself into sorting out \textcolor{red}{mathematically} the physics of the phenomenon associated with electricity and magnetism. He published three key papers in the period 1856 to 1864 that are the foundation for E and M.}
\paragraph{\indent b. Modern vector notation (mostly due to Heaviside circa 1884) did not exist, but JCM nonetheless spotted a major inconsistency in the quasistatic equations:}
\paragraph{\indent\indent i. JCM knew \textcolor{blue}{the divergence of the curl of a vector field is zero}: $\nabla\cdot(\nabla\times\boldsymbol{v})=0$.}
\paragraph{\indent\indent ii. JCM saw the identity held for the electric field $\boldsymbol{E}$:}
\begin{equation*}
    \nabla\cdot(\nabla\times\boldsymbol{E})=\nabla\cdot\bigg(-\frac{\partial\boldsymbol{B}}{\partial t}\bigg)=-\frac{\partial}{\partial t}(\nabla\cdot\boldsymbol{B})=0
\end{equation*}
\paragraph{\indent\indent iii. But he saw the identity in general fails for the 1850's version of Ampere's Law for the magnetic field $\boldsymbol{B}$:}
\begin{equation*}
    \nabla\cdot(\nabla\times\boldsymbol{B})=\textcolor{red}{\nabla\cdot(\mu_0\boldsymbol{J})\neq 0}
\end{equation*}
\paragraph{\indent\indent $\cdot$ He replaced $\nabla\cdot\boldsymbol{J}$ by using the continuity equation}
\begin{equation*}
    \nabla\cdot\boldsymbol{J}=-\frac{\partial \rho}{\partial t}
\end{equation*}
\paragraph{\indent\indent $\cdot$ He also knew from Gauss' Law that}
\begin{equation*}
    \rho=\epsilon_0\nabla\cdot\boldsymbol{E}
\end{equation*}
\paragraph{\indent\indent $\cdot$ Substituting this into the $\nabla\cdot\boldsymbol{J}$ expression, he saw}
\begin{equation*}
    \nabla\cdot(\mu_0\boldsymbol{J})=\mu_0\nabla\cdot\boldsymbol{J}=-\mu_0\epsilon_0\frac{\partial(\nabla\cdot\boldsymbol{E})}{\partial t}
\end{equation*}
\paragraph{\indent\indent which means the original identity was actually}
\begin{equation*}
    \nabla\cdot(\nabla\times\boldsymbol{B})=\textcolor{red}{-\mu_0\epsilon_0\frac{\partial(\nabla\cdot\boldsymbol{E})}{\partial t}\neq 0}
\end{equation*}
\paragraph{3. Maxwell saw that, for consistency, he needed to modify Ampere's Law by \underline{inserting an} \\\underline{additional term}:}
\begin{equation*}
    \nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}+\textcolor{blue}{\mu_0\epsilon_0\frac{\partial \boldsymbol{E}}{\partial t}}
\end{equation*}
\paragraph{\indent a. This additional term will cancel the right-hand side we saw above.}
\paragraph{\indent b. With that change, all four equations are completely consistent with each other.}
\paragraph{\indent c. In numbers, $\mu_0\epsilon_0=1.1\times 10^{-17}s^2m^{-2}$. Unless the \textcolor{blue}{derivative} is huge (enormous field or frequency), the added term is nearly impossible to detect (and certainly was impossible to detect in the mid-19th century).}
\paragraph{\indent d. Since this extra term comes in with $\epsilon_0\boldsymbol{E}$, JCM called this added term the "\textcolor{blue}{displacement current}".}
\subsubsection{Maxwell's equations (in vacuo and in matter)}
\paragraph{1. We now have a fully consistent set of equations for thow the fields and sources behave in vacuum. These are the "true" Maxwell's Equations:}
\paragraph{\indent a. \textcolor{blue}{Gauss' Law}, based on observations and Coulomb's Law:}
\begin{equation*}
    \nabla\cdot\boldsymbol{E}=-\frac{\rho}{\epsilon_0}
\end{equation*}
\paragraph{\indent b. The statement that there are \textcolor{blue}{no magnetic monopoles}, based on observations and the Biot-Savart Law:}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}=0
\end{equation*}
\paragraph{\indent c. \textcolor{blue}{Faraday's Law}, based on observations:}
\begin{equation*}
    \nabla\times\boldsymbol{E}=-\frac{\partial \boldsymbol{B}}{\partial t}
\end{equation*} 
\paragraph{\indent d. \textcolor{blue}{Ampere's Law}, based on observations, the Biot-Savart Law, the continuity equation \textcolor{blue}{plus Maxwell's \underline{theoretical} "fix"}:}
\begin{equation*}
    \nabla\times\boldsymbol{B}=\mu_0\boldsymbol{J}+\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}
\end{equation*}
\paragraph{2. As most textbooks suggest, these can be written in a more pedagogical form with \textcolor{blue}{sources} on the right-hand side and \textcolor{blue}{fields} on the left:}
\paragraph{\indent a. Gauss' Law:}
\begin{equation*}
    \epsilon_0\nabla\cdot\boldsymbol{E}=\rho
\end{equation*}
\paragraph{\indent b. No magnetic monopoles:}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}=0
\end{equation*}
\paragraph{\indent c. Faraday's Law:}
\begin{equation*}
    \nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}=0
\end{equation*}
\paragraph{\indent d. Ampere's Law plus Maxwell's "fix":}
\begin{equation*}
    \nabla\times\boldsymbol{B}-\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}=\mu_0\boldsymbol{J}
\end{equation*}
\paragraph{3. Of course, much of the time, the electric and magnetic fields are in matter, not vacuum. Let's recast the vacuum forms of Maxwell's Equations into forms appropriate for materials. \textcolor{blue}{Such a change will only affect the equations which have sources on the right hand side}.}
\paragraph{\indent a. The \textcolor{blue}{no-monopole statement} does not change: $\textcolor{red}{nabla\cdot\boldsymbol{B}=0}$.}
\paragraph{\indent b. \textcolor{blue}{Faraday's Law} doesn't change either: \textcolor{red}{$\nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}=0$}.}
\paragraph{\indent c. While \textcolor{blue}{Gauss' Law} has a source on the right hand side, it actually doesn't change either:}
\paragraph{\indent\indent i. The charge density remains $\rho=\rho_f+\rho_b=\rho_f-\nabla\cdot\boldsymbol{P}$}
\paragraph{\indent\indent ii. Gauss' Law in materials is}
\begin{align*}
    \epsilon_0\nabla\cdot\boldsymbol{E}&=\rho=\rho_f-\nabla\cdot\boldsymbol{P}\\
    \epsilon_0\nabla\cdot\boldsymbol{E}+\nabla\cdot\boldsymbol{P}&=\rho_f\\
    \nabla\cdot(\epsilon_0\boldsymbol{E}+\boldsymbol{P})&=\rho_f\\
    \textcolor{red}{\nabla\cdot\boldsymbol{D}}&\textcolor{red}{=\rho_f\quad\quad:\quad \boldsymbol{D}=\epsilon_0\boldsymbol{E}+\boldsymbol{P}}\\
\end{align*}
\paragraph{\indent d. But the source term in \textcolor{blue}{Ampere's Law} will need more work.}
\paragraph{\indent\indent i. In the last chapter, the current density $\boldsymbol{J}$ was broken into free and bound pieces:}
\begin{equation*}
    \boldsymbol{J}=\boldsymbol{J}_f+\boldsymbol{J}_b=\boldsymbol{J}_f+\nabla\times\boldsymbol{M}
\end{equation*}
\paragraph{\indent\indent ii. But if static charges can move, we are missing the portion of the bound current where the bound polarization charges in electric dipoles oscillates back and forth. To take account of that, we add a \textcolor{blue}{polarization current density} to $\boldsymbol{J}$. This polarization current density is defined as}
\begin{equation*}
    \boldsymbol{J}_p=\frac{\partial\boldsymbol{P}}{\partial t}\rightarrow \boldsymbol{J}=\boldsymbol{J}_f+\boldsymbol{J}_b+\boldsymbol{J}_p=\boldsymbol{J}_f+\nabla\times\boldsymbol{M}+\frac{\partial \boldsymbol{P}}{\partial t}
\end{equation*}
\paragraph{\indent\indent iii. With this term, Ampere's Law becomes:}
\begin{align*}
    \nabla\times\boldsymbol{B}&=\mu_0\boldsymbol{J}+\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}=\mu_0\{ \boldsymbol{J}_f+\boldsymbol{J}_b+\boldsymbol{J}_p\}+\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}\\
    \nabla\times\boldsymbol{B}&=\mu_0\bigg\{ \boldsymbol{J}_f+\nabla\times\boldsymbol{M}+\frac{\partial\boldsymbol{P}}{\partial t}\bigg\} +\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}\\
    \nabla\times \frac{\boldsymbol{B}}{\mu_0}&=\boldsymbol{J}_f+\nabla\times\boldsymbol{M}+\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}+\frac{\partial\boldsymbol{P}}{\partial t}\\
    \nabla\times\bigg( \frac{\boldsymbol{B}}{\mu_0}-\boldsymbol{M}\bigg)&=\boldsymbol{J}_f+\frac{\partial}{\partial t}(\epsilon_0\boldsymbol{E}+\boldsymbol{P})\\
    \textcolor{red}{\nabla\times\boldsymbol{H}}&\textcolor{red}{=\boldsymbol{J}_f+\frac{\partial\boldsymbol{D}}{\partial t}\quad:\quad \boldsymbol{H}=\bigg( \frac{\boldsymbol{B}}{\mu_0}-\boldsymbol{M}\bigg)}
\end{align*}
\paragraph{\indent e. So, in materials, Maxwell's Equations in materials have become:}
\paragraph{\indent\indent i. Gauss' Law:}
\begin{equation*}
    \nabla\cdot\boldsymbol{D}=\rho_f
\end{equation*}
\paragraph{\indent\indent ii. No magnetic monopoles:}
\begin{equation*}
    \nabla\cdot\boldsymbol{B}=0
\end{equation*}
\paragraph{\indent\indent iii. Faraday's Law:}
\begin{equation*}
    \nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}=0
\end{equation*}
\paragraph{\indent\indent iv. Ampere's Law plus Maxwell's "fix":}
\begin{equation*}
    \nabla\times\boldsymbol{H}+\boldsymbol{J}_f+\frac{\partial\boldsymbol{D}}{\partial t}
\end{equation*}
\paragraph{\indent\indent v. With these in hand, you can develop the boundary conditions using pillboxes and loops, per usual.}
\paragraph{\indent\indent vi. Add the Lorentz force law, and you have everything needed to handle electric charges and currents in classical mechanics. As we said in the first chapter, \textcolor{blue}{this was one of our primary motivations for E and M}.}
\paragraph{4. Maxwell didnt stop once the equations were consistent. JCM moved to King's College in London in 1860.}
\paragraph{\indent a. Having taken the divergence of the curl of the fields, JCM also knew he could tae the curl of the curl.}
\begin{align*}
    \nabla\times\boldsymbol{E}+\frac{\partial\boldsymbol{B}}{\partial t}&=0\\
    \nabla\times(\nabla\times\boldsymbol{E})&=-\frac{\partial}{\partial t}\nabla\times\boldsymbol{B}\\
\end{align*}
\paragraph{\indent b. Using vector identities, the left-hand side (in vacuo) is }
\begin{equation*}
    \nabla\times(\nabla\times\boldsymbol{E})=\nabla(\nabla\cdot\boldsymbol{E})-\nabla^2\boldsymbol{E}=-\nabla^2\boldsymbol{E}
\end{equation*}
\paragraph{\indent c. The right-hand side uses Ampere's Law with JCM's fix:}
\begin{equation*}
    -\frac{\partial}{\partial t}\nabla\times\boldsymbol{B}=-\frac{\partial}{\partial t}\bigg( \mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}\bigg) =-\mu_0\epsilon_0\frac{\partial^2\boldsymbol{E}}{\partial t^2}
\end{equation*}
\paragraph{\indent d. Putting these pieces together we get}
\begin{equation*}
    \nabla^2\boldsymbol{E}=\mu_0\epsilon_0\frac{\partial^2\boldsymbol{E}}{\partial t^2}\quad:\quad\text{A wave equation for $\boldsymbol{E}$!}
\end{equation*}
\paragraph{5. He then did a similar analysis for the curl of $\boldsymbol{B}$:}
\begin{align*}
    \nabla\times\boldsymbol{B}-\mu_0\epsilon_0\frac{\partial\boldsymbol{E}}{\partial t}&=0\\
    \nabla\times(\nabla\times\boldsymbol{B})&=\mu_0\epsilon_0\frac{\partial}{\partial t}\nabla\times\boldsymbol{E}\\
\end{align*} 
\paragraph{\indent a. Using vector identities, the left-hand side (in vacuo) is}
\begin{equation*}
    \nabla\times(\nabla\times\boldsymbol{B})=\nabla(\nabla\boldsymbol{B})-\nabla^2\boldsymbol{B}=-\nabla^2\boldsymbol{B}
\end{equation*}
\paragraph{\indent b. the right-hand side uses Faraday's Law:}
\begin{equation*}
    \frac{\partial}{\partial t}\nabla\times\boldsymbol{E}=\frac{\partial}{\partial t}\bigg( -\mu_0\epsilon_0\frac{\partial\boldsymbol{B}}{\partial t}\bigg)=-\mu_0\epsilon_0\frac{\partial^2\boldsymbol{B}}{\partial t^2}
\end{equation*}
\paragraph{\indent c. Putting these together we get}
\begin{equation*}
    \nabla^2\boldsymbol{B}=\mu_0\epsilon_0\frac{\partial^2\boldsymbol{B}}{\partial t^2}\quad:\quad\text{A wave equation for $\boldsymbol{B}$!}
\end{equation*}
\paragraph{6. Thus, in 1865, JCM wound up with two very pretty and identical wave equations for $\boldsymbol{E}$ and $\boldsymbol{B}$:}
\begin{equation*}
    \nabla^2\boldsymbol{E}=\mu_0\epsilon_0\frac{\partial^2\boldsymbol{E}}{\partial t^2}\quad:\quad\nabla^2\boldsymbol{B}=\mu_0\epsilon_0\frac{\partial^2\boldsymbol{B}}{\partial t^2}
\end{equation*}
\paragraph{\indent a. These wave propagate together through space at a velocity given by:}
\begin{equation*}
    v=(\mu_0\epsilon_0)^{-\frac{1}{2}}=3\times10^8 \quad \text{m/s}
\end{equation*}
\paragraph{\indent b. JCM immediately recognized that the best experiments of his time gave almost exactly this number as the \textcolor{blue}{speed of light}!}
\paragraph{\indent c. \textcolor{blue}{"...light consists in the transverse undulations of the same medium which is the cause of the electric and magnetic phenomena."}}
\paragraph{\indent d. This was \textcolor{blue}{completely unexpected}. No scientist working with batteries, froglegs, and magnets in the early 19th century thought that light and optics had anything to do with electricity and magnetism.}
\paragraph{7. Tremendous skepticism resulted.}
\paragraph{8. Arguably, the linchpin for acceptance came with \textcolor{blue}{Heinrich Hertz's} experiments in 1887-1889, wherein he produced and measured the effects of radio-wavelength polarized electromagnetic radiation.}
\paragraph{9. Commenting on Maxwell's theory of electromagnetism, Einstein said in 1940}
\paragraph{\textcolor{blue}{"Imagine (Maxwell's) feelings when the differential equations he had formulated proved to him that electromagnetic fields spread in the form of polarized waves, and at the speed of light! To few men in the world has such an experience been vouchsafed... it took many physicists some decades to grasp the full significance of Maxwell's discovery, so bold was the leap that his genius forced upon the conceptions of his fellow-workers."}}
\end{document}